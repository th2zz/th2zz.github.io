<!DOCTYPE html>
<html lang="en">

<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8" />
    
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
     th2zz
  </title>
  <meta name="generator" content="hexo-theme-yilia-plus">
  
  <link rel="shortcut icon" href="/assets/torr3.ico" />
  
  <link rel="stylesheet" href="/css/style.css">
  <script src="/js/pace.min.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

  

  

</head>

</html>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="app">
    <main class="content">
      
<section class="cover">
    
  <div class="cover-frame">
    <div class="bg-box">
      <img src="/images/cover3.jpg" alt="image frame" />
    </div>
    <div class="cover-inner text-center text-white">
      <h1><a href="/">th2zz</a></h1>
      <div id="subtitle-box">
        
        <span id="subtitle"></span>
        
      </div>
      <div>
        
      </div>
    </div>
  </div>
  <div class="cover-learn-more">
    <a href="javascript:void(0)" class="anchor"><i class="ri-arrow-down-line"></i></a>
  </div>
</section>



<script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js"></script>

<div id="main">
  <section class="outer">
  <article class="articles">
    
    
    
    
    <article id="post-computer_network" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/12/02/computer_network/"
    >计网总结</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2019/12/02/computer_network/" class="article-date">
  <time datetime="2019-12-02T15:32:49.000Z" itemprop="datePublished">2019-12-02</time>
</a>
      
      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h1 id="包交换-vs-电路交换网络"><a class="markdownIt-Anchor" href="#包交换-vs-电路交换网络"></a> 包交换 vs 电路交换网络</h1>
<ul>
<li>电路交换
<ul>
<li>需要建立连接 和 专用物理线路 线路利用率低 没有转发机制</li>
<li>容易受网络中断影响</li>
</ul>
</li>
<li>包交换
<ul>
<li>更灵活  不需要专用线路 可以线路复用  线路利用率高</li>
<li>不容易受网络中断影响</li>
</ul>
</li>
</ul>
<h1 id="时延"><a class="markdownIt-Anchor" href="#时延"></a> 时延</h1>
<p>E2E总时延 = 排队时延 + 处理时延 + 传输时延 + 传播时延</p>
<p>P2P总时延 = 传输时延 + 传播时延</p>
<h1 id="传输过程和基本术语"><a class="markdownIt-Anchor" href="#传输过程和基本术语"></a> 传输过程和基本术语</h1>
<p><strong>Message “报文” - Segment “报文段” - Datagram / Packet “数据报 / 包” - Frame“帧” - bit</strong></p>
<p><img src="https://img-blog.csdnimg.cn/20181201104548931.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2EzMTkyMDQ4,size_16,color_FFFFFF,t_70" alt="img"></p>
<p><a href="https://blog.csdn.net/a3192048/article/details/84671340" target="_blank" rel="noopener">https://blog.csdn.net/a3192048/article/details/84671340</a></p>
<ul>
<li>
<p>Links: 链路 连接节点的物理介质</p>
</li>
<li>
<p>Service / Interface: between layering</p>
</li>
<li>
<p>Protocol: between peer</p>
</li>
<li>
<p>E2E Client to Server  P2P otherwise</p>
</li>
<li>
<p>根据信息在传输线上的传送方向，分为以下三种通信方式：</p>
<ul>
<li>单工通信Simplex：单向传输</li>
<li>半双工通信Half-duplex：双向交替传输</li>
<li>全双工通信Duplex：双向同时传输</li>
</ul>
</li>
<li>
<p>局域网：多种不同结构</p>
<ul>
<li>局域网是一种典型的广播信道，主要特点是网络为一个单位所拥有，且地理范围和站点数目均有限。有多种局域网技术，其中以太网占主导地位。可以按照网络拓扑结构对局域网进行分类：星 环 直线</li>
</ul>
</li>
<li>
<p>以太网：星形结构局域网 中间使用集线器或交换机连接</p>
</li>
<li>
<p>MAC地址 链路层地址 48位 设备网卡的唯一标识 有多少个适配器=多少个mac地址 os可更换</p>
</li>
<li>
<p>Switch交换机 Hub集线器 Router路由</p>
<ul>
<li>Hub 集线器 <strong>[layer1]</strong> enables mulitple hosts to create <strong>a broadcast Channel (only floods)</strong> 作用于物理层的 能使多个主机 创建一个广播频道的设备 具备多个网口，专门实现多台计算机的互联作用。</li>
<li>Switch 交换机 <strong>[layer 2]</strong> 收处理转发以太网帧到网络中的其他设备 会维护一个&lt;mac link/接口&gt; 表 “交换表” 表类似一个LRU缓存 因此能够实现mac地址识别=说它具有“学习能力”. Can have simultaneous p2p connectivity between different hosts</li>
<li>Router 路由 <strong>[layer 3]</strong> 根据routing table提供转发和路由两种功能 转发：将数据包移送到合适输出端 路由：决定数据包的路由路径。</li>
</ul>
</li>
<li>
<p>Bridge Repeater Gateway</p>
<ul>
<li>Repeater 中继器**[layer 1]** receive and repeat/regenerate signal</li>
<li>Bridge 网桥**[layer 2]** 连接两个局域网</li>
<li>Gateway 网关 <strong>[layer 3]</strong>  两个不同网络之间的关口设备</li>
</ul>
</li>
</ul>
<h1 id="ip-service-model-ip-best-effort-network-最大努力网络"><a class="markdownIt-Anchor" href="#ip-service-model-ip-best-effort-network-最大努力网络"></a> IP-service model / IP best-effort network /最大努力网络</h1>
<ul>
<li>
<p>packets may lose, duplicate, reorder</p>
</li>
<li>
<p>connectionelss best-effort destination based forwarding.</p>
</li>
</ul>
<h1 id="layering-architecture"><a class="markdownIt-Anchor" href="#layering-architecture"></a> Layering &amp; Architecture</h1>
<ul>
<li>OSI architecture 应用层传输层之间多了session(建立及管理会话) presentation(数据压缩、加密以及数据描述)</li>
<li>TCP/IP architecture 将物理层和数据链路层合并为“网络接口层”</li>
</ul>
<h2 id="application-layer"><a class="markdownIt-Anchor" href="#application-layer"></a> Application Layer</h2>
<p><strong>E2E</strong>用户服务  HTTP FTP DNS DHCP 远程登录 邮件</p>
<h2 id="transport-layer"><a class="markdownIt-Anchor" href="#transport-layer"></a> Transport Layer</h2>
<p><strong>E2E</strong> <strong>为应用进程提供端到端的通信服务 在应用层和网络层之间multiplexing和demultiplexing</strong> TCP UDP</p>
<p>Hide defects and limitations of the network</p>
<p>Fragmentation &amp; reassembly</p>
<p>resend defect packets</p>
<ul>
<li>TCP
<ul>
<li>Connection oriented: need to set up connection (has overhead)</li>
<li>Reliable: it will make sure packets get through, if lost/corrupted resend packet</li>
<li>Flow control: “making sure receiver not overwhelmed”</li>
<li>Congestion control: “making network is not overloaded”</li>
</ul>
</li>
<li>UDP
<ul>
<li>Connectionless: no need to set up connection, if need to send just send</li>
<li>Unreliable best-effort</li>
<li>No Flow control</li>
<li>No Congestion control</li>
</ul>
</li>
</ul>
<p>No timing / throughput / security gurantee</p>
<p>Why should we even bother using UDP ? you have a lot more control when having a tradeoff</p>
<h2 id="network-layer"><a class="markdownIt-Anchor" href="#network-layer"></a> Network Layer</h2>
<p>P2P Addressing, Routing, Congestion control <strong>点对点寻址，路由，拥塞控制</strong> Moving data between networks. 涉及协议： IP, ARP, ICMP and routing protocol</p>
<ul>
<li>
<p>Addressing</p>
<ul>
<li>
<p>IP: 沙漏结构的中点，将异构网络连接起来，使之看起来像个统一的网络</p>
<ul>
<li>IP is a <strong>unreliable</strong> protocol because it does not guarantee the delivery of a datagram to its destination. <strong>The reliability must be provided by the upper layer protocols like TCP.</strong> IP does not support flow control, retransmission, acknowledgement and error recovery.</li>
<li><strong>地址系统</strong>
<ul>
<li>Class-based addressing (过去版本):  lead to problem of large #networks in routing table</li>
<li>Subnetting and supernetting 子网与超网
<ul>
<li>subnet ip = subnet mask &amp; host ip address</li>
<li>Supernetting: classless interdomain routing CIDR 无分类跨网地址系统
<ul>
<li>ip地址=网络前缀+主机号 128.14.35.7/20 表示前 20 位为网络前缀。</li>
<li>意义：减少了路由表项   查找时采取最长前缀匹配原则选择哪一个</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Fragmentation/Reassembly <strong>报文的拆分重组</strong>: enabling heterogenous system to transmit their own “max pkt” 和tcp合作 tcp负责mtu discovery</li>
<li>Error reporting and control (ICMP) <strong>错误报告和控制</strong>
<ul>
<li>
<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/aa29cc88-7256-4399-8c7f-3cf4a6489559.png" alt="img" style="zoom:30%;">
</li>
<li><strong>封装在 IP 数据报中</strong>，但是不属于高层协议。</li>
<li>ping 用来测试两台主机之间的连通性 通过icmp echo实现</li>
</ul>
</li>
<li>Traceroute 追踪一个数据包路径: 封装一个无法交付的udp包, 利用IP协议的“ttl”字段，尝试从每个网关到某个主机的路径引发ICMP 超时响应。</li>
<li>IP packet format</li>
</ul>
<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/85c05fb1-5546-4c50-9221-21f231cdc8c5.jpg" alt="img" style="zoom:40%;">
</li>
</ul>
</li>
<li>
<p>Routing</p>
<ul>
<li>
<p><strong>How does router figure out MAC</strong></p>
<ul>
<li>
<p>ARP: routers and hosts maintain an dynammic &lt;IP, MAC&gt; cache, this table is called ARP table</p>
<p>If IP is not in ARP table, broadcast ARP request, hosts that have that IP address will responds</p>
</li>
</ul>
</li>
<li>
<p>Types &amp; protocols used</p>
<ul>
<li>Intra-domain
<ul>
<li>RIP Routing Information Protocol:  rely on local computation in all nodes
<ul>
<li>Distance Vector Protocol (based on Bellman-ford)</li>
</ul>
</li>
<li>OSPF Open Shortest Path First Protocol: no local computation  <strong>faster loop-free convergence</strong>
<ul>
<li>Link state Protocol (based on Dijkstra’s shortest path)</li>
</ul>
</li>
</ul>
</li>
<li>Inter-domain
<ul>
<li>BGP Border Gateway Protocol</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="link-layer"><a class="markdownIt-Anchor" href="#link-layer"></a> Link Layer</h2>
<p>P2P <strong>相邻网络节点/主机的数据传输和控制</strong> 局域网(LAN) 广域网(WAN)</p>
<ul>
<li><strong>Framing</strong> 把网络层传下来的包封装成帧 加个开始和结束</li>
<li>P2P点对点服务: Logical link control (LLC)
<ul>
<li><strong>Error Detection</strong> CRC checksum</li>
<li><strong>Flow Control</strong> “making sure receiver not overwhelmed”</li>
</ul>
</li>
<li>Broadcast广播服务: Media access control (MAC)
<ul>
<li><strong>Frames synchronization</strong> 帧的同步 clock based, character counting, byte stuffing.</li>
<li><strong>Channel sharing</strong> 信道共享- methods:
<ul>
<li>信道复用：时分，频分，码分</li>
<li>交替：轮询，令牌传递</li>
<li>随机访问   主要例子：Aloha, Ethernet
<ul>
<li>Ethernet MAC采用CSMA/CD协议 (Carrier Sense Multiple Access / Collision Detection) 载波监听多点接入/碰撞检测
<ul>
<li>Only if line is idle, start to send immediately (Carrier Sense 载波监听)</li>
<li>if busy wait for “inter-frame gap” = 96 bit time</li>
<li>if collision detected, send jam signal, do binary exponential backoff “nth randomly choose k from {0,1,2,…,2^n-1}, then delay k*51.2 μs” 二进制指数后退   collision domain = 1 RTT</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="physical-layer"><a class="markdownIt-Anchor" href="#physical-layer"></a> Physical Layer</h2>
<p>P2P transmission of raw bits</p>
<h1 id="application-layer-2"><a class="markdownIt-Anchor" href="#application-layer-2"></a> Application Layer</h1>
<ul>
<li>
<p>2 different Architecture: Client Server / Peer to Peer</p>
</li>
<li>
<p>Socket = Door</p>
<ul>
<li>Transport Layer = hallway</li>
</ul>
</li>
<li>
<p>IP + port determines host &amp; process</p>
</li>
<li>
<p>Public Domain Protocols    Propertiary protocol Skype … etc.</p>
<ul>
<li>HTTP</li>
<li>FTP</li>
<li>SMTP</li>
<li>BitTorrent</li>
</ul>
</li>
<li>
<p>不同情况下应用有不同需求 data loss vs time-sensitive vs throughput</p>
</li>
</ul>
<h2 id="常用端口"><a class="markdownIt-Anchor" href="#常用端口"></a> 常用端口</h2>
<table>
<thead>
<tr>
<th>应用</th>
<th>应用层协议</th>
<th>端口号</th>
<th>传输层协议</th>
<th>备注</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>域名解析</strong></td>
<td><strong>DNS</strong></td>
<td><strong>53</strong></td>
<td><strong>UDP/TCP</strong></td>
<td><strong>长度超过 512 字节时使用 TCP</strong></td>
</tr>
<tr>
<td><strong>动态主机配置协议</strong></td>
<td><strong>DHCP</strong></td>
<td><strong>67/68</strong></td>
<td><strong>UDP</strong></td>
<td></td>
</tr>
<tr>
<td><strong>超文本传送协议</strong></td>
<td><strong>HTTP</strong></td>
<td><strong>80</strong></td>
<td><strong>TCP</strong></td>
<td></td>
</tr>
<tr>
<td><strong>文件传送协议</strong></td>
<td><strong>FTP</strong></td>
<td><strong>20/21</strong></td>
<td><strong>TCP</strong></td>
<td>数据连接 20，控制连接 21</td>
</tr>
<tr>
<td>远程终端协议</td>
<td>TELNET</td>
<td>23</td>
<td>TCP</td>
<td>ssh = 22</td>
</tr>
<tr>
<td>简单网络管理协议</td>
<td>SNMP</td>
<td>161/162</td>
<td>UDP</td>
<td></td>
</tr>
<tr>
<td>简单邮件传送协议</td>
<td>SMTP</td>
<td>25</td>
<td>TCP</td>
<td></td>
</tr>
<tr>
<td>邮件读取协议</td>
<td>POP3</td>
<td>110</td>
<td>TCP</td>
<td></td>
</tr>
<tr>
<td>网际报文存取协议</td>
<td>IMAP</td>
<td>143</td>
<td>TCP</td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="web-and-http"><a class="markdownIt-Anchor" href="#web-and-http"></a> Web and HTTP</h2>
<h2 id="ftp"><a class="markdownIt-Anchor" href="#ftp"></a> FTP</h2>
<p>使用TCP进行连接, 使用2个连接来传输一个文件</p>
<ul>
<li>控制连接：服务器打开端口号 21 等待客户端的连接，客户端主动建立连接后，使用这个连接将客户端的命令传送给服务器，并传回服务器的应答。</li>
<li>数据连接：用来传送一个文件数据</li>
</ul>
<p>根据数据连接是否是服务器端主动建立，FTP 有主动和被动两种模式：</p>
<ul>
<li>主动模式：服务器端主动建立数据连接，服务器端端口号 20，客户端端口号1024 - 65535随机（因为 0~1023 是熟知端口号）。</li>
</ul>
<p><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/03f47940-3843-4b51-9e42-5dcaff44858b.jpg" alt="img"></p>
<ul>
<li>被动模式：服务器端被动，客户端主动建立数据连接，客户端端口号自己指定，服务器端的端口号随机。</li>
</ul>
<p><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/be5c2c61-86d2-4dba-a289-b48ea23219de.jpg" alt="img"></p>
<p>主动模式要求客户端开放端口号给服务器端，需要去配置客户端的防火墙。被动模式只需要服务器端开放端口号即可，无需客户端配置防火墙。但是被动模式会导致服务器端的安全性减弱，因为开放了过多的端口号。</p>
<h2 id="dns"><a class="markdownIt-Anchor" href="#dns"></a> DNS</h2>
<img src="https://s2.ax1x.com/2020/02/03/1NTl4S.png" alt="dns" style="zoom:50%;">
<img src="https://s2.ax1x.com/2020/02/03/1NTMAf.png" alt="dns" style="zoom:50%;">
<img src="https://s2.ax1x.com/2020/02/03/1NTuHP.png" alt="recdns" style="zoom:50%;">
<p>DNS 可以使用 <strong>UDP 或者 TCP</strong> 进行传输，<strong>使用的端口号都为 53</strong>。大多数情况下 DNS 使用 <strong>UDP</strong> 进行传输，这就要求域名解析器和域名服务器都必须<strong>自己处理超时和重传</strong>从而保证可靠性。在两种<strong>特殊情况下会使用 TCP</strong> 进行传输：</p>
<ul>
<li>如果返回的响应超过 512 字节（UDP 最大只支持 512 字节的数据）。</li>
<li>DNS zone transfer</li>
</ul>
<h4 id="dns-负载均衡"><a class="markdownIt-Anchor" href="#dns-负载均衡"></a> DNS 负载均衡</h4>
<p>同一主机在dns服务器里配置多个主机记录=多个不同服务器ip，dns服务器解析域名时会轮询，这就完成了简单的负载均衡。</p>
<h2 id="dhcp"><a class="markdownIt-Anchor" href="#dhcp"></a> DHCP</h2>
<p>只适用于动态ip分配的情形，如进入一个新的移动网络。 主机不知道自己ip地址 ask dhcp server</p>
<p>DHCP (Dynamic Host Configuration Protocol) 是用于动态ip分配和配置的协议。</p>
<p>DHCP 配置的内容不仅是 IP 地址，还包括子网掩码、网关 IP 地址。</p>
<p>DHCP 工作过程如下：</p>
<ol>
<li>客户端发送 Discover 报文，该报文的目的地址为 255.255.255.255:67，源地址为 0.0.0.0:68，被放入 UDP 中，该报文被广播到同一个子网的所有主机上。如果客户端和 DHCP 服务器不在同一个子网，就需要使用中继代理。</li>
<li>DHCP 服务器收到 Discover 报文之后，发送 Offer 报文给客户端，该报文包含了客户端所需要的信息。因为客户端可能收到多个 DHCP 服务器提供的信息，因此客户端需要进行选择。</li>
<li>如果客户端选择了某个 DHCP 服务器提供的信息，那么就发送 Request 报文给该 DHCP 服务器。</li>
<li>DHCP 服务器发送 Ack 报文，表示客户端此时可以使用提供给它的信息。</li>
</ol>
<p><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/23219e4c-9fc0-4051-b33a-2bd95bf054ab.jpg" alt="img"></p>
<h2 id="远程登录协议"><a class="markdownIt-Anchor" href="#远程登录协议"></a> 远程登录协议</h2>
<p>SSH  TELNET</p>
<h2 id="电子邮件协议"><a class="markdownIt-Anchor" href="#电子邮件协议"></a> 电子邮件协议</h2>
<p>发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。</p>
<h2 id="web页面请求过程"><a class="markdownIt-Anchor" href="#web页面请求过程"></a> Web页面请求过程</h2>
<h3 id="1-dhcp-配置主机信息"><a class="markdownIt-Anchor" href="#1-dhcp-配置主机信息"></a> 1. DHCP 配置主机信息</h3>
<ul>
<li>假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。</li>
<li>主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。</li>
<li>该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。</li>
<li>该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:FF:FF:FF:FF:FF，将广播到与交换机连接的所有设备。</li>
<li>连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。</li>
<li>该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。</li>
<li>主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。</li>
</ul>
<h3 id="2-arp-解析-mac-地址"><a class="markdownIt-Anchor" href="#2-arp-解析-mac-地址"></a> 2. ARP 解析 MAC 地址</h3>
<ul>
<li>主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。</li>
<li>主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。</li>
<li>该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。</li>
<li>该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。</li>
<li>DHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。</li>
<li>主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:FF:FF:FF:FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。</li>
<li>网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。</li>
</ul>
<h3 id="3-dns-解析域名"><a class="markdownIt-Anchor" href="#3-dns-解析域名"></a> 3. DNS 解析域名</h3>
<ul>
<li>知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。</li>
<li>网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。</li>
<li>因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。</li>
<li>到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。</li>
<li>找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。</li>
</ul>
<h3 id="4-http-请求页面"><a class="markdownIt-Anchor" href="#4-http-请求页面"></a> 4. HTTP 请求页面</h3>
<ul>
<li>有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。</li>
<li>在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。</li>
<li>HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。</li>
<li>连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。</li>
<li>HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。</li>
<li>浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。</li>
</ul>
<h1 id="tcpudp"><a class="markdownIt-Anchor" href="#tcpudp"></a> TCP/UDP</h1>
<ul>
<li>
<p>UDP header：src port, dest port, header length, checksum</p>
</li>
<li>
<p><strong>TCP header:</strong></p>
<ul>
<li>SRC，DST ports (16-bit each)</li>
<li><strong>Sequence #序号,     Ack #确认号</strong>(32-bit each) 序号：当前数据段第一个字节编号 确认号：期望下个数据段第一个字节编号</li>
<li>Header length(data offset), <strong>reserve flags(indicate pkt types)</strong> SYN FIN ACK</li>
<li><strong>Receive window</strong> (16-bits     that specify how big my receive buffer is) important for <strong>flow control</strong></li>
<li>Check sum, Urgent Ptr: can be     used by app to indicate a receiving host need to pay attention about     packets but most case is ignored.</li>
<li>Options</li>
</ul>
</li>
<li>
<p>TCP</p>
<ul>
<li>全双工：代表建立连接后可以双向传送接受数据</li>
<li>以连接为导向： 意味着需要主动建立连接</li>
<li>可以提供包级别的可靠传输 什么是包级别的可靠传输：udp只提供位级别的可靠传输 由checksum实现 只能进行简单的检测看看数据是否污染，包级别可靠传输 在网络层 也就是基本的的ip-service model=best-effort destination-based forwarding里是不能够被保证的，但是我们在很多实际应用中又需要这个保证，所以就在传输层由tcp来做：<strong>保证包级别可靠传输</strong>主要靠两个机制：
<ul>
<li>接收方发送<strong>确认</strong>ack 就是要求接受者每次接收到数据都要回复发送方 说一声我收到了 只有这个确认机制只能保证我们可以收到包，还不够，有问题的包还需要进行恢复</li>
<li><strong>计时器/超时检测机制</strong> 解决了“<strong>什么时候重新发没收到的/有问题的包</strong>”  他的机制很简单：只要超时了 就要重发 超时标准要比RTT稍微多一点尽量接近RTT, RTO新= RTO旧*2  by karn’s algorithm</li>
</ul>
</li>
<li>提供流量控制：确保接收方的buffer不会overflow
<ul>
<li>接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。</li>
</ul>
</li>
<li>提供拥塞控制：与整个网络有关, 网络比较拥挤的时候控制发送方的窗口。增加一个congestion window CWND
<ul>
<li><strong>send window (#unacknowledge pkts in flight) = min(CWND, RWND</strong>) 当cwnd更小时，我们就进入了一个拥塞控制的模式
<ul>
<li>慢开始与拥塞避免
<ul>
<li>cwnd := 1, cwnd++ for each ack == cwnd*2 each RTT</li>
<li>cwnd &gt;= ssthresh do congestion avoidance: cwnd++ for each RTT;</li>
</ul>
</li>
<li>快重传和快恢复 on dupack fast retransmit the next sequence from receiver side.  Fast recover it by setting ssthresh = cwnd/2, cwnd = ssthresh, do congestion avoidance</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="三次握手建立连接-四次挥手关闭连接"><a class="markdownIt-Anchor" href="#三次握手建立连接-四次挥手关闭连接"></a> 三次握手建立连接 四次挥手关闭连接</h2>
<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/e92d0ebc-7d46-413b-aec1-34a39602f787.png" alt="img" style="zoom:35%;">
<ul>
<li>
<p><strong>为什么需要三次握手</strong>：TCP是一个<strong>全双工</strong>通信协议，也就是说它是<strong>双向收发</strong>的。<strong>初始序号是两边都要随机选择</strong>, 这个主要是因为安全问题要避免TCP sequence prediction attack的。<strong>然后，因为两方都要告诉对面自己的初始序号</strong> = 也就是<strong>通信双方数据原点的位置</strong>，<strong>所以至少要4次握手</strong>。SYN  ACK SYN ACK, <strong>然后因为tcp header里reserve flags部分SYN ACK是可以同时为1的 中间两个步骤可以合并</strong> 所以3次就够。</p>
</li>
<li>
<p>第三次握手过程中sender可以piggypack data而receiver只能在这次握手结束才可以。</p>
</li>
<li>
<p>在socket编程中，客户端执行connect()时，将触发三次握手。</p>
</li>
</ul>
<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/f87afe72-c2df-4c12-ac03-9b8d581a8af8.jpg" alt="img" style="zoom:50%;">
<ul>
<li>
<p>四次挥手是因为tcp是双向的性质+tcp半关闭造成的。假如客户端主动关闭，那么直到客户端收到服务器的ack前，数据传输仍然可以从服务器到客户端进行，tcp是半关闭的client-server关了但server-client方向还没关，这也是为什么有close-wait状态的原因，服务器端要等待最后这一波数据传输的完成。所以这也解释了中间两次为什么不能像建立连接一样合并。当服务器没有数据要传时他就可以通过fin来释放自己方向的连接了。</p>
</li>
<li>
<p><strong>TIME_WAIT / 2MSL等待状态</strong>: 首先被动方如果接受了ack不需要等，因为他已经完成同步了可以释放资源了。然后主动方必须要等因为他不知道自己发的ack对面收没收到。这里需要假设没收到。那么它需要等待来自对面的超时重传消息，这最坏情况要1MSL。然后他等到了的话又要发ack回去。所以主动方要等最坏情况一个来回2MSL。</p>
</li>
<li>
<p>在socket编程中，任何一方执行close()操作即可产生挥手操作。</p>
</li>
</ul>
<h2 id="应用层面实现可靠传输-发收双方缓存工作原理滑动窗口"><a class="markdownIt-Anchor" href="#应用层面实现可靠传输-发收双方缓存工作原理滑动窗口"></a> 应用层面实现可靠传输-发收双方缓存工作原理：滑动窗口</h2>
<ul>
<li>Buffers on senders and receivers are operated as “sliding window”. Senders maintain buffers of sent but unacknowledged packets. Receivers maintains buffer to assure non-duplicate, in order delivery to applications.</li>
<li>发送方缓存：<strong>已发送和未确认的包</strong>   接收方缓存：<strong>不重复，按序到达的包</strong></li>
</ul>
<p>窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。</p>
<p><strong>发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收</strong>。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。</p>
<p>接收窗口<strong>只会对窗口内最后一个按序到达的字节进行确认</strong>。<strong>发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。就可以移动了</strong>。<strong>如果发送方窗口迟迟收不到来自接收方的确认，就会超时重传</strong></p>
<p><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/a3253deb-8d21-40a1-aae4-7d178e4aa319.jpg" alt="img"></p>
<h2 id="拥塞控制"><a class="markdownIt-Anchor" href="#拥塞控制"></a> 拥塞控制</h2>
<p>如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。</p>
<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/51e2ed95-65b8-4ae9-8af3-65602d452a25.jpg" alt="img" style="zoom:30%;">
<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/910f613f-514f-4534-87dd-9b4699d59d31.png" alt="img" style="zoom:30%;">
<h2 id="1-慢开始与拥塞避免"><a class="markdownIt-Anchor" href="#1-慢开始与拥塞避免"></a> 1. 慢开始与拥塞避免</h2>
<ul>
<li>
<p>Slow start: 初始 cwnd = 1，每收到1个ack cwnd++，cwnd指数增长：2、4、8 …</p>
</li>
<li>
<p>为避免过快，设置一个慢开始门限 ssthresh，当 cwnd &gt;= ssthresh 时，进入拥塞避免，每个轮次cwnd++</p>
</li>
<li>
<p>超时: 令 ssthresh = cwnd / 2，重新执行慢开始。</p>
</li>
</ul>
<h2 id="2-快重传与快恢复"><a class="markdownIt-Anchor" href="#2-快重传与快恢复"></a> 2. 快重传与快恢复</h2>
<p>接收方只对最后一个收到的有序报文段进行确认。在发送方，如果收到<strong>三个重复确认</strong>，那么可以知道接收方下一个报文段丢失，此时执行快重传</p>
<p>只是丢失个别报文段，而不是网络拥塞，因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。</p>
<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/f61b5419-c94a-4df1-8d4d-aed9ae8cc6d5.png" alt="img" style="zoom:50%;">
<h1 id="http"><a class="markdownIt-Anchor" href="#http"></a> HTTP</h1>
<ul>
<li>Stateless
<ul>
<li>Every request is completely independent</li>
<li>Similar to transaction</li>
<li>programming, local storage, cookies, sessions are used to create enhanced user experience</li>
</ul>
</li>
<li>HTTPS
<ul>
<li>data sent is encrpted</li>
<li>SSL / TLS</li>
<li>install a certificate on web host.</li>
</ul>
</li>
<li>HTTP Methods
<ul>
<li>GET: fetch data from server</li>
<li>POST: submit data to server</li>
<li>PUT: update data already on the server</li>
<li>DELETE: deletes data from server</li>
</ul>
</li>
<li>Headers
<ul>
<li>General: Request URL, Method, Status code, remote address, referer policy</li>
<li>Response: server, set-cookie, content-type, content-length, date</li>
<li>Request: cookies, accept-xxx, content-type, content-length, authorization, user-agent, referrer</li>
</ul>
</li>
</ul>
<h2 id="基本方法"><a class="markdownIt-Anchor" href="#基本方法"></a> 基本方法</h2>
<ul>
<li>Get 获取资源</li>
<li>Post 传输数据</li>
<li>Head 获取报文头部</li>
<li>Put/Delete 上传/删除文件 不安全没有验证机制</li>
<li>Patch 部分修改资源</li>
</ul>
<h2 id="状态码"><a class="markdownIt-Anchor" href="#状态码"></a> 状态码</h2>
<p>200 OK</p>
<p>3XX 重定向</p>
<p>4XX 客户端错误 如 404 NOT FOUND</p>
<p>5XX 服务端错误</p>
<h2 id="长连接短连接流水线"><a class="markdownIt-Anchor" href="#长连接短连接流水线"></a> 长连接短连接&amp;流水线</h2>
<ul>
<li>
<p>HTTP 1.1之后采用长连接persistent connection 只需要建立一次 TCP 连接就能进行多次 HTTP 通信。如果要断开连接，需要由客户端或者服务器端提出断开，使用 <code>Connection : close</code>；在 HTTP/1.1 之前默认是短连接的，如果需要使用长连接，则使用 <code>Connection : Keep-Alive</code>。</p>
</li>
<li>
<p>默认情况下，HTTP 请求是按顺序发出的，下一个请求只有在当前请求收到响应之后才会被发出。由于受到网络延迟可能需要等待很长时间。</p>
<p>流水线是在同一条长连接上连续发出请求，而不用等待响应返回，这样可以减少延迟。</p>
</li>
</ul>

      
      <!-- reward -->
      
    </div>
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Computer-Network/">Computer Network</a></li></ul>


    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-java-jvm" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/10/01/java-jvm/"
    >JVM</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2019/10/01/java-jvm/" class="article-date">
  <time datetime="2019-09-30T17:34:41.000Z" itemprop="datePublished">2019-09-30</time>
</a>
      
      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h1 id="jvm-architecture"><a class="markdownIt-Anchor" href="#jvm-architecture"></a> JVM architecture</h1>
<ul>
<li>
<p>Main function: load &amp; execute java application</p>
</li>
<li>
<p>Process: edit - javac myapp.java - java myapp (create a jvm instance)</p>
</li>
<li>
<img src="https://s2.ax1x.com/2020/02/08/1WkqSg.png" alt="1WkqSg.png" style="zoom:50%;">
</li>
<li>
<img src="https://s2.ax1x.com/2020/02/08/1WAGnA.png" alt="1WAGnA.png" style="zoom:50%;">
</li>
<li>
<p>components:</p>
<ul>
<li>class loader: input .class files output bytecode for execution engine</li>
<li>Runtime data areas</li>
<li>execution engine: executes byte code by talking to OS (may use native method calls that will be translated to machine language)</li>
</ul>
</li>
</ul>
<h3 id="1-class-loader-and-its-subsystem"><a class="markdownIt-Anchor" href="#1-class-loader-and-its-subsystem"></a> 1. Class Loader and its subsystem</h3>
<ul>
<li>
<img src="https://s2.ax1x.com/2020/02/08/1WA2NV.png" alt="1WA2NV.png" style="zoom:50%;">
</li>
</ul>
<h4 id="load"><a class="markdownIt-Anchor" href="#load"></a> Load</h4>
<ul>
<li>Load: Load bytecode into memory
<ul>
<li>can read from different sources: file system, socket</li>
<li>can have classNotFound</li>
<li>Three types of class loaders:
<ul>
<li><strong>bootstrap</strong> rt.jar: <strong>load java internal classes</strong></li>
<li><strong>extension</strong> jre/lib/ext: <strong>load classes from additional application jar in jre/lib</strong></li>
<li><strong>application</strong> CLASSPATH, -cp: load classes from specified path</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="link"><a class="markdownIt-Anchor" href="#link"></a> Link</h4>
<ul>
<li>Link phase
<ul>
<li><strong>verify</strong> bytecode compatibility with JVM</li>
<li><strong>Prepare</strong> allocate memory and init to default value for class (static) variables</li>
<li><strong>Resolve</strong> resolve symbolic references to other classes / constant pool to actual reference
<ul>
<li>classDefNotFound</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="initialize"><a class="markdownIt-Anchor" href="#initialize"></a> Initialize</h4>
<ul>
<li>Initialize
<ul>
<li>Execute static code block “static initializer”</li>
<li>actual initialization of static variables</li>
</ul>
</li>
</ul>
<h4 id="类初始化时机"><a class="markdownIt-Anchor" href="#类初始化时机"></a> 类初始化时机</h4>
<ol>
<li>主动引用<br>
虚拟机规范中并没有强制约束何时进行加载，但是规范严格规定了有且只有下列五种情况必须对类进行初始化（加载、验证、准备都会随之发生）：</li>
</ol>
<ul>
<li>遇到 new、getstatic、putstatic、invokestatic 这四条字节码指令时，如果类没有进行过初始化，则必须先触发其初始化。最常见的生成这 4 条指令的场景是：使用 new 关键字实例化对象的时候；读取或设置一个类的静态字段（被 final 修饰、已在编译期把结果放入常量池的静态字段除外）的时候；以及调用一个类的静态方法的时候。</li>
<li>使用 java.lang.reflect 包的方法对类进行反射调用的时候，如果类没有进行初始化，则需要先触发其初始化。</li>
<li>当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。</li>
<li>当虚拟机启动时，用户需要指定一个要执行的主类（包含 main() 方法的那个类），虚拟机会先初始化这个主类；</li>
<li>当使用 JDK 1.7 的动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果为 REF_getStatic, REF_putStatic, REF_invokeStatic 的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化；</li>
</ul>
<ol start="2">
<li>被动引用<br>
以上 5 种场景中的行为称为对一个类进行主动引用。除此之外，所有引用类的方式都不会触发初始化，称为被动引用。被动引用的常见例子包括：</li>
</ol>
<ul>
<li>通过子类引用父类的静态字段，不会导致子类初始化。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">System.out.println(SubClass.value);  <span class="comment">// value 字段在 SuperClass 中定义Copy to clipboardErrorCopied</span></span><br></pre></td></tr></table></figure>
<ul>
<li>通过数组定义来引用类，不会触发此类的初始化。该过程会对数组类进行初始化，数组类是一个由虚拟机自动生成的、直接继承自 Object 的子类，其中包含了数组的属性和方法。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SuperClass[] sca = <span class="keyword">new</span> SuperClass[<span class="number">10</span>];Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure>
<ul>
<li>常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">System.out.println(ConstClass.HELLOWORLD);</span><br></pre></td></tr></table></figure>
<h3 id="2-runtime-data-areas"><a class="markdownIt-Anchor" href="#2-runtime-data-areas"></a> 2. Runtime data areas</h3>
<ul>
<li><strong>per thread means operations in thread local storage are generally safe.</strong></li>
<li><strong>per JVM means operations in shared data areas such as meatspace, Heap are not thread-safe.</strong></li>
</ul>
<h4 id="per-thread"><a class="markdownIt-Anchor" href="#per-thread"></a> Per-thread</h4>
<img src="https://s2.ax1x.com/2020/02/08/1WmTkn.png" alt="1WmTkn.png" style="zoom:50%;">
<h5 id="pc-register"><a class="markdownIt-Anchor" href="#pc-register"></a> PC Register</h5>
<ul>
<li><strong>PC Register</strong>:  program counter register
<ul>
<li>pointer to next instruction <strong>per thread</strong></li>
</ul>
</li>
</ul>
<h5 id="java-stacks"><a class="markdownIt-Anchor" href="#java-stacks"></a> Java Stacks</h5>
<ul>
<li><strong>Java Stacks</strong>: stack frames “chains of stack frames” corresponded to current methods execution <strong>per thread</strong>
<ul>
<li>use -Xss to mention size of stacks we want to maintain</li>
<li>when run out of memory, can have StackOverflowError</li>
</ul>
</li>
</ul>
<h5 id="native-method-stacks"><a class="markdownIt-Anchor" href="#native-method-stacks"></a> Native method Stacks</h5>
<ul>
<li><strong>Native method stacks</strong>: native method stacks if needed / used <strong>per thread</strong>.
<ul>
<li>a thread with its method may call a native method such as loading a dll and run something, then the native method stack will be created, and you will get a pointer</li>
</ul>
</li>
</ul>
<h4 id="per-jvm"><a class="markdownIt-Anchor" href="#per-jvm"></a> Per-JVM</h4>
<img src="https://s2.ax1x.com/2020/02/08/1WZNA1.md.png" alt="1WZNA1.md.png" style="zoom:80%;">
<h5 id="metaspace-method-area"><a class="markdownIt-Anchor" href="#metaspace-method-area"></a> Metaspace / Method Area</h5>
<ul>
<li>
<p><strong>Method Area</strong> “PermGen space 64MB”: metadata for class, available for reflection <strong>per JVM</strong>.</p>
<ul>
<li>use -XX:MaxPermSize to adjust size if we need to store a lot more classes</li>
<li><strong>Removed since Java 8</strong></li>
<li>Now is called: <strong>Metaspace</strong>
<ul>
<li>a seperate memory portion in native operating system</li>
<li>no limit now, can grow infinitely, but can have a limit if tuned.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="heap"><a class="markdownIt-Anchor" href="#heap"></a> Heap</h5>
<ul>
<li>
<p><strong>Heap</strong>: stores Object data such as arrays, objects… <strong>per JVM</strong>.</p>
<ul>
<li>now has runtime constant pool and string pool</li>
<li>use -Xms for min size, -Xms for max size if need to tune.</li>
</ul>
</li>
</ul>
<h5 id="direct-memory"><a class="markdownIt-Anchor" href="#direct-memory"></a> Direct Memory</h5>
<ul>
<li>直接内存: 在 JDK 1.4 中新引入了 NIO 类，它可以使用 Native 函数库直接分配堆外内存，然后通过 Java 堆里的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在堆内存和堆外内存来回拷贝数据。</li>
</ul>
<h3 id="3-execution-engine"><a class="markdownIt-Anchor" href="#3-execution-engine"></a> 3. Execution Engine</h3>
<img src="https://s2.ax1x.com/2020/02/08/1WQdZF.png" alt="1WQdZF.png" style="zoom:50%;">
<ul>
<li><strong>Interperter</strong>: interpret &amp; execute bytecode related native operations
<ul>
<li>done by interacting with Java Native Method Interface (JNI)
<ul>
<li><strong>Platform independent (native) libraries</strong>: ex. in windows JRE /bin you will see .dll files   .so on unix platform</li>
</ul>
</li>
</ul>
</li>
<li><strong>JIT Compiler</strong> (Just-in-time): do not interpret instructions that will be executed again and agin, compile it on the fly and keep the bytecode to avoid wasteful interpretations.</li>
<li><strong>Hotspot profiler</strong>: make statistics on hotspot to help JIT compiler.</li>
<li><strong>Garbage Collector (GC)</strong>: cleans up unused classes / objects in memory areas.</li>
</ul>
<h1 id="jvm-gc"><a class="markdownIt-Anchor" href="#jvm-gc"></a> JVM GC</h1>
<ul>
<li>Intro
<ul>
<li>Memory leak: 内存管理不当导致的“不需要的内存没有被释放” <strong>can have Memory leak in Java</strong></li>
<li>In C++/C, programmers responsible for manage memory, can easily lead to memory leaks if not handled properly
<ul>
<li>malloc() realloc() calloc() free() new and destructors</li>
</ul>
</li>
</ul>
</li>
<li>Basics
<ul>
<li>Live object = reachable (referenced by someone else)</li>
<li>dead object = unreachable (not referenced anywhere)</li>
<li><strong>root node = main thread</strong></li>
<li>Objects e.g. (new xxx) are allocated in the heap, static members, class definitions (metadata) are stored in Permgen / Metaspace</li>
<li>GC is carried out by a <strong>daemon thread &quot;Garbage collector&quot;</strong></li>
<li><strong>we cannot force gc to happen</strong> (System.gc()😉</li>
<li>failed new allocations in heap  = java.lang.OutOfMemoryError</li>
<li>GC只处理java new出来的对象，但无法关闭其他资源，也无法处理java调用C或其他语言分配出的内存。</li>
<li>垃圾回收分多级，0级为全部(Full)的垃圾回收，会回收OLD段中的垃圾；1级或以上为部分垃圾回收，只会回收Young中的垃圾。</li>
<li>System.gc并不保证GC执行，只是向JVM发送建议，并不是命令。</li>
<li>finalize被调用时代表gc准备回收该对象内存</li>
</ul>
</li>
</ul>
<h3 id="directed-graph-reachability"><a class="markdownIt-Anchor" href="#directed-graph-reachability"></a> Directed Graph &amp; Reachability</h3>
<ul>
<li>.NET的垃圾回收采用引用计数，java的垃圾回收机制采取的是有向图的方式来实现，具体的说，java程序中的每个线程对象就可以看作是一个有向图的起点，有向边从栈中的引用者指向堆中的引用对象。在这个有向图中，如果一个对象和根节点之间是可达的，那么这个对象就是有效的，反之，这个对象就是可以被回收的。采取这样一种机制的优点是可以有效的避免循环引用。</li>
</ul>
<h2 id="general-gc-steps-mark-sweep-compact"><a class="markdownIt-Anchor" href="#general-gc-steps-mark-sweep-compact"></a> General GC steps: Mark Sweep Compact</h2>
<ul>
<li><strong>Mark</strong>
<ul>
<li>Starts from root node (main) walks the object graph, <strong>marks reachable object</strong> as live.</li>
</ul>
</li>
<li><strong>Sweep</strong>/Delete
<ul>
<li><strong>clean unreachable objects</strong> and <strong>reclaim memory</strong></li>
</ul>
</li>
<li><strong>Compacting</strong>
<ul>
<li>arrange things in order: move objects around to <strong>avoid fragmentation</strong> = make memory contiguous.</li>
</ul>
</li>
</ul>
<h2 id="java-gc-generational-collectors"><a class="markdownIt-Anchor" href="#java-gc-generational-collectors"></a> Java GC: <strong>Generational collectors</strong></h2>
<h3 id="heap-division"><a class="markdownIt-Anchor" href="#heap-division"></a> Heap division</h3>
<ul>
<li>
<img src="https://s2.ax1x.com/2020/02/08/1WtC4S.png" alt="1WtC4S.png" style="zoom:80%;">
</li>
<li>Young Generation
<ul>
<li><strong>Eden space</strong>: new object();</li>
<li><strong>Survivor space 1 / 2</strong>: used to <strong>move back and force</strong> survivors that survive minor GC each turn
<ul>
<li>can <strong>help avoid compacting step</strong></li>
</ul>
</li>
</ul>
</li>
<li>Old Generation
<ul>
<li>objects that survived at least “threshold” rounds of GC</li>
<li>if full, iincur Major GC</li>
</ul>
</li>
</ul>
<h3 id="minor-vs-major-gc"><a class="markdownIt-Anchor" href="#minor-vs-major-gc"></a> Minor vs Major GC</h3>
<ul>
<li>Minor:
<ul>
<li>only Young Generation</li>
<li>Responsive</li>
</ul>
</li>
<li>Major:
<ul>
<li>run through entire heap</li>
<li>Long pause / latency</li>
<li>High throughput</li>
<li>Good for batch processing, jobs in database that that care about throughput &gt; latency</li>
</ul>
</li>
</ul>
<h3 id="entire-process"><a class="markdownIt-Anchor" href="#entire-process"></a> Entire process</h3>
<ol>
<li>new obj allocated in Eden</li>
<li>Eden full = allocation fail for new obj
<ol>
<li>Minor GC run, mark reachable objs</li>
<li>move reachable obj to survivor 1</li>
<li>Sweep unreachables</li>
<li>survivors counters =  “1” means 1 rounds</li>
</ol>
</li>
<li>Now Eden clear, allocate new objs… some in survivor 1 became unreachable… when Eden full,
<ol>
<li>minor GC mark and move reachables to survivor 2 <strong>the empty one</strong></li>
<li>move reachables in S1 to S2, <strong>increment</strong> S1 <strong>survivor counter.</strong>  By moving around this way we <strong>avoids compacting steps.</strong></li>
</ol>
</li>
<li><strong>Repeat</strong>: allocate in Eden, Eden full, mark and move all reachable (Eden or Sx) to the empty S, increment counters, sweep unreachables</li>
<li>If counter <strong>hit threshold, promote them to Old Generation</strong>.</li>
<li>If Old Generation is near full, Major GC runs across the entire heap MSC. very time consuming, can lead to pause.</li>
</ol>
<h2 id="gc-types-usages"><a class="markdownIt-Anchor" href="#gc-types-usages"></a> GC types &amp; Usages</h2>
<h3 id="basic-serial-collector"><a class="markdownIt-Anchor" href="#basic-serial-collector"></a> Basic Serial Collector</h3>
<ul>
<li>runs in single thread, used for basic applications</li>
</ul>
<h3 id="concurrent-collector-cmsc"><a class="markdownIt-Anchor" href="#concurrent-collector-cmsc"></a> Concurrent collector (CMSC)</h3>
<ul>
<li>A thread that performs GC concurrently for the app.</li>
<li>No waiting for the old generation.</li>
<li><strong>small pause only when mark / remark</strong>. Otherwise no pause “concurrent”.</li>
<li>use when
<ul>
<li>more available memory</li>
<li>high number of CPUs</li>
<li>needs responsiveness</li>
</ul>
</li>
</ul>
<h3 id="parallel-collector-pmsc"><a class="markdownIt-Anchor" href="#parallel-collector-pmsc"></a> Parallel collector (PMSC)</h3>
<ul>
<li>use multiple CPU and multiple threads to do MSC (mark sweep compact).</li>
<li>only runs when heap is full / near full.</li>
<li><strong>long pause when it runs</strong>.</li>
<li>use when
<ul>
<li>less available memory</li>
<li>less number of CPUs</li>
<li>needs high throughput &amp; can withstand pauses</li>
</ul>
</li>
</ul>
<h3 id="g1-collector-garbage-first-17"><a class="markdownIt-Anchor" href="#g1-collector-garbage-first-17"></a> G1 collector (Garbage - first) 1.7+</h3>
<ul>
<li>Divide heap into small regions, each of them can be eden / survivor / old</li>
<li><strong>Dynamically chose regions with most garbage to GC</strong>
<ul>
<li>More predictable GC pauses</li>
<li>Low pauses and fragmentation</li>
<li>Parallelism &amp; concurrency together</li>
<li>Better heap utilization</li>
</ul>
</li>
</ul>
<h3 id="usage"><a class="markdownIt-Anchor" href="#usage"></a> Usage</h3>
<p><img src="https://s2.ax1x.com/2020/02/08/1WBMZj.png" alt="1WBMZj.png"></p>
<ul>
<li>notice CMS is only in old generation.</li>
</ul>
<h2 id="memory-leaks"><a class="markdownIt-Anchor" href="#memory-leaks"></a> Memory Leaks</h2>
<ul>
<li>
<p>内存溢出通常发生于OLD段或Perm段垃圾回收后，仍然无内存空间容纳新的Java对象的情况。</p>
</li>
<li>
<p>建议将不用的对象引用设为null来避免临时的内存泄漏： 将他们标记为可清理对象。</p>
</li>
<li>
<p>常发生于</p>
<ol>
<li>使用生命周期较长的单位：单例模式类对象， 静态集合类形成的对象引用   <strong>暂时内存泄漏：只有相应对象/类被释放时才会gc</strong></li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Static Vector v = new Vector(); </span><br><span class="line">for (int i = 1; i&lt;100; i++) </span><br><span class="line">&#123; </span><br><span class="line">    Object o = new Object(); </span><br><span class="line">    v.add(o); </span><br><span class="line">    o = null; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>
<p><strong>使用了各种资源连接忘了关</strong>：数据库连接，网络连接，IO连接等，显式调用close<strong>关闭后才能被GC回收</strong></p>
</li>
<li>
<p>**改变哈希值，**当一个对象被存储进HashSet集合中以后，就不能修改这个对象中的那些参与计算哈希值的字段了，否则，对象修改后的哈希值与最初存储进HashSet集合中时的哈希值就不同了，在这种情况下，即使在contains方法使用该对象的当前引用作为的参数去HashSet集合中检索对象，也将返回找不到对象的结果，这也会导致无法从HashSet集合中单独删除当前对象，造成内存泄露</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">  Set&lt;Person&gt; set = <span class="keyword">new</span> HashSet&lt;Person&gt;();</span><br><span class="line">  Person p1 = <span class="keyword">new</span> Person(<span class="string">"唐僧"</span>,<span class="string">"pwd1"</span>,<span class="number">25</span>);</span><br><span class="line">  Person p2 = <span class="keyword">new</span> Person(<span class="string">"孙悟空"</span>,<span class="string">"pwd2"</span>,<span class="number">26</span>);</span><br><span class="line">  Person p3 = <span class="keyword">new</span> Person(<span class="string">"猪八戒"</span>,<span class="string">"pwd3"</span>,<span class="number">27</span>);</span><br><span class="line">  set.add(p1);</span><br><span class="line">  set.add(p2);</span><br><span class="line">  set.add(p3);</span><br><span class="line">  System.out.println(<span class="string">"总共有:"</span>+set.size()+<span class="string">" 个元素!"</span>); <span class="comment">//结果：总共有:3 个元素!</span></span><br><span class="line">  p3.setAge(<span class="number">2</span>); <span class="comment">//修改p3的年龄,此时p3元素对应的hashcode值发生改变</span></span><br><span class="line">  set.remove(p3); <span class="comment">//此时remove不掉，造成内存泄漏</span></span><br><span class="line">  set.add(p3); <span class="comment">//重新添加，居然添加成功</span></span><br><span class="line">  System.out.println(<span class="string">"总共有:"</span>+set.size()+<span class="string">" 个元素!"</span>); <span class="comment">//结果：总共有:4 个元素!</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
</ul>
<h2 id="java对象引用类别强引用软引用弱引用虚引用"><a class="markdownIt-Anchor" href="#java对象引用类别强引用软引用弱引用虚引用"></a> Java对象引用类别：强引用，软引用，弱引用，虚引用</h2>
<ul>
<li>
<p><strong>强引用</strong>就是平时最常用的引用，当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。</p>
</li>
<li>
<p>如果一个对象只具有<strong>软引用</strong>，则内存空间足够，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。</p>
</li>
<li>
<p>只具有<strong>弱引用</strong>的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，<strong>不管当前内存空间足够与否，都会回收它的内存</strong>。</p>
</li>
<li>
<p>虚引用，这种引用不常用，主要用途是关联对象，实现对对象引用关系追踪。虚引用并不会决定对象的生命周期。也无法通过虚引用得到一个对象。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。</p>
</li>
<li>
<p>几种引用分别位于java.lang.ref.SoftReference; java.lang.ref.WeakReference; 和 java.lang.ref.PhantomReference;</p>
</li>
</ul>
<h2 id="finalize"><a class="markdownIt-Anchor" href="#finalize"></a> finalize( )</h2>
<ul>
<li>
<p>do not use finalizer manually: finalize()</p>
<ul>
<li>
<p>guranteed to be called <strong>only ONCE</strong> at the end of execution when GC is done</p>
</li>
<li>
<p>no gurantee of gc happens</p>
</li>
<li>
<p>do not use finalizer on anything important</p>
</li>
<li>
<p>suppose we try to resurect obj by recreating an object in finalize( ), this = new xxx( );</p>
<ul>
<li>obj is recreated in memory at the end of gc = <strong>memory leak</strong></li>
</ul>
</li>
</ul>
</li>
<li>
<p>finalize被调用时代表gc准备回收该对象内存</p>
<ul>
<li>对象不可达，但是调用<strong>finalize之后</strong>又变得可达的情况存在，在finalize函数中通过this指针让其他句柄执行本身即可，但是再下次回收时不会再调用finalize，因为只能调用一次。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">protected void finalize()</span><br><span class="line">&#123;</span><br><span class="line">     main.ref=this;  // 恢复本对象，让本对象可达</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>垃圾回收器不能对用Java以外的代码编写的Class(比如JNI，C<ins>的new方法分配的内存)进行正确的回收，这时就需要覆盖默认finalize的方法来实现对这部分内存的正确释放和回收(比如C</ins>需要delete)。</li>
<li>finalize不能等同于C<ins>对象的destructor析构函数，C</ins>析构函数在在对象生命周期结束时会确定执行，而finalize函数的调用具有很大的不确定性。</li>
</ul>
<blockquote>
<p><strong>1、调用时间不确定——有资源浪费的风险</strong></p>
<p>如果把某些稀缺资源放到finalize()中释放，可能会导致该稀缺资源等上很久很久以后才被释放。造成资源的浪费！另外，某些类对象所携带的资源（比如某些JDBC的类）可能本身就很耗费内存，这些资源的延迟释放会造成很大的性能问题。</p>
<p><strong>2、可能不被调用——有资源泄漏的风险</strong></p>
<p>在某些情况下，finalize()压根儿不被调用。比如在JVM退出的当口，内存中那些对象的finalize函数可能就不会被调用了。</p>
<p>因此一些清理工作如文件的关闭，连接的关闭等不要放到finalize函数中，要在程序中单独进行管理，一般finalize只做C/C++内存的回收。<br>
<strong>3、对象可能在finalize函数调用时复活——有诈尸的风险</strong>　　<br>
诈尸的情况比较少见，不过俺还是稍微提一下。<br>
　　本来，只有当某个对象已经失效（没有引用），垃圾回收器才会调用该对象的finalize函数。但是，万一碰上某个变态的程序员，在finalize()函数内部再把对象自身的引用（也就是this）重新保存在某处，也就相当于把自己复活了（因为这个对象重新有了引用，不再处于失效状态）。这种做法是不是够变态啊</p>
<p>为了防止发生这种诡异的事情，垃圾回收器只能在每次调用完finalize()之后再次去检查该对象是否还处于失效状态。这无形中又增加了JVM的开销。<br>
　　随便提一下。由于JDK的文档中规定了（具体见“这里”），JVM对于每一个类对象实例最多只会调用一次finalize()。所以，对于那些诈尸的实例，当它们真正死亡时，finalize()反而不会被调用了。这看起来是不是很奇怪？<br>
<strong>4、要记得自己做异常捕获</strong><br>
　　刚才在介绍finalize()调用机制时提到，一旦有异常抛出到finalize函数外面，会被垃圾回收线程捕获并丢弃。也就是说，异常被忽略掉了（异常被忽略的危害，“这里”有提到）。为了防止这种事儿，凡是finalize()中有可能抛出异常的代码，你都得写上try catch语句，自己进行捕获。 　<br>
<strong>5、要小心线程安全</strong><br>
　　由于调用finalize()的是垃圾回收线程，和你自己代码的线程不是同一个线程；甚至不同对象的finalize()可能会被不同的垃圾回收线程调用（比如使用“并行收集器”的时候）。所以，当你在finalize()里面访问某些数据的时候，还得时刻留心线程安全的问题。</p>
</blockquote>
</li>
</ul>
<h2 id="常量池总结"><a class="markdownIt-Anchor" href="#常量池总结"></a> 常量池总结</h2>
<ul>
<li>
<p>**class文件常量池 / constant pool：存静态常量,符号引用和字面量 ** 存在于.class文件中</p>
</li>
<li>
<p><strong>运行时常量池</strong>：类加载后，常量池中的数据会在<strong>运行时常量池</strong>中存放！这里所说的常量包括：基本类型包装类**（包装类<strong>不管理浮点型</strong>，整形只会管理-128到127）和<strong>String</strong>（也可以通过String.intern()方法可以强制将String放入常量池）**</p>
</li>
<li>
<p><strong>字符串常量池</strong>： HotSpot VM里，记录interned string的一个全局表叫做StringTable，它本质上就是个HashSet<string>。注意它只存储对java.lang.String实例的引用，而不存储String对象的内容</string></p>
</li>
<li>
<p>运行时常量池和字符串常量池都在堆中。</p>
</li>
</ul>
<h2 id="other-notes"><a class="markdownIt-Anchor" href="#other-notes"></a> Other Notes</h2>
<ol>
<li>Tune the heaps</li>
</ol>
<img src="https://s2.ax1x.com/2020/02/08/1WspsU.png" alt="1WspsU.png" style="zoom:80%;">
<ol start="2">
<li>GC logging with graphical tool if we suspect gc is the problem for performance issues.</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-verbose:gc</span><br><span class="line"></span><br><span class="line">-XX:+PrintGCDetails</span><br><span class="line"></span><br><span class="line">-Xloggc:gc.log</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>jvisualvm: visual gc plugin</li>
</ol>

      
      <!-- reward -->
      
    </div>
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Java/">Java</a></li></ul>


    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-Database Management System - Indexing" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/04/22/Database Management System - Indexing/"
    >Database Management System - Indexing</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2019/04/22/Database Management System - Indexing/" class="article-date">
  <time datetime="2019-04-21T23:49:41.000Z" itemprop="datePublished">2019-04-21</time>
</a>
      
      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h1 id="indexing"><a class="markdownIt-Anchor" href="#indexing"></a> Indexing</h1>
<h2 id="基本概念"><a class="markdownIt-Anchor" href="#基本概念"></a> 基本概念</h2>
<ul>
<li><strong>search key/搜索码/搜索键</strong>  注意这里的码的定义与主码、候 选码以及超码中的码定义不同。这里是泛指。例如如果一个文件上有多个索引，那么它就有多个搜索码。 一个文件可以有多个索引，分别基于不同的搜索码。</li>
<li><strong>基本的索引类型</strong>:
<ul>
<li>顺序索引。基于值的顺序排序。</li>
<li>散列索引。基于将值平均分布到若干散列桶中。一个值所属的散列桶是由散列函数觉定。</li>
</ul>
</li>
<li><strong>顺序索引与散列索引评价metric</strong>。
<ul>
<li>访问类型: 范围查询？等值查询？</li>
<li>访问时间:在查询中使用该技术找到一个特定数据项或数据项集所需的时间</li>
<li>插入时间: 插入一个新数据项所需的时间。该值包括找到插入这个新数据项的正确位置所需的时间，以及更新索引结构所需的时间。</li>
<li>删除时间:删除一个数据项所需的时间。该值包括找到待删除项所需的时间，以 及更新索引结构所需的时间。</li>
<li>空间开销:索引结构所占用的额外存储空间。倘若存储索引结构的额外空间大小适度，通常牺牲一定的空间代价来换取性能的提高是值得的。 通常需要在一个文件上建立多个索引。</li>
</ul>
</li>
</ul>
<h2 id="顺序索引"><a class="markdownIt-Anchor" href="#顺序索引"></a> 顺序索引</h2>
<ul>
<li>
<p><strong>主索引/聚集索引  primary index / clustered/clustering index</strong>：</p>
<ul>
<li>不一定是建立在主码，可以是任何码之上。</li>
<li>包含记录的文件与搜索码指定的顺序相同！</li>
</ul>
</li>
<li>
<p><strong>辅助索引/次级索引/非聚集索引 secondary index non-clustering index non-clustered index</strong></p>
<ul>
<li>包含记录的文件与搜索码指定的顺序不同！</li>
</ul>
</li>
<li>
<p><strong>稠密萦引 (dense index)</strong> :</p>
<ul>
<li>稠密聚集索引：文件中的每个搜索码值都有一个索引项。索引项包括搜索码值以及指向具有该搜索码值的第一条数据记录的指针。具有相同搜 索码值的其余记录顺序地存储在第一条数据记录之后，记录根据 相同的搜索码值排序。</li>
<li>稠密非聚集索引中，索引必须存储指向所有具有相同搜索码值的记录的指针列表。</li>
<li>相比稀疏索引 定位record更快</li>
</ul>
</li>
<li>
<p><strong>稀疏索引 (sparse index) : 在稀疏索引中，只为搜索码的某些值建立索引项</strong>。</p>
<ul>
<li>只有索引是聚集索引时才能使用稀疏索引。</li>
<li>和稠密索引一样，每个索引项也包括一个搜索码值和指向具有该搜索码值的第一条数据记录的 指针。为了定位一条记录，我们找到其最大搜索码值小于或等于所查找记录的搜索码值的索引</li>
<li>require less space and impose less maintainance overhead for insertions/deletions项。然后从该索引项指向的记录开始，沿着文件中的指针查找，直到找到所需记录为止。<br>
<img src="https://i.imgur.com/HVaboXj.png" alt=""></li>
</ul>
</li>
<li>
<p><strong>选择那种索引？</strong><br>
使用稀疏还是稠密索引是一个access time and space overhead tradeoff.<br>
A good compromise is to have a sparse index with one index entry per block.<br>
Because the dominant cost in processing a database request is the time that it takes to bring a block from disk into main memory. Once we have brought in the block, the time to scan the entire block is negligible. we minimize block accesses while keeping the size of the index (and thus our space overhead) as small as possible.</p>
</li>
</ul>
<h2 id="多级索引"><a class="markdownIt-Anchor" href="#多级索引"></a> 多级索引</h2>
<ul>
<li>If the relation instead had 100,000,000 tuples, the index would instead occupy 1,000,000 blocks, or 4 gigabytes of space. Such large indices are stored as sequential files on disk.</li>
<li>If an index is small enough to be kept entirely in main memory, the search time to find an entry is low. However, if the index is so large that not all of it can be kept in memory, index blocks must be fetched from disk when required.<br>
The search for an entry in the index then requires several disk-block reads.</li>
<li>The process of searching a large index may be costly.</li>
</ul>
<img src="https://i.imgur.com/56ApMIy.png" width="250">
<ul>
<li>To locate a record, we first use binary search on the outer index to find the record for the largest search-key value less than or equal to the one that we desire. The pointer points to a block of the inner index. We scan this block until we find the record that has the largest search-key value less than or equal to the one that we desire. The pointer in this record points to the block of the file that contains the record for which we are looking.</li>
<li>In our example, an inner index with 10,000 blocks would require 10,000 entries in the outer index, which would occupy just 100 blocks. If we assume that the outer index is already in main memory, we would read only one index block for a search using a multilevel index, rather than the 14 blocks we read with binary search. As a result, we can perform 14 times as many index searches per second.</li>
<li>Indeed, we can repeat this process as many times as necessary. Indices with two or more levels are called multilevel indices. <strong>Searching for records with a multilevel index requires significantly fewer I/O operations than does searching for records by binary search</strong>.</li>
</ul>
<h2 id="索引更新"><a class="markdownIt-Anchor" href="#索引更新"></a> 索引更新</h2>
<p>Regardless of what form of index is used, every index must be updated whenever a record is either inserted into or deleted from the file. Further, in case a record in the file is updated, any index whose search-key attribute is affected by the update must also be updated;<br>
As a result we only need to consider insertion and deletion on an index, and do not need to consider updates explicitly.</p>
<ul>
<li>
<p><strong>Insertion</strong>: First, the system performs a lookup using the search-key value that appears in the record to be inserted. The actions the system takes next depend on whether the index is dense or sparse:</p>
<ul>
<li>Dense indices:</li>
</ul>
<ol>
<li>If the search-key value does not appear in the index, the system inserts an index entry with the search-key value in the index at the appropriate position.</li>
<li>Otherwise the following actions are taken:
<ul>
<li>a. If the index entry stores pointers to all records with the same search- key value, the system adds a pointer to the new record in the index entry.</li>
<li>b. Otherwise, the index entry stores a pointer to only the first record with the search-key value. The system then places the record being inserted after the other records with the same search-key values.</li>
</ul>
</li>
</ol>
<ul>
<li>Sparse indices: We assume that the index stores an entry for each block. If the system creates a new block, it inserts the first search-key value (in search-key order) appearing in the new block into the index. On the other hand, if the new record has the least search-key value in its block, the system updates the index entry pointing to the block; if not, the system makes no change to the index.</li>
</ul>
</li>
<li>
<p><strong>Deletion</strong>: To delete a record,the system first looks up the record to be deleted. The actions the system takes next depend on whether the index is dense or sparse:</p>
<ul>
<li>Dense indices:</li>
</ul>
<ol>
<li>If the deleted record was the only record with its particular search-key value, then the system deletes the corresponding index entry from the index.</li>
<li>Otherwise the following actions are taken:
<ul>
<li>a. If the index entry stores pointers to all records with the same search- key value, the system deletes the pointer to the deleted record from the index entry.</li>
<li>b. Otherwise, the index entry stores a pointer to only the first record with the search-key value. In this case, if the deleted record was the first record with the search-key value, the system updates the index entry to point to the next record.</li>
</ul>
</li>
</ol>
<ul>
<li>Sparse indices:</li>
</ul>
<ol>
<li>If the index does not contain an index entry with the search-key value of the deleted record, nothing needs to be done to the index.</li>
<li>Otherwise the system takes the following actions:
<ul>
<li>a. If the deleted record was the only record with its search key, the system replaces the corresponding index record with an index rec- ord for the next search-key value (in search-key order). If the next search-key value already has an index entry, the entry is deleted instead of being replaced.</li>
<li>b. Otherwise, if the index entry for the search-key value points to the record being deleted, the system updates the index entry to point to the next record with the same search-key value.</li>
</ul>
</li>
</ol>
</li>
</ul>
<p>Insertion and deletion algorithms for multilevel indices are a simple extension of the scheme just described. On deletion or insertion, the system updates the lowest-level index as described. As far as the second level is concerned, the lowest-level index is merely a file containing records—thus, if there is any change in the lowest-level index, the system updates the second-level index as described. The same technique applies to further levels of the index, if there are any.</p>
<h2 id="辅助索引"><a class="markdownIt-Anchor" href="#辅助索引"></a> 辅助索引</h2>
<p>A clustering/primary index may be sparse    中间空过的搜索键值可以通过顺序扫描的方式获取<br>
Secondary/nonclustered indices must be dense  辅助索引若是稀疏的，就不能保证sequential order, 中间相隔的搜索键值没有办法获取<br>
基于候选键的辅助索引就像稠密聚集索引，除了：索引所指的连续的记录值实际上不是顺序储存的<br>
通常情况下辅助索引可以有与聚集索引不同的结构：若聚集索引的搜索键不是候选键，索引只需指向有search key value的第一个记录即可，后续记录可以顺序scan。 但对于搜索键不是候选键的非聚集索引，索引只指向第一个record with each search-key value是不够的, 剩余的相同search key value的记录可以存在于文件任何地方，因为文件是以聚集索引的搜索键排序的<br>
所以，辅助索引必须包含所有记录的指针<br>
我们可以使用额外一层间接的方式来实现基于非候选键的辅助索引： 辅助索引里的指针指向bucket， bucket指针（们）指向文件记录<br>
<img src="https://i.imgur.com/8ZYKi8C.png" alt=""></p>
<ul>
<li>索引的自动创建：
<ul>
<li>大多数据库都会自动为主键创建索引（从而用于检测primary key constraint on new tuple insertion） 若无主键索引，当插入元组时整个relation都要读一下来确保不违反primary-key constraint.<br>
我们无法储存既被聚集索引搜索键排序的又被辅助索引搜索键排序的文件！<br>
因为辅助索引键的顺序和物理键的顺序不同，如果我们按辅助索引键的顺序扫描那么读取一个记录就可能需要从磁盘读一个新的block  这非常慢！</li>
</ul>
</li>
</ul>
<p>上述索引更新方法 插入删除也适用于次级索引。the actions taken are those described for dense indices storing a pointer to every record in the file. 如果一个文件有多个索引，每当文件被修改，所有索引都要更新</p>
<p>辅助索引可以提高 基于非主索引key的query的查询效率，但对于数据库改动会造成很大的额外开支。数据库设计者需根据估计的各种queries频率和改动来决定是否使用一些辅助索引。<br>
所以除非根据估计辅助索引可以带来性能提升，不要使用辅助索引：因为辅助索引是nonclustered index whose key order is different from physical-key order in file. 不同的index所指record可能会在不同的磁盘区块上，会导致额外磁盘IO访问！ 使用不当会效果很糟糕！</p>
<h2 id="btree索引与哈希索引"><a class="markdownIt-Anchor" href="#btree索引与哈希索引"></a> B+tree索引与哈希索引</h2>
<p>index以block为单位进行index  within block用offset</p>
<h3 id="索引类型与基本特点"><a class="markdownIt-Anchor" href="#索引类型与基本特点"></a> <strong>索引类型与基本特点</strong></h3>
<ul>
<li>hash index  通过哈希函数生成hash address to a bucket with possible overflow chain for managing collision cheaper than B+tree if no overflow occurs Access: O(1+#overflow buckets)所以hash索引的最大的特点就是等值查询快，不能进行范围索引。</li>
<li>位图索引适合静态low-cardinality重复数据（属性），can be used as a compressed storage mechanism at the leaf nodes of B±trees for those values that occur very frequently.</li>
<li>B+tree 索引</li>
</ul>
<h3 id="motivation"><a class="markdownIt-Anchor" href="#motivation"></a> Motivation</h3>
<ul>
<li>The primary disadvantage of the index-sequential file organization is that performance degrades as the file grows. To overcome this deficiency, we can use a B±tree index.</li>
</ul>
<h3 id="btree索引特点"><a class="markdownIt-Anchor" href="#btree索引特点"></a> <strong>B+tree索引特点</strong></h3>
<p>普通balanced binary tree tall and thin, b tree fat and short because of the node size! b树索引同时支持范围及等值查询 log (N/2) N path length上届disk block access远远优于log2N普通平衡树 for N records in file 可以大量减少磁盘io次数</p>
<ul>
<li><strong>B tree</strong>: m-way(order m, m fanout, m-1info fields) search tree with additional constraints:  叶子层高度相同 root 2 key  其他节点至少半满ceiling(order/2)来尽量减少高度  B-tree indices are similar to B±tree indices. The primary distinction between the two approaches is that a B-tree eliminates the redundant storage of search-key values:<strong>A B-tree allows search-key values to appear only once.</strong></li>
<li><strong>B+ tree</strong> 更贴近多级索引，是在b树基础上, nonleaf node sparse index 减少disk page access  支持equality search 在叶子层将nonleaf节点key按中序遍历顺序拷贝下来 叶子层包含record ptrs 保持中序遍历顺序建立链表 形成dense &amp; clustered index 密集聚集索引 从而支持range search范围搜索<br>
order=#ptr fields = p    /node<br>
#k,v fields = p-1          /node<br>
(p-1)(key_ptr_size + record_ptr_size) + p(block_ptr_size) &lt;= blocksize=512</li>
<li>若想要插入的位置已满  recursively按中序遍历顺序将中点上移 同时将前驱后继节点分开 始终保持节点半满的要求   删除： 左合并 右合并 来满足半满的限制  split if necessary can propagate to root.     重点：split colasce redistribution merge</li>
<li>bottom-up construction for empty B+tree index: 每一层每个节点使用最小值&amp;最小值指针创建下一层entry until root is created</li>
<li>sort and then bulk-loading(insertion)</li>
</ul>
<h3 id="btree索引的缺点"><a class="markdownIt-Anchor" href="#btree索引的缺点"></a> <strong>B+tree索引的缺点</strong></h3>
<ul>
<li><strong>long term performance degradation:</strong> b+tree索引或file organization的一个缺点是：相邻叶子节点可能存在于磁盘不同区域，最优情况是节点内指针遵循磁盘内容连续的分布，这样顺序扫描叶子结点基本等价于顺序扫描磁盘. 但随着越来越多的插入删除更新操作, sequentiality is increasingly lost, has to wait for disk seeks increasingly often. 这时候需要重建索引restore sequentiality</li>
<li>次级索引的更新问题: 拆分节点可能需要更新建立的次级索引，一个叶节点可能有成百上千条record 每一条都可能在不同地方 Thus a leaf-node split may require tens or even hundreds of I/O operations to update all affected secondary indices, making it a very expensive operation。解决方法： In secondary indices, in place of pointers to the indexed records, we store the values of the primary- index search-key attributes. For example, suppose we have a primary index on theattribute ID of relation instructor; then a secondary index on dept with each department name a list of instructor’s ID values of the corresponding records, instead of storing pointers to the records. locating a record using the sec- ondary index now requires two steps: First we use the secondary index to find the primary-index search-key values, and then we use the primary index to find the corresponding records. The above approach thus greatly reduces the cost of index update due to file reorganization, although it increases the cost of accessing data using a secondary index.</li>
</ul>
<h3 id="btree-file-organization"><a class="markdownIt-Anchor" href="#btree-file-organization"></a> <strong>b+tree file organization</strong></h3>
<p>使用b+tree的思想可以创建b+tree file organization  因为不再储存ptr而是file record leaf node size更大 需要更好的space utilization， 可以通过提高节点容量下限来解决 例如2n/3<br>
B±tree file organizations可以用于储存大的对象如 SQL clobs and blobs, 这些东西通常比disk block大甚至好几个gb. 可以通过拆分成很多个小的record序列的方式使用b+tree file organization储存. The records can be sequentially numbered, or numbered by the byte offset of the record within the large object, and the record number can be used as the search key.</p>
<h3 id="hash-index"><a class="markdownIt-Anchor" href="#hash-index"></a> <strong>Hash Index</strong></h3>
<ul>
<li>
<p>can be used for (strictly speaking) <strong>secondary indices/file organization</strong>,因为</p>
<ul>
<li>A hash index is never needed as a clustering index structure, since, if a file itself is organized by hashing, there is no need for a separate hash index structure on it.</li>
<li>hash file organization provides the same direct access to records that indexing provides, we pretend that a file organized by hashing also has a clustering hash index on it.</li>
</ul>
</li>
<li>
<p><strong>open hashing with overflow chain for buckets</strong>: add chained bucket when need(conflict) usually used in database</p>
</li>
<li>
<p><strong>closed hashing</strong>: the set of buckets is fixed. Deletion is troublesome: usually used in compiler and assembler because there is only lookup and insert.</p>
<ul>
<li>choose other bucket when a bucket is full: Linear probing, quadratic probing</li>
<li>hash function must be choosed wisely otherwise performance degrades.</li>
</ul>
</li>
<li>
<p><strong>static hashing</strong>: linear congruential hash function with fixed #hash buckets  use overflow chain to manage contention</p>
<ul>
<li>problem: performance degrades as database grows in size if no reorganziation of hash structure is done (remap everything &amp; reconstruct corresponding buckets, time-comsuming &amp; massive)</li>
</ul>
</li>
<li>
<p><strong>extendible/dynammic hashing</strong>:</p>
<ul>
<li>copes with changes in database size by splitting and coalescing buckets as the database grows and shrinks. Does so by using extra level of directory that double its size when local depth = global depth during insertion to buckets &amp; bucket overflow (bits are not enough to distinguish the search values of the overflown bucket.). use directory of size <strong>2^k</strong> to store ptrs to hash buckets. 扩容numbering使用gray code. <strong>Directory numbering last k bits 0 - 2^k</strong></li>
<li>hash function: check out last k bits / mod 2^k</li>
<li>global depth = k: Max # of bits needed to tell which bucket an entry belongs to in the directory</li>
<li>local depth: # of bits used in <strong>directory numbering</strong> to determine if an entry belongs to this bucket or not</li>
<li>If a bucket overflow happens, the bucket is split into two. The directory may or may not double, depending on whether the local depth of the overflown bucket was equal to the global depth before split.</li>
<li>After resize, we do not necessarily have new buckets, match existing directory to current buckets. Meaning usually a bucket is pointed by 2 entries or more. A bucket is only pointed by 1 when bucket overflow due to insertion and this situation is after spliting.</li>
<li><a href="https://www.youtube.com/watch?v=TtkN2xRAgv4&amp;list=PLkZdHIQy-AeJjLbvcLO-rp1-eImyJvO2l" target="_blank" rel="noopener">https://www.youtube.com/watch?v=TtkN2xRAgv4&amp;list=PLkZdHIQy-AeJjLbvcLO-rp1-eImyJvO2l</a></li>
<li><a href="http://delab.csd.auth.gr/papers/ExtendibleHashing2017.pdf" target="_blank" rel="noopener">http://delab.csd.auth.gr/papers/ExtendibleHashing2017.pdf</a></li>
<li><a href="http://www.cs.sfu.ca/CourseCentral/354/lxwu/notes/chapter11.pdf" target="_blank" rel="noopener">http://www.cs.sfu.ca/CourseCentral/354/lxwu/notes/chapter11.pdf</a></li>
</ul>
</li>
</ul>
<h2 id="multiple-key-indices"><a class="markdownIt-Anchor" href="#multiple-key-indices"></a> Multiple key indices</h2>
<ul>
<li>in general a search key can have more than one attribute. A search key containing more than one attribute is referred to as a composite search key. The structure of the index is the same as that of any other index, the only difference being that the search key is not a single attribute, but rather is a list of attributes. The search key can be represented as a tuple of values, of the form (a1, . . . , an), where the indexed attributes are A1, . . . , An. The ordering of search-key values is the lexicographic ordering.</li>
<li>As an example. Consider an index on takes relation on composite search key(courseid,semester,year). This index is useful in finding all students who have registered for a particular course in a particular semester/year. An ordered index on multiple-key can be also used to answer some other queries efficiently.</li>
</ul>

      
      <!-- reward -->
      
    </div>
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Database/">Database</a></li></ul>


    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-Operating System - Persistence" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/04/11/Operating System - Persistence/"
    >Operating System - Persistence</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2019/04/11/Operating System - Persistence/" class="article-date">
  <time datetime="2019-04-11T01:51:23.000Z" itemprop="datePublished">2019-04-10</time>
</a>
      
      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h1 id="cs537-operating-system-summary-part-2-persistence"><a class="markdownIt-Anchor" href="#cs537-operating-system-summary-part-2-persistence"></a> <strong>CS537 - Operating System Summary Part 2 Persistence</strong></h1>
<h1 id="persistence"><a class="markdownIt-Anchor" href="#persistence"></a> Persistence</h1>
<h2 id="io-device-and-communication-protocol"><a class="markdownIt-Anchor" href="#io-device-and-communication-protocol"></a> IO Device and Communication Protocol</h2>
<h3 id="motivation"><a class="markdownIt-Anchor" href="#motivation"></a> Motivation</h3>
<ul>
<li>we want <strong>hardware</strong> that will let us plug in different devices</li>
<li>we want <strong>OS</strong> that can interact with different combinations of HW</li>
</ul>
<h3 id="hardware-support-for-io-device-in-system-architecture"><a class="markdownIt-Anchor" href="#hardware-support-for-io-device-in-system-architecture"></a> Hardware support for IO device in system architecture</h3>
<ul>
<li>different buses have different speed, costs, size/volume of devices that need to be connected with</li>
<li>high speed buses are very expensive to manufacture</li>
<li>Hierarchical buses are a good solution<br>
<img src="https://i.imgur.com/8mMkV75.png" alt=""></li>
<li>proprietary bus: <strong>60GB/s</strong> on a 4-core system</li>
<li>General I/O bus: PCI…etc. <strong>1-4GB/s</strong></li>
<li>Peripheral I/O bus: disk devices, SCSI, SATA, USB, <strong>100MB/s</strong></li>
<li>Modern system hierarcical uses more specialized chipset and p2p interconnects for better performance. Example Z270 Chipset:<br>
<img src="https://i.imgur.com/eXgCTWC.png" alt=""></li>
<li>Dedicated Graphics bus: facilitate graphics intensive applications such as gaming, interactive web browser, and photo manipulations.</li>
<li>Higher performance devices connected via PCIe, NVMe persistent storage.</li>
<li>lower performance devices connected via USB, eSATA: modern sata standard, SSD: higher speed storage</li>
</ul>
<h3 id="oss-view-to-device-a-canonical-device"><a class="markdownIt-Anchor" href="#oss-view-to-device-a-canonical-device"></a> OS’s view to Device &amp; a canonical device</h3>
<p><img src="https://i.imgur.com/DtbaXIO.png" alt=""></p>
<ul>
<li>Interface: where OS reads/writes to, allow system to control its operations</li>
<li>Internal Structure (Varies depends on different devices &amp; manufacture): microcontroller, extra memory, special-purpose chips…connection to cache/disk drives, graphics cards…</li>
</ul>
<h3 id="a-canonical-protocol-os-writing-to-device"><a class="markdownIt-Anchor" href="#a-canonical-protocol-os-writing-to-device"></a> A canonical protocol OS writing to device</h3>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (STATUS == BUSY)</span><br><span class="line">    ; <span class="comment">// spin</span></span><br><span class="line">Write data to DATA <span class="keyword">register</span></span><br><span class="line">Write command to COMMAND <span class="keyword">register</span></span><br><span class="line"><span class="keyword">while</span> (STATUS == BUSY)</span><br><span class="line">    ; <span class="comment">// spin</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Simple polling protocol works but is inefficient sometimes:</li>
</ul>
<table>
<thead>
<tr>
<th>CPU</th>
<th>sys_write A</th>
<th>waits</th>
<th>copy Data &amp; Command to A</th>
<th>wait(for command to be executed)</th>
<th>B</th>
</tr>
</thead>
<tbody>
<tr>
<td>DISK</td>
<td>busy</td>
<td>busy</td>
<td></td>
<td>busy</td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>The policy of polling itself reduces CPU utilization when job processing time can be long</li>
<li>Using interrupt instead<br>
<img src="https://i.imgur.com/lgYgLBu.png" alt=""></li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (STATUS == BUSY) <span class="comment">// 1</span></span><br><span class="line">    wait <span class="keyword">for</span> interrupt;</span><br><span class="line">Write data to DATA <span class="keyword">register</span> <span class="comment">// 2</span></span><br><span class="line">Write command to COMMAND <span class="keyword">register</span> <span class="comment">// 3</span></span><br><span class="line"><span class="keyword">while</span> (STATUS == BUSY) <span class="comment">// 4</span></span><br><span class="line">    wait <span class="keyword">for</span> interrupt;</span><br></pre></td></tr></table></figure>
<ul>
<li>Interrupt improves CPU utilization in this case.</li>
<li>Summary: Polling/Interrupt is a tradeoff.
<ul>
<li>Faster devices:
<ul>
<li>better to spin(poll) and keep waiting than taking interrupt overhead</li>
</ul>
</li>
<li>Unknown device speed:
<ul>
<li>Hybrid approach (spin then use interrupts)</li>
</ul>
</li>
<li>Better not to use interrupts when Floods of interrupts arrive:
<ul>
<li>Example: floods of requests to the NIC device of a webserver</li>
<li>can lead to livelock (always handling interrupts rather than doing actual works - user level processes to service some requests)</li>
<li>Better to ignore interrupts and use some polling to make some progress handling them and control what is happening in the system</li>
</ul>
</li>
<li>Other improvement
<ul>
<li>Interrupt coalescing (batch together several interrupts into a single one): This reduces overhead of interrupts processing</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="data-transfer-costs-more-efficient-data-movement-with-dma"><a class="markdownIt-Anchor" href="#data-transfer-costs-more-efficient-data-movement-with-dma"></a> Data Transfer Costs &amp; More efficient data movement with DMA</h3>
<ul>
<li>Programmed I/O:
<ul>
<li>Programmed IO(PIO) is a method of transferring data between the CPU and a peripheral, such as a network adapter or an ATA storage device. Each data item transfer is initiated by an instruction in the program, involving the CPU for every transaction.</li>
<li>when using PIO to transfer a large chunk of data to a device. CPU is overburdened with trivial tasks of copying data from memory to device explicitly one word at a time. Poor CPU utilization!<br>
<img src="https://i.imgur.com/NxnvlJU.png" alt=""></li>
<li><strong>Solution</strong>: Direct Memory Access (DMA)
<ul>
<li>CPU let a <strong>special purpose device “DMA engine”</strong> to copy data on behalf of it.</li>
<li>OS would program the DMA engine by telling it where the data lives inmemory, how much data to copy, and which device to send it to</li>
<li>CPU is thus free and OS can do something else: this improves both CPU and disk utilization, and improves the time of copying data into the <strong>data register</strong> in a device. (not command register because commands are usually very small in size).<br>
<img src="https://i.imgur.com/by6oZkv.png" alt=""><br>
<img src="https://i.imgur.com/XuKa5ys.png" alt=""></li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (STATUS == BUSY) <span class="comment">// 1</span></span><br><span class="line">    ;</span><br><span class="line">Write command to COMMAND <span class="keyword">register</span> <span class="comment">// no step 2 anymore, 3</span></span><br><span class="line"><span class="keyword">while</span> (STATUS == BUSY) <span class="comment">// 4</span></span><br><span class="line">    ;</span><br></pre></td></tr></table></figure>
<h3 id="methods-of-device-interactions"><a class="markdownIt-Anchor" href="#methods-of-device-interactions"></a> Methods of Device interactions</h3>
<ul>
<li>How OS communicates with Device? (Doesn’t matter much, both are used)
<ul>
<li>Special instructions
<ul>
<li>each device has a port</li>
<li>in/out instructions (x86) communicate with device</li>
</ul>
</li>
<li>Memory-Mapped I/O
<ul>
<li>H/W maps registers into address space
<ul>
<li>example: eax ebx cpu register</li>
</ul>
</li>
<li>loads/stores of mapped register sent to device
<ul>
<li>load/store eax/ebx</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="device-drivers"><a class="markdownIt-Anchor" href="#device-drivers"></a> Device Drivers</h3>
<p><img src="https://i.imgur.com/tYLHgXh.png" alt=""></p>
<ul>
<li>Motivation: we want to keep device general and neutral as much as possible and hide the details of device interactions with OS subsystems.</li>
<li>Device driver: At the lowest level, a piece of software in the OS must know in detail how a device works. Any specifics of device interaction are encapsulated within.</li>
<li>Significance: Writing device driver for each device helps us abstract hardware and avoid writing different OS for different H/W combinations.</li>
<li>Example: we want a file system that works with SSD, USB, SATA</li>
<li>Problem: Many devices in a system! Each has its own protocol!
<ul>
<li>Drivers are 70% of Linux Source code and major causes of OS crashes.</li>
</ul>
</li>
</ul>
<h2 id="hard-disks"><a class="markdownIt-Anchor" href="#hard-disks"></a> Hard Disks</h2>
<h3 id="hard-disk-interface-and-its-view-to-osuser"><a class="markdownIt-Anchor" href="#hard-disk-interface-and-its-view-to-osuser"></a> Hard Disk Interface and its view to OS/User</h3>
<ul>
<li>The abstraction to OS/User</li>
</ul>
<table>
<thead>
<tr>
<th>sector 0</th>
</tr>
</thead>
<tbody>
<tr>
<td>sector 1</td>
</tr>
<tr>
<td>sector 2</td>
</tr>
<tr>
<td>…</td>
</tr>
</tbody>
</table>
<ul>
<li>Disk has a sector-addressable address space</li>
<li>Appears as an array of sectors</li>
<li>Similar to Paging, sectors are typically 512 bytes/sector</li>
<li>Main operations: <strong>atomic</strong> read/write to a particular sector. When power failure, can have guranntee that r/w to a sector is done or not.</li>
<li>Mechanical and slow</li>
</ul>
<h3 id="internals-performance-measure"><a class="markdownIt-Anchor" href="#internals-performance-measure"></a> Internals &amp; Performance Measure</h3>
<img src="https://i.imgur.com/eMcYqyA.png" width="250">
<img src="https://i.imgur.com/zwN9ySC.png" width="250">
<ul>
<li>Platter: a circular/disk shape entity with magnetic foam on both sides</li>
<li>Spindle: connected with motor to make platter spin.</li>
<li>RPM(Rotations Per Minutes): tells the rate of platter spinning. 10000RMP = 1 rotation/6ms<br>
<img src="https://i.imgur.com/b8jsBT7.png" alt=""></li>
<li>Surface: one side of a platter. <strong>Both sides</strong> can be written/read.</li>
<li>tracks: a ring of certain inner &amp; outer radius, surface is divided into different tracks. Tracks are divided into numbered sectors. Each track in above graph has 8 sectors.</li>
<li>cylinder: stack of tracks across platters. This idea is useful when we want to do uniform operations on the same track of each surfaces.</li>
<li>Arm seeks over desired tracks, platter rotates! <strong>A head per surface for R/W!</strong></li>
<li>Reading/Writing data from disks<br>
<img src="https://i.imgur.com/gP9kn0E.png" width="250">
<ul>
<li>Rotation Delay: the waiting time for the platter to rotate till the head is positioned at right sector on the single track. On average R/2.<br>
<img src="https://i.imgur.com/uYVVvU7.png" width="250"></li>
<li>Seek Time: the waiting time for disk arm to be positioned on the right track.</li>
<li>Transfer Time: actual time data is either read from or written to the surface.</li>
<li>Overall Time to Read/write
<ul>
<li><strong>Time_IO = seek + rotation + transfer</strong></li>
<li>IO rate (mainly used for comparing drives performance):
<ul>
<li><strong>IO_rate = size to transfer / Time_IO</strong></li>
</ul>
</li>
</ul>
</li>
<li>Summary
<ul>
<li>Seek cost (major): Function of cylinder distance. Not purely linear cost. Must accelerate, coast, decelerate, settle. Settling alone can take 0.5 - 2 ms. Entire seeks often takes 4 - 10 ms. <strong>Average seek = 1/3 of max seek</strong>.</li>
<li>Rotate cost (major): Depends on rotations per minute (RPM). 7200 RPM is common, 15000 RPM is high end. <strong>Average rotation = 1/2 of rotation delay</strong></li>
<li>Transfer time: pretty fast. depends on RPM and sector density. 100+ MB/s is typical for maximum transfer rate.</li>
</ul>
</li>
</ul>
</li>
<li>IO time calculation Example
<ul>
<li><img src="https://i.imgur.com/Xf8oBgw.png" alt=""> Find  the time for 4KB random read for Cheetah (on average).</li>
<li>Solution:
<ul>
<li>Tseek = 4ms</li>
<li>Trotate = 15000R/60s = 15000R/60000ms = 0.25R/ms = 4 R/ms = 2R/ms on average</li>
<li>Ttransfer = 4KB/(125MB/s) = 4/125 ms</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="workload-performance"><a class="markdownIt-Anchor" href="#workload-performance"></a> Workload Performance</h3>
<ul>
<li>Question: How does two kinds of workload affect performance?
<ul>
<li>Sequential: reads a large number of sectors consecutively from the disk, without jumping around.</li>
<li>Random: issues small (e.g., 4KB) reads to random locations on the disk.</li>
<li>Example:<br>
<img src="https://i.imgur.com/WdGY378.png" alt="">
<ul>
<li>What is throughput (IO rate) for sequential workload and random workload for Cheetah?
<ul>
<li>Sequential: 4ms seek + 2ms rotate + 1s transfer = 1.006s This means effective throughput is almost equal to 125MB/s</li>
<li>Random: IO time = 6ms, 4KB/6ms &lt;&lt;&lt; 125MB/s <strong>much lower throughput than sequential access</strong>.</li>
</ul>
</li>
<li>Conclusion: When at all possible, transfer data to and from disks in a sequential manner. If sequential is not possible, at least think about transferring data in large chunks: the bigger, the better. If I/O is done in little random pieces, I/O performance will suffer dramatically.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="some-techniques-manufacturers-use-to-improve-performance-of-disks"><a class="markdownIt-Anchor" href="#some-techniques-manufacturers-use-to-improve-performance-of-disks"></a> Some techniques manufacturers use to improve performance of disks</h3>
<h4 id="track-skew-skewed-layout"><a class="markdownIt-Anchor" href="#track-skew-skewed-layout"></a> Track Skew (skewed layout):</h4>
<ul>
<li>How should sector number be laid out so that we can continue reading sequentially?</li>
<li>
<img src="https://i.imgur.com/1aGAVKw.png" width="250">
</li>
<li>Goal: We want low overhead and seamless transformation from 15 to 16 when we want to read 16 after 15.</li>
<li>Solution with track skew method:
<ul>
<li>idea: <strong>overlapping seek and rotation</strong></li>
<li>
<img src="https://i.imgur.com/ravLbuh.png" width="250">
</li>
<li>By the time the platter rotate, the head already place at position of 16.</li>
</ul>
</li>
</ul>
<h4 id="zones"><a class="markdownIt-Anchor" href="#zones"></a> Zones</h4>
<ul>
<li>Idea: outer tracks have more area available than inner tracks and thus can store more data. But we fixed sector size. So we can have <strong>non-uniform division</strong>: more sectors on outer tracks to utilize that space.</li>
<li>
<img src="https://i.imgur.com/bULnWS6.png" width="250">
</li>
<li>Zone bit recording: call collection of sectors as zone.</li>
</ul>
<h4 id="cache-inside-drive"><a class="markdownIt-Anchor" href="#cache-inside-drive"></a> Cache inside drive</h4>
<ul>
<li>Idea: Drives may cache both reads and writes. (In addition to OS cache). Cache is not big (2MB-16MB)</li>
<li>Advantages of caching in drive for read:
<ul>
<li>Store recently read sectors. Fetch it from cache.</li>
<li>Read-ahead: read contents of entire track into cache. predictively facilitates sequential workload.</li>
</ul>
</li>
<li>Advantages &amp; Disadvantages of caching in drive for write:
<ul>
<li>Immediate reporting: CPU doesn’t need to wait for write to finish. Can acknowledge a write even before the write actually makes it to the magnetic medieum.</li>
<li>Danger: cached data can be lost on power failure.</li>
</ul>
</li>
<li>Other advantages: multiple outstanding requests
<ul>
<li>Tagged command queuing: Disk can reorder/schedule requests for better performance.</li>
</ul>
</li>
</ul>
<h2 id="io-scheduler-scheduling-policies-and-tradeoff"><a class="markdownIt-Anchor" href="#io-scheduler-scheduling-policies-and-tradeoff"></a> IO scheduler, scheduling policies and tradeoff</h2>
<h3 id="motivation-2"><a class="markdownIt-Anchor" href="#motivation-2"></a> Motivation</h3>
<p>Given a stream of I/O requests, in what <strong>order</strong> should they be served?</p>
<ul>
<li>Example timeline: P1Read___P2Read___P3write__</li>
</ul>
<h3 id="goal"><a class="markdownIt-Anchor" href="#goal"></a> Goal</h3>
<ul>
<li>OS should dispatch requests in certain order to the shared storage device disk.</li>
</ul>
<h3 id="key-problem"><a class="markdownIt-Anchor" href="#key-problem"></a> Key Problem</h3>
<ul>
<li>Much different than CPU scheduling, Position of disk head relative to request position matters more than length of job</li>
<li>Example:
<ul>
<li>FCFS/FIFO: Assume seek+rotate = 10 ms for random request, How long (roughly) does the below workload take? Requests are given in sector numbers:
<ul>
<li>300001, 700001, 300002, 700002, 300003, 700003  = 60ms because each time we need to seek and rotate</li>
<li>300001, 300002, 300003, 700001, 700002, 700003  = 20ms 2 sequential pattern<br>
-This shows why IO scheduling is important.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="crux"><a class="markdownIt-Anchor" href="#crux"></a> Crux</h3>
<ul>
<li>we want to implement an algorithm that <strong>more closely approximates SJF by taking both seek and rotation into account</strong>.</li>
</ul>
<h3 id="sstf-shortest-seek-time-first"><a class="markdownIt-Anchor" href="#sstf-shortest-seek-time-first"></a> SSTF (Shortest SEEK Time First)</h3>
<ul>
<li>Strategy always choose request that requires <strong>least seek time</strong> (time for seeking and rotating)</li>
<li>Greedy algorithm (looks for local optimal)</li>
<li>Implementation in OS: use sector number as a substitite, order by nearest sector number first, try to issue requests that are closely together.</li>
<li>Disadvantages: starvation!
<ul>
<li>ex. 30001,30002,…,70001(starved)</li>
<li>avoid starvation:
<ul>
<li>Scan/Elevator Algorithm: Sweep back and forth, from one end of disk other, serving requests as pass that cylinder; Sorts by cylinder number(order of tracks); ignores rotation delays;
<ul>
<li>
<img src="https://i.imgur.com/ZnJPy5F.png" width="150/">
</li>
<li>
<p>Example: input 101 201 102 301 203; output_order 101 201 301 203 102 (first bit track#)</p>
</li>
<li>
<p>This ensure for example the request at outermost track does not starve!</p>
</li>
<li>
<p>This is a “Best effort” work done on OS side -&gt; logically like sorting</p>
</li>
</ul>
</li>
<li>C-SCAN(Circular Scan Algorithm): Only sweep in one direction. 1-&gt;2-&gt;3 reset 1-&gt;2-&gt;3
<ul>
<li>This is more fair than SCAN because in pure backand-forth SCAN middle one 2 is treated more times on average than peripheral 1 and 3.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Problem: SCAN and SSTF  do not actually adhere as closely to the principle of SJF as they could. In particular, they ignore rotation.</li>
</ul>
<h3 id="sptfshortest-positioning-time-first"><a class="markdownIt-Anchor" href="#sptfshortest-positioning-time-first"></a> SPTF(Shortest Positioning Time First)</h3>
<img src="https://i.imgur.com/gAfQtUL.png" width="200">
<ul>
<li>
<p>Example: we get 2 requests one to 16, one to 8. 16 gets shorter seek but longer rotate, 8 has shorter rotation delay and longer seek. If seek time is higher than rotational delay in the disk in this example, then SSTF related policies are fine = we want to minimize seek time. So go to 16. Otherwise 8 is a better choice because we need to minimize rotation delay to have better performance.</p>
</li>
<li>
<p>This algorithm is complex, for simplicity, many OS only implements shortest seek time first</p>
</li>
</ul>
<h3 id="where-should-io-scheduler-go-os-vs-disk"><a class="markdownIt-Anchor" href="#where-should-io-scheduler-go-os-vs-disk"></a> Where should IO scheduler go? OS vs Disk.</h3>
<ul>
<li>Disk: it knows disk geometry much better but fixed by hardware, can be hard to update firmware or the scheduler.</li>
<li>OS: knows processes that are requesting, so we can do some weighted or fair sharing across processes. Easy to update scheduler software. Can have multiple disks scheudler and change scheduler based on workload pattern.</li>
<li>Typical state of the art approach: has a simple scheduler in OS side that sorts the requests based on sector locations, then has one more complex scheduler on disk side to take account of seek time and rotation time in order to minimize things further. But typically OS sends multiple requests to disk, so disk scheduelr can do some reordering between them.</li>
</ul>
<h3 id="how-busy-should-we-keep-the-disk"><a class="markdownIt-Anchor" href="#how-busy-should-we-keep-the-disk"></a> How busy should we keep the disk?</h3>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//This is a procedure that reads from a file </span></span><br><span class="line"><span class="comment">//descriptor 1KB at a time and process that.</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reader</span><span class="params">(<span class="keyword">int</span> fd)</span> </span>&#123;	</span><br><span class="line">    <span class="keyword">char</span> buf[<span class="number">1024</span>];	</span><br><span class="line">    <span class="keyword">int</span>	rv;	</span><br><span class="line">    <span class="keyword">while</span>((rv = read(buf,fd)) != <span class="number">0</span>) &#123;	</span><br><span class="line">	 	    assert(rv);	</span><br><span class="line">	 	    <span class="comment">// takes short time, e.g., 1ms	</span></span><br><span class="line">	 	    process(buf, rv);	</span><br><span class="line">    &#125;	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<img src="https://i.imgur.com/ThnSHG3.png" width="150">
<br>
<ul>
<li>
<p>assume 2 processes calling read() with C-SCAN,consider workload pattern: 100 101 200 201 102 103 202. This pattern is possible because there is maybe 1 ms gap between 101 and 102 so that other threads(processes) can interrupt. This is very inefficient. Should the OS always submit requests waiting present on the queue or should wait to see if other requests arrive (BE work-conserving and let disk be idle at some point so that we can make more efficient progress in the future)?</p>
</li>
<li>
<p>Work conservation (a trick used by linux scheduler)</p>
<ul>
<li>not work conserving/violating work-conservation: might wait for a while to merge or get a better sequence of requests</li>
<li>Work conserving schedulers always try to do work if there’s work to be done <strong>(always run a request if resource is free)</strong>
<ul>
<li>Sometimes, it’s better to wait instead if system anticipates another request will arrive.</li>
<li>example: I/O Merging. OS coalesces several IO requests into ONE. Less IO overhead.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="raid"><a class="markdownIt-Anchor" href="#raid"></a> RAID</h2>
<h3 id="motivation-3"><a class="markdownIt-Anchor" href="#motivation-3"></a> Motivation</h3>
<ul>
<li>Typical scenario</li>
</ul>
<table>
<thead>
<tr>
<th>APP</th>
</tr>
</thead>
<tbody>
<tr>
<td>OS FS</td>
</tr>
<tr>
<td>Storage Devices:most file systems work with one disk</td>
</tr>
</tbody>
</table>
<ul>
<li>
<p>sometimes we need many disks for reasons:</p>
<ul>
<li>Capacity</li>
<li>Performance</li>
<li>Reliability</li>
</ul>
</li>
<li>
<p>Solution1 JBOD - Just a bunch of disks<br>
<img src="https://i.imgur.com/0XJooqP.png" alt=""></p>
<ul>
<li>Applications store data on different FS, ex. critical data that app decides to replicate</li>
<li>Downsides: need to know multiple devices, need to be rewritten, not deployable</li>
</ul>
</li>
<li>
<p>Solution2 RAID - Redundant Array of Inexpensive (Independent) Disks<br>
<img src="https://i.imgur.com/A4kPGQM.png" alt=""></p>
<ul>
<li>abstract multiple physical disks into one logical disk to OS</li>
<li>Advantages: transparent to apps, deployable Improved capacity, performance, and reliability!</li>
</ul>
</li>
</ul>
<h3 id="fault-model-of-raid"><a class="markdownIt-Anchor" href="#fault-model-of-raid"></a> Fault Model of RAID</h3>
<ul>
<li>Simple: Fail-stop model</li>
<li>Either works correctly or fails entirely</li>
<li>System can easily detect which part is not working</li>
<li>No silent failures, No corruptions, …etc…</li>
</ul>
<h3 id="general-strategy-of-raid-mapping"><a class="markdownIt-Anchor" href="#general-strategy-of-raid-mapping"></a> General strategy of RAID - Mapping</h3>
<p><img src="https://i.imgur.com/djO9nvL.png" alt=""></p>
<ul>
<li>Mapping blocks: build fast, large disk from smaller ones</li>
<li>Very similar to VM: go from virtual space to physical space by looking up TLB and pagetable</li>
<li>VM mapping is dynamic - mapping can change for example, when memory is free and is reallocated.</li>
<li>RAID mapping is static - translation is simple static calculation: no lookup</li>
</ul>
<h3 id="general-strategy-of-raid-redundancy"><a class="markdownIt-Anchor" href="#general-strategy-of-raid-redundancy"></a> General strategy of RAID - Redundancy</h3>
<p><img src="https://i.imgur.com/hrQi5Rw.png" alt=""></p>
<ul>
<li>Add even more disks for reliability</li>
<li>More redundancy == More fault tolerance</li>
<li>This is a tradeoff
<ul>
<li>Redundancy improves reliability (and maybe performance)</li>
<li>Deduplication improves space efficiency</li>
</ul>
</li>
</ul>
<h3 id="raid-analysis"><a class="markdownIt-Anchor" href="#raid-analysis"></a> RAID analysis</h3>
<ul>
<li>RAID level: different levels</li>
<li>Workload: types of reads/writes issued by app</li>
<li>Metric: capacity, reliability, performance</li>
<li>Analysis mode: given Workload, Raid level, determine/calculate Metric</li>
</ul>
<h3 id="raid-levels"><a class="markdownIt-Anchor" href="#raid-levels"></a> RAID levels</h3>
<ol start="0">
<li>Stripping</li>
<li>Mirroring</li>
<li>Parity</li>
<li>Rotated parity<br>
We will not discuss 2, 3, 6 in this class.</li>
</ol>
<h3 id="workload"><a class="markdownIt-Anchor" href="#workload"></a> Workload</h3>
<p><img src="https://i.imgur.com/x9e3J0f.png" alt=""></p>
<h3 id="metrics"><a class="markdownIt-Anchor" href="#metrics"></a> Metrics</h3>
<p><img src="https://i.imgur.com/hfU880R.png" alt=""></p>

      
      <!-- reward -->
      
    </div>
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/OS/">OS</a></li></ul>


    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-Computer Networking" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/04/09/Computer Networking/"
    >Computer Networking</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2019/04/09/Computer Networking/" class="article-date">
  <time datetime="2019-04-09T14:52:41.000Z" itemprop="datePublished">2019-04-09</time>
</a>
      
      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <p><img src="/network/1.png" alt=""><br>
<img src="/network/2.png" alt=""><br>
<img src="/network/3.png" alt=""><br>
<img src="/network/4.png" alt=""><br>
<img src="/network/5.png" alt=""><br>
<img src="/network/6.png" alt=""><br>
<img src="/network/7.png" alt=""><br>
<img src="/network/8.png" alt=""><br>
<img src="/network/9.png" alt=""><br>
<img src="/network/10.png" alt=""><br>
<img src="/network/11.png" alt=""><br>
<img src="/network/12.png" alt=""><br>
<img src="/network/13.png" alt=""><br>
<img src="/network/14.png" alt=""><br>
<img src="/network/15.png" alt=""><br>
<img src="/network/16.png" alt=""><br>
<img src="/network/17.png" alt=""><br>
<img src="/network/18.png" alt=""><br>
<img src="/network/19.png" alt=""><br>
<img src="/network/20.png" alt=""><br>
<img src="/network/21.png" alt=""><br>
<img src="/network/22.png" alt=""><br>
<img src="/network/23.png" alt=""><br>
<img src="/network/24.png" alt=""><br>
<img src="/network/25.png" alt=""><br>
<img src="/network/26.png" alt=""><br>
<img src="/network/27.png" alt=""><br>
<img src="/network/28.png" alt=""><br>
<img src="/network/29.png" alt=""><br>
<img src="/network/30.png" alt=""><br>
<img src="/network/31.png" alt=""><br>
<img src="/network/32.png" alt=""><br>
<img src="/network/33.png" alt=""><br>
<img src="/network/34.png" alt=""><br>
<img src="/network/35.png" alt=""><br>
<img src="/network/36.png" alt=""><br>
<img src="/network/37.png" alt=""></p>

      
      <!-- reward -->
      
    </div>
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Computer-Network/">Computer Network</a></li></ul>


    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-Operating System - Concurrency" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/04/03/Operating System - Concurrency/"
    >Operating System - Concurrency</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2019/04/03/Operating System - Concurrency/" class="article-date">
  <time datetime="2019-04-03T01:06:41.000Z" itemprop="datePublished">2019-04-02</time>
</a>
      
      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h1 id="cs537-operating-system-summary-part-2-concurrency"><a class="markdownIt-Anchor" href="#cs537-operating-system-summary-part-2-concurrency"></a> <strong>CS537 - Operating System Summary Part 2 Concurrency</strong></h1>
<h1 id="concurrency"><a class="markdownIt-Anchor" href="#concurrency"></a> Concurrency</h1>
<h2 id="thread"><a class="markdownIt-Anchor" href="#thread"></a> Thread</h2>
<h3 id="processes-vs-thread"><a class="markdownIt-Anchor" href="#processes-vs-thread"></a> Processes vs Thread</h3>
<ul>
<li>
<p>Process</p>
<ul>
<li>Example: Chrome (process per tab)</li>
<li>Communicate via pipe() or similar</li>
<li>Pros: Don’t need new abstractions; good for security</li>
<li>Cons:
<ul>
<li>Cumbersome programming</li>
<li>High communication overheads</li>
<li>Expensive context switching</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Thread</p>
<ul>
<li>Multiple threads of same process share an address space</li>
<li>Divide large task across several cooperative threads</li>
<li>Communicate through shared address space</li>
<li>Shared: page directories, page tables, code segment</li>
<li>Not Shared: instruction pointer, stack</li>
</ul>
</li>
<li>
<p>Multiple threads within a single process share:</p>
<ul>
<li>Process ID (PID)</li>
<li>Address space: Code (instructions), Most data (heap)</li>
<li>Open file descriptors</li>
<li>Current working directory</li>
<li>User and group id</li>
</ul>
</li>
<li>
<p>Each thread has its own</p>
<ul>
<li>Thread ID (TID)</li>
<li>Set of registers, including Program counter and Stack pointer</li>
<li>Stack for local variables and return addresses (in same address space)</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/3DmuMbX.png" alt=""></p>
<h3 id="common-programming-models"><a class="markdownIt-Anchor" href="#common-programming-models"></a> Common Programming Models</h3>
<ul>
<li>
<p>Producer/consumer</p>
<ul>
<li>Multiple producer threads create data (or work) that is handled by one of the multiple consumer threads</li>
</ul>
</li>
<li>
<p>Pipeline</p>
<ul>
<li>Task is divided into series of subtasks, each of which is handled in series by a different thread</li>
</ul>
</li>
<li>
<p>Defer work with background thread</p>
<ul>
<li>One thread performs non-critical work in the background (when CPU idle)</li>
</ul>
</li>
</ul>
<h3 id="user-level-threads-many-to-one"><a class="markdownIt-Anchor" href="#user-level-threads-many-to-one"></a> User-level threads: Many-to-one</h3>
<ul>
<li>
<p>Idea</p>
<ul>
<li>Implemented by user-level runtime libraries</li>
<li>Create, schedule, synchronize threads at user-level</li>
<li>OS is not aware of user-level threads</li>
<li>OS thinks each process contains only a single thread of control</li>
</ul>
</li>
<li>
<p>Advantages</p>
<ul>
<li>Does not require OS support; Portable</li>
<li>Can tune scheduling policy to meet application demands</li>
<li>Lower overhead thread operations since no system call</li>
</ul>
</li>
<li>
<p>Disadvantages</p>
<ul>
<li>Cannot leverage multiprocessors</li>
<li>Entire process blocks when one thread blocks</li>
</ul>
</li>
</ul>
<img src="https://i.imgur.com/usa8UOF.png" width="50%" style="margin:auto; display: block;">
<h3 id="kernel-level-threads-one-to-one"><a class="markdownIt-Anchor" href="#kernel-level-threads-one-to-one"></a> Kernel-level threads: One-to-one</h3>
<ul>
<li>
<p>Idea</p>
<ul>
<li>OS provides each user-level thread with a kernel thread</li>
<li>Each kernel thread scheduled independently</li>
<li>Thread operations (creation, scheduling, synchronization) performed by OS</li>
</ul>
</li>
<li>
<p>Advantages</p>
<ul>
<li>Each kernel-level thread can run in parallel on a multiprocessor</li>
<li>When one thread blocks, other threads from process can be scheduled</li>
</ul>
</li>
<li>
<p>Disadvantages</p>
<ul>
<li>Higher overhead for thread operations</li>
<li>OS must scale well with increasing number of threads</li>
</ul>
</li>
</ul>
 <img src="https://i.imgur.com/NVLmaXh.png" width="50%" style="margin:auto; display: block;">
<h3 id="thread-schedule-examples"><a class="markdownIt-Anchor" href="#thread-schedule-examples"></a> Thread Schedule Examples</h3>
<ul>
<li>
<p>Assume <code>M[0x123]</code> = 100 initially, and we want to increment it by 1 twice</p>
</li>
<li>
<p>Example 1</p>
<table>
<thead>
<tr>
<th>Thread 1</th>
<th>Thread 2</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>mov 0x123, %eax</code> =&gt; <code>%eax</code> = 100<br> <code>add $0x1, %eax</code> =&gt; <code>%eax</code> = 101<br> <code>mov %eax, 0x123</code> =&gt;<code>M[0x123]</code> = 101<br><br><br><br></td>
<td><br><br><br><code>mov 0x123, %eax</code> =&gt; <code>%eax</code> = 101<br> <code>add $0x1, %eax</code> =&gt; <code>%eax</code> = 102<br> <code>mov %eax, 0x123</code> =&gt;<code>M[0x123]</code> = 102</td>
</tr>
</tbody>
</table>
</li>
<li>
<p>Example 2</p>
<table>
<thead>
<tr>
<th>Thread 1</th>
<th>Thread 2</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>mov 0x123, %eax</code> =&gt; <code>%eax</code> = 100<br><br><br><br> <code>add $0x1, %eax</code> =&gt; <code>%eax</code> = 101<br> <code>mov %eax, 0x123</code> =&gt;<code>M[0x123]</code> = 101<br></td>
<td><br><code>mov 0x123, %eax</code> =&gt; <code>%eax</code> = 100<br> <code>add $0x1, %eax</code> =&gt; <code>%eax</code> = 101<br> <code>mov %eax, 0x123</code> =&gt;<code>M[0x123]</code> = 101<br><br><br></td>
</tr>
</tbody>
</table>
</li>
</ul>
<h3 id="non-determinism"><a class="markdownIt-Anchor" href="#non-determinism"></a> Non-Determinism</h3>
<ul>
<li>
<p>Concurrency leads to non-deterministic results</p>
<ul>
<li>Different results even with same inputs</li>
<li>race conditions</li>
</ul>
</li>
<li>
<p>Whether bug manifests depends on CPU schedule!</p>
</li>
<li>
<p>How to program: imagine scheduler is malicious?!</p>
</li>
</ul>
<h3 id="what-do-we-want"><a class="markdownIt-Anchor" href="#what-do-we-want"></a> What do we want?</h3>
<ul>
<li>
<p>Want 3 instructions to execute as an uninterruptable group</p>
</li>
<li>
<p>That is, we want them to be atomic</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mov 0x123, %eax </span><br><span class="line">add $0x1, %eax  </span><br><span class="line">mov %eax, 0x123</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>More general: Need mutual exclusion for critical sections</p>
<ul>
<li>if thread A is in critical section C, thread B isn’t</li>
<li>(okay if other threads do unrelated work)</li>
</ul>
</li>
</ul>
<h3 id="synchronization"><a class="markdownIt-Anchor" href="#synchronization"></a> Synchronization</h3>
<ul>
<li>Build higher-level synchronization primitives in OS</li>
<li>Operations that ensure correct ordering of instructions across threads</li>
<li>Use help from hardware</li>
</ul>
<h3 id="concurrency-objective"><a class="markdownIt-Anchor" href="#concurrency-objective"></a> Concurrency Objective</h3>
<ul>
<li>
<p>Mutual exclusion (e.g., A and B don’t run at same time)</p>
<ul>
<li>solved with locks</li>
</ul>
</li>
<li>
<p>Ordering (e.g., B runs after A does something)</p>
<ul>
<li>solved with condition variables and semaphores</li>
</ul>
</li>
</ul>
<h3 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h3>
<ul>
<li>Concurrency is needed for high performance when using multiple cores</li>
<li>Threads are multiple execution streams within a single process or address space (share PID and address space, own registers and stack)</li>
<li>Context switches within a critical section can lead to non-deterministic bugs</li>
</ul>
<h2 id="locks"><a class="markdownIt-Anchor" href="#locks"></a> Locks</h2>
<h3 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h3>
<ul>
<li>
<p>Goal: Provide mutual exclusion (mutex)</p>
</li>
<li>
<p>Atomic operation: No other instructions can be interleaved</p>
</li>
</ul>
<ol>
<li>
<p>Allocate and Initialize</p>
<ul>
<li>
<figure class="highlight plain"><figcaption><span>mylock </span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    </span><br><span class="line">2. Acquire</span><br><span class="line">    - Acquire exclusion access to lock;</span><br><span class="line">    - Wait if lock is not available (some other process in critical section)</span><br><span class="line">    - Spin or block (relinquish CPU) while waiting</span><br><span class="line">    - ```Pthread_mutex_lock(&amp;mylock);</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li>
<p>Release</p>
<ul>
<li>Release exclusive access to lock; let another process enter critical section</li>
<li>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### Implementation Goals</span><br><span class="line">- Correctness</span><br><span class="line">    - Mutual exclusion</span><br><span class="line">        - Only one thread in critical section at a time</span><br><span class="line">    - Progress (deadlock-free) </span><br><span class="line">        - If several simultaneous requests, must allow one to proceed</span><br><span class="line">        - Deadlock happens when all threads are waiting for lock</span><br><span class="line"></span><br><span class="line">    - Bounded (starvation-free)</span><br><span class="line">        - Must eventually allow each waiting thread to enter</span><br><span class="line">        - The waiting time for lock is bounded</span><br><span class="line"></span><br><span class="line">- Fairness: Each thread waits for same amount of time</span><br><span class="line">- Performance: CPU is not used unnecessarily</span><br><span class="line"></span><br><span class="line">### Spin Lock with Interrupts</span><br><span class="line">- Idea</span><br><span class="line">    - Turn off interrupts for critical sections</span><br><span class="line">    - Prevent dispatcher from running another thread</span><br><span class="line">    - Code between interrupts executes atomically</span><br><span class="line"></span><br><span class="line">- Implementation code</span><br><span class="line">    ```c=</span><br><span class="line">    void acquire(lockT *l) &#123;</span><br><span class="line">        disableInterrupts();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    void release(lockT *l)  &#123; </span><br><span class="line">        enableInterrupts(); </span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ol>
<ul>
<li>Disadvantages
<ul>
<li>Only works on uniprocessors</li>
<li>Process can keep control of CPU for arbitrary length</li>
<li>Cannot perform other necessary work</li>
</ul>
</li>
</ul>
<h3 id="spin-lock-with-load-store"><a class="markdownIt-Anchor" href="#spin-lock-with-load-store"></a> Spin Lock with Load + Store</h3>
<ul>
<li>
<p>Idea: uses a single <strong>shared</strong> lock variable</p>
</li>
<li>
<p>Implementation code</p>
</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// shared variable </span></span><br><span class="line">boolean lock = <span class="literal">false</span>; </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">acquire</span><span class="params">(Boolean *lock)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">while</span> (*lock) <span class="comment">/* wait */</span> ; </span><br><span class="line">    *lock = <span class="literal">true</span>; </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">release</span><span class="params">(Boolean *lock)</span> </span>&#123; </span><br><span class="line">    *lock = <span class="literal">false</span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>Race condition</p>
<table>
<thead>
<tr>
<th>Thread 1</th>
<th>Thread 2</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>while (*lock)</code><br><br><br> <code>lock = true;</code></td>
<td><br><code>while (*lock)</code> <br> <code>*lock = true;</code><br><br></td>
</tr>
</tbody>
</table>
<ul>
<li>Both threads grab lock!</li>
<li>Problem: Testing lock and setting lock are not atomic</li>
</ul>
</li>
</ul>
<h3 id="spin-lock-with-xchg"><a class="markdownIt-Anchor" href="#spin-lock-with-xchg"></a> Spin Lock with xchg</h3>
<ul>
<li>
<p>xchg: Atomic exchange or test-and-set</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// return what was pointed to by addr</span></span><br><span class="line"><span class="comment">// at the same time, store newval into addr</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">xchg</span><span class="params">(<span class="keyword">int</span> *addr, <span class="keyword">int</span> newval)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> old = *addr;</span><br><span class="line">    *addr = newval;</span><br><span class="line">    <span class="keyword">return</span> old;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Implementation code</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> flag;</span><br><span class="line">&#125; <span class="keyword">lock_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    lock-&gt;flag = <span class="number">0</span>; <span class="comment">// 0 =&gt; unlocked; 1 =&gt; locked</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">acquire</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (xchg(&amp;lock-&gt;flag, <span class="number">1</span>) == <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="comment">// spin-wait (do nothing)</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// exit loop when flag changed from 0 (unlocked) to 1 (locked)</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">release</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    lock-&gt;flag = <span class="number">0</span>; <span class="comment">// set the flag to 0 (unlocked)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="spin-lock-with-cas"><a class="markdownIt-Anchor" href="#spin-lock-with-cas"></a> Spin Lock with CAS</h3>
<ul>
<li>
<p>CAS: Compare and Swap</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Atomic instruction</span></span><br><span class="line"><span class="comment">// set newval to *addr when *addr == expected</span></span><br><span class="line"><span class="comment">// return what was pointed to by addr</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">CompareAndSwap</span><span class="params">(<span class="keyword">int</span> *addr, <span class="keyword">int</span> expected, <span class="keyword">int</span> newval)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">int</span> actual = *addr; </span><br><span class="line">    <span class="keyword">if</span> (actual == expected)  </span><br><span class="line">        *addr = newval; </span><br><span class="line">    <span class="keyword">return</span> actual; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Implementation code</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">acquire</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">while</span>(CompareAndSwap(&amp;lock-&gt;flag, <span class="number">0</span>, <span class="number">1</span>) == <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="comment">// spin-wait (do nothing)  </span></span><br><span class="line">    &#125;</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">release</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    lock-&gt;flag = <span class="number">0</span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Exercise with xchg and CAS</p>
<ul>
<li>
<p>Code</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> a = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span> b = xchg(&amp;a, <span class="number">2</span>);</span><br><span class="line"><span class="keyword">int</span> c = CompareAndSwap(&amp;b, <span class="number">2</span>, <span class="number">3</span>);</span><br><span class="line"><span class="keyword">int</span> d = CompareAndSwap(&amp;b, <span class="number">1</span>, <span class="number">3</span>) ;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Result:</p>
<table>
<thead>
<tr>
<th>a</th>
<th>b</th>
<th>c</th>
<th>d</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>1</td>
<td></td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>1</td>
<td>1</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>3</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
</li>
</ul>
</li>
</ul>
<h3 id="ticket-locks"><a class="markdownIt-Anchor" href="#ticket-locks"></a> Ticket Locks</h3>
<ul>
<li>
<p>Basic spinlocks are unfair</p>
<p><img src="https://i.imgur.com/l2lu5Vn.png" alt=""></p>
<ul>
<li>Scheduler is unaware of locks/unlocks!</li>
</ul>
</li>
<li>
<p>Introduction to Ticket Locks</p>
<ul>
<li>
<p>Idea: reserve each thread’s turn to use a lock.</p>
</li>
<li>
<p>Each thread spins until their turn.</p>
</li>
<li>
<p>Use new atomic primitive, fetch-and-add</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">FetchAndAdd</span><span class="params">(<span class="keyword">int</span> *ptr)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">int</span> old = *ptr; </span><br><span class="line">    *ptr = old + <span class="number">1</span>; </span><br><span class="line">    <span class="keyword">return</span> old; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Acquire: Grab ticket; Spin while not thread’s ticket != turn</p>
</li>
<li>
<p>Release: Advance to next turn</p>
</li>
</ul>
</li>
<li>
<p>Example</p>
<table>
<thead>
<tr>
<th>Time</th>
<th>Event</th>
<th>ticket</th>
<th>Turn</th>
<th>Result</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>A <code>lock()</code></td>
<td>0</td>
<td>0</td>
<td>A runs</td>
</tr>
<tr>
<td>2</td>
<td>B <code>lock()</code></td>
<td>1</td>
<td></td>
<td>B spins until turn = 1</td>
</tr>
<tr>
<td>3</td>
<td>C <code>lock()</code></td>
<td>2</td>
<td></td>
<td>C spins until turn = 2</td>
</tr>
<tr>
<td>4</td>
<td>A <code>unlock()</code></td>
<td></td>
<td>1</td>
<td>B runs</td>
</tr>
<tr>
<td>5</td>
<td>A <code>lock()</code></td>
<td>3</td>
<td></td>
<td>A spins until turn = 3</td>
</tr>
<tr>
<td>6</td>
<td>B <code>unlock()</code></td>
<td></td>
<td>2</td>
<td>C runs</td>
</tr>
<tr>
<td>7</td>
<td>C <code>unlock()</code></td>
<td></td>
<td>3</td>
<td>A runs</td>
</tr>
<tr>
<td>8</td>
<td>A <code>unlock()</code></td>
<td></td>
<td>4</td>
<td></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>Ticket Lock Implementation</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span> </span><br><span class="line">    <span class="keyword">int</span> ticket; </span><br><span class="line">    <span class="keyword">int</span> turn; </span><br><span class="line">&#125; <span class="keyword">lock_t</span>; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">lock_init</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123; </span><br><span class="line">    lock-&gt;ticket = <span class="number">0</span>; </span><br><span class="line">    lock-&gt;turn = <span class="number">0</span>; </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">acquire</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> myturn = FetchAndAdd(&amp;lock-&gt;ticket);</span><br><span class="line">    <span class="keyword">while</span> (lock-&gt;turn != myturn); <span class="comment">// spin</span></span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">release</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123; </span><br><span class="line">    FetchAndAdd(&amp;lock-&gt;turn); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="ticket-lock-with-yield"><a class="markdownIt-Anchor" href="#ticket-lock-with-yield"></a> Ticket Lock with Yield</h3>
<ul>
<li>
<p>Spinlock Performance</p>
<ul>
<li>
<p>Fast when…</p>
<ul>
<li>many CPUs</li>
<li>locks held a short time</li>
<li>advantage: avoid context switch</li>
</ul>
</li>
<li>
<p>Slow when…</p>
<ul>
<li>one CPU</li>
<li>locks held a long time</li>
<li>disadvantage: spinning is wasteful</li>
</ul>
</li>
</ul>
</li>
<li>
<p>CPU Scheduler is Ignorant</p>
<ul>
<li>CPU scheduler may run B, C, D instead of A even though B, C, D are waiting for A</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/Avi05dZ.png" alt=""></p>
<ul>
<li>
<p>Ticket Locks with Yield</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span> </span><br><span class="line">    <span class="keyword">int</span> ticket; </span><br><span class="line">    <span class="keyword">int</span> turn; </span><br><span class="line">&#125; <span class="keyword">lock_t</span>; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">lock_init</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123; </span><br><span class="line">    lock-&gt;ticket = <span class="number">0</span>; </span><br><span class="line">    lock-&gt;turn = <span class="number">0</span>; </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">acquire</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> myturn = FetchAndAdd(&amp;lock-&gt;ticket);</span><br><span class="line">    <span class="keyword">while</span> (lock-&gt;turn != myturn) &#123;</span><br><span class="line">        yield(); <span class="comment">// yield instead of spin</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">release</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123; </span><br><span class="line">    FetchAndAdd(&amp;lock-&gt;turn); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Yield instead of Spin</p>
</li>
</ul>
<p><img src="https://i.imgur.com/cXfmvjp.png" alt=""></p>
<ul>
<li>Time Comparison: Yield vs Spin
<ul>
<li>
<p>Assumption</p>
<ul>
<li>Round robin scheduling, 10ms time slice</li>
<li>Process A, B, C, D, E, F, G, H, I, J in the system</li>
</ul>
</li>
<li>
<p>Timeline</p>
<ul>
<li>A: lock() … compute … unlock()</li>
<li>B: lock() … compute … unlock()</li>
<li>…</li>
<li>J: lock() … compute … unlock()</li>
<li>A: lock() … compute … unlock()</li>
<li>…</li>
</ul>
</li>
<li>
<p>If A’s compute is 20ms long, starting at t = 0, when does B get lock with spin ?</p>
<ul>
<li>
<p>110 ms</p>
<table>
<thead>
<tr>
<th>A…J</th>
<th>A</th>
<th>B</th>
</tr>
</thead>
<tbody>
<tr>
<td>100</td>
<td>10</td>
<td></td>
</tr>
</tbody>
</table>
</li>
</ul>
</li>
<li>
<p>If B’s compute is 30ms long, when does C get lock with spin ?</p>
<ul>
<li>
<p>320 ms</p>
<table>
<thead>
<tr>
<th>A…J</th>
<th>A…J</th>
<th>A…J</th>
<th>A</th>
<th>B</th>
<th>C</th>
</tr>
</thead>
<tbody>
<tr>
<td>100</td>
<td>100</td>
<td>100</td>
<td>10</td>
<td>10</td>
<td></td>
</tr>
</tbody>
</table>
</li>
</ul>
</li>
<li>
<p>If context switch time = 1ms, when does B get lock with yield ?</p>
<ul>
<li>29 ms</li>
<li>
<table>
<thead>
<tr>
<th>A</th>
<th>B…J</th>
<th>A</th>
<th>B</th>
</tr>
</thead>
<tbody>
<tr>
<td>10</td>
<td>9</td>
<td>10</td>
<td></td>
</tr>
</tbody>
</table>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="queue-lock"><a class="markdownIt-Anchor" href="#queue-lock"></a> Queue Lock</h3>
<ul>
<li>
<p>Motivation</p>
<ul>
<li>
<p>Time complexity of spinlock</p>
<ul>
<li>Without yield: O(threads * time_slice)</li>
<li>With yield: O(threads * context_switch)</li>
</ul>
</li>
<li>
<p>Even with yield, spinning is slow with high thread contention</p>
</li>
</ul>
</li>
<li>
<p>Idea</p>
<ul>
<li>Block and put thread on waiting queue instead of spinning</li>
<li>Remove waiting threads from scheduler ready queue</li>
<li>(e.g., <code>park()</code> and <code>unpark(threadID)</code>)</li>
<li>Scheduler runs any thread that is ready</li>
</ul>
</li>
<li>
<p>Example</p>
<ul>
<li>
<p>Assumption</p>
<ul>
<li>A &amp; C has 60ms of work</li>
<li>A, B, D contend for lock</li>
<li>C not contending</li>
<li>Context switch + yield takes 5ms</li>
</ul>
</li>
<li>
<p>Timeline</p>
<table>
<thead>
<tr>
<th>Time</th>
<th>Event</th>
<th>Running</th>
<th>Runnable</th>
<th>Waiting</th>
</tr>
</thead>
<tbody>
<tr>
<td>Initial</td>
<td></td>
<td></td>
<td>A, B, C, D</td>
<td></td>
</tr>
<tr>
<td>0-20</td>
<td>A scheduled</td>
<td>A</td>
<td>B, C, D</td>
<td></td>
</tr>
<tr>
<td>20-25</td>
<td>B scheduled &amp; blocked</td>
<td></td>
<td>C, D, A</td>
<td>B</td>
</tr>
<tr>
<td>25-45</td>
<td>C scheduled</td>
<td>C</td>
<td>D, A</td>
<td>B</td>
</tr>
<tr>
<td>45-50</td>
<td>D scheduled &amp; blocked</td>
<td></td>
<td>A, C</td>
<td>B, D</td>
</tr>
<tr>
<td>50-70</td>
<td>A scheduled</td>
<td>A</td>
<td>C</td>
<td>B, D</td>
</tr>
<tr>
<td>70-90</td>
<td>C scheduled</td>
<td>C</td>
<td>A</td>
<td>B, D</td>
</tr>
<tr>
<td>90-110</td>
<td>A scheduled &amp; finished</td>
<td>A</td>
<td>C</td>
<td>B, D</td>
</tr>
<tr>
<td>110-130</td>
<td>C scheduled &amp; finished</td>
<td>C</td>
<td>B</td>
<td>D</td>
</tr>
<tr>
<td>130-150</td>
<td>B scheduled &amp; finished</td>
<td>B</td>
<td>D</td>
<td></td>
</tr>
<tr>
<td>150-170</td>
<td>D scheduled &amp; finished</td>
<td>D</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</li>
</ul>
</li>
<li>
<p>Incorrect Implementation</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="keyword">bool</span> lock = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">bool</span> guard = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">queue_t</span> q;</span><br><span class="line">&#125; LockT;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. Grab guard</span></span><br><span class="line"><span class="comment">// 2. If lock is held, add to queue and park</span></span><br><span class="line"><span class="comment">// 3. If lock is not held, grab the lock</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">acquire</span><span class="params">(LockT *l)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">while</span> (XCHG(&amp;l-&gt;guard, <span class="literal">true</span>)); </span><br><span class="line">    <span class="keyword">if</span> (l-&gt;lock) &#123; </span><br><span class="line">        qadd(l-&gt;q, tid); </span><br><span class="line">        l-&gt;guard = <span class="literal">false</span>; </span><br><span class="line">        park();     <span class="comment">// blocked  </span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">        l-&gt;lock = <span class="literal">true</span>; </span><br><span class="line">        l-&gt;guard = <span class="literal">false</span>; </span><br><span class="line">    &#125; </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. Grab guard</span></span><br><span class="line"><span class="comment">// 2. If queue is empty, release hte lock</span></span><br><span class="line"><span class="comment">// 3. If the queue is not empty, unpark head of queue</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">release</span><span class="params">(LockT *l)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">while</span> (XCHG(&amp;l-&gt;guard, <span class="literal">true</span>)); </span><br><span class="line">    <span class="keyword">if</span> (qempty(l-&gt;q))</span><br><span class="line">        l-&gt;lock=<span class="literal">false</span>; </span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        unpark(qremove(l-&gt;q));  </span><br><span class="line">    l-&gt;guard = <span class="literal">false</span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Questions and Answers</p>
<ul>
<li>
<p>Why is guard used?<br>
To ensure queue operations is thread safe</p>
</li>
<li>
<p>Why OK to spin on guard?<br>
Very shhort critical section</p>
</li>
<li>
<p>In release(), why not set <code>lock = false</code> when unpark?<br>
<code>lock == true</code> is passed from one thread to the next</p>
</li>
</ul>
</li>
<li>
<p>Race Condition for Previous Implementation</p>
<table>
<thead>
<tr>
<th>Thread 1 (in lock)</th>
<th>Thread 2 (in unlock)</th>
</tr>
</thead>
<tbody>
<tr>
<td>if (l-&gt;lock) {<br> qadd(l-&gt;q, tid); <br> l-&gt;guard = false; <br> <br> <br> <br><br>  park()</td>
<td><br> <br> <br> while (TAS(&amp;l-&gt;guard, true)); <br> if (qempty(l-&gt;q)) // false!!  <br> else unpark(qremove(l-&gt;q)); <br> l-&gt;guard = false;   <br> <br></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>Correct Implementation</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="keyword">bool</span> lock = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">bool</span> guard = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">queue_t</span> q;</span><br><span class="line">&#125; LockT;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">acquire</span><span class="params">(LockT *l)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">while</span> (XCHG(&amp;l-&gt;guard, <span class="literal">true</span>)); </span><br><span class="line">    <span class="keyword">if</span> (l-&gt;lock) &#123; </span><br><span class="line">        qadd(l-&gt;q, tid); </span><br><span class="line">        setpark(pid); <span class="comment">// notify of plan</span></span><br><span class="line">        l-&gt;guard = <span class="literal">false</span>; </span><br><span class="line">        park();     <span class="comment">// blocked  </span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">        l-&gt;lock = <span class="literal">true</span>; </span><br><span class="line">        l-&gt;guard = <span class="literal">false</span>; </span><br><span class="line">    &#125; </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">release</span><span class="params">(LockT *l)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">while</span> (XCHG(&amp;l-&gt;guard, <span class="literal">true</span>)); </span><br><span class="line">    <span class="keyword">if</span> (qempty(l-&gt;q))</span><br><span class="line">        l-&gt;lock=<span class="literal">false</span>; </span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        unpark(qremove(l-&gt;q));  </span><br><span class="line">    l-&gt;guard = <span class="literal">false</span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Time Comparison: Yield vs Blocking</p>
<ul>
<li>
<p>Assumption</p>
<ul>
<li>Round robin scheduling, 10ms time slice</li>
<li>Process A, B, C, D, E, F, G, H, I, J in the system</li>
<li>Context switch takes 1ms</li>
</ul>
</li>
<li>
<p>Timeline</p>
<ul>
<li>A: lock() … compute … unlock()</li>
<li>B: lock() … compute … unlock()</li>
<li>…</li>
<li>J: lock() … compute … unlock()</li>
<li>A: lock() … compute … unlock()</li>
<li>…</li>
</ul>
</li>
<li>
<p>If A’s compute is 30ms long, starting at t = 0, when does B get lock with yield?</p>
<ul>
<li>
<p>48 ms</p>
<table>
<thead>
<tr>
<th>A</th>
<th>B…J</th>
<th>A</th>
<th>B…J</th>
<th>A</th>
<th>B</th>
</tr>
</thead>
<tbody>
<tr>
<td>10</td>
<td>9</td>
<td>10</td>
<td>9</td>
<td>10</td>
<td></td>
</tr>
</tbody>
</table>
</li>
</ul>
</li>
<li>
<p>If A’s compute is 30ms long, starting at t = 0, when does B get lock with blocking?</p>
<ul>
<li>
<p>39 ms</p>
<table>
<thead>
<tr>
<th>A</th>
<th>B…J</th>
<th>A</th>
<th>A</th>
<th>B</th>
</tr>
</thead>
<tbody>
<tr>
<td>10</td>
<td>9</td>
<td>10</td>
<td>10</td>
<td></td>
</tr>
</tbody>
</table>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="queue-lock-vs-spin-lock"><a class="markdownIt-Anchor" href="#queue-lock-vs-spin-lock"></a> Queue Lock vs Spin Lock</h3>
<ul>
<li>
<p>Each approach is better under different circumstances</p>
</li>
<li>
<p>Uniprocessor</p>
<ul>
<li>Waiting process is scheduled à Process holding lock isn’t</li>
<li>Waiting process should always relinquish processor</li>
<li>Associate queue of waiters with each lock (as in previous implementation)</li>
</ul>
</li>
<li>
<p>Multiprocessor</p>
<ul>
<li>Waiting process is scheduled -&gt; Process holding lock might be</li>
<li>Spin or block depends on how long, t, before lock is released
<ul>
<li>Lock released quickly -&gt; Spin-wait</li>
<li>Lock released slowly -&gt; Block</li>
<li>Quick and slow are relative to context-switch cost, C</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="condition-variables"><a class="markdownIt-Anchor" href="#condition-variables"></a> Condition Variables</h2>
<h3 id="ordering"><a class="markdownIt-Anchor" href="#ordering"></a> Ordering</h3>
<ul>
<li>
<p>Idea: Thread A runs after Thread B does something</p>
</li>
<li>
<p>Example: Join</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pthread_t</span> p1, p2; </span><br><span class="line">Pthread_create(&amp;p1, <span class="literal">NULL</span>, mythread, <span class="string">"A"</span>); </span><br><span class="line">Pthread_create(&amp;p2, <span class="literal">NULL</span>, mythread, <span class="string">"B"</span>); </span><br><span class="line"><span class="comment">// join waits for the threads to finish </span></span><br><span class="line">Pthread_join(p1, <span class="literal">NULL</span>); </span><br><span class="line">Pthread_join(p2, <span class="literal">NULL</span>); </span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="condition-variables-2"><a class="markdownIt-Anchor" href="#condition-variables-2"></a> Condition Variables</h3>
<ul>
<li>
<p>Condition Variable: queue of waiting threads</p>
</li>
<li>
<p>B waits for a signal on CV before running: <code>wait(CV, …)</code></p>
</li>
<li>
<p>A sends signal to CV when time for B to run: <code>signal(CV, …)</code></p>
</li>
<li>
<p><code>wait(cond_t *cv, mutex_t *lock)</code></p>
<ul>
<li>assumes the lock is held when wait() is called</li>
<li>puts caller to sleep + releases the lock (atomically)</li>
<li>when awoken, reacquires lock before returning</li>
</ul>
</li>
<li>
<p><code>signal(cond_t *cv)</code></p>
<ul>
<li>wake a single waiting thread (if &gt;= 1 thread is waiting)</li>
<li>if there is no waiting thread, just return, doing nothing</li>
</ul>
</li>
</ul>
<h3 id="join-attempt-1-no-state"><a class="markdownIt-Anchor" href="#join-attempt-1-no-state"></a> Join Attempt 1: No State</h3>
<ul>
<li>
<p>Code</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// parent</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">thread_join</span><span class="params">()</span> </span>&#123; </span><br><span class="line">   Mutex_lock(&amp;m);     <span class="comment">// x </span></span><br><span class="line">   Cond_wait(&amp;c, &amp;m);  <span class="comment">// y </span></span><br><span class="line">   Mutex_unlock(&amp;m);   <span class="comment">// z </span></span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">// child</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">thread_exit</span><span class="params">()</span> </span>&#123; </span><br><span class="line">   Mutex_lock(&amp;m);    <span class="comment">// a </span></span><br><span class="line">   Cond_signal(&amp;c);   <span class="comment">// b </span></span><br><span class="line">   Mutex_unlock(&amp;m);  <span class="comment">// c </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Intended schedule</p>
<table>
<thead>
<tr>
<th>Time</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
</tr>
</thead>
<tbody>
<tr>
<td>Parent</td>
<td>x</td>
<td>y</td>
<td></td>
<td></td>
<td></td>
<td>z</td>
</tr>
<tr>
<td>Child</td>
<td></td>
<td></td>
<td>a</td>
<td>b</td>
<td>c</td>
<td></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>Broken schedule</p>
<table>
<thead>
<tr>
<th>Time</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
</tr>
</thead>
<tbody>
<tr>
<td>Parent</td>
<td></td>
<td></td>
<td></td>
<td>x</td>
<td>y</td>
</tr>
<tr>
<td>Child</td>
<td>a</td>
<td>b</td>
<td>c</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>Parent is stuck because nobody will call signal</li>
</ul>
</li>
<li>
<p>Rule of Thumb 1</p>
<ul>
<li>Keep state in addition to CV’s</li>
<li>CV’s are used to signal threads when state changes</li>
<li>If state is already as needed, thread doesn’t wait for a signal!</li>
</ul>
</li>
</ul>
<h3 id="join-attempt-2-no-mutex-lock"><a class="markdownIt-Anchor" href="#join-attempt-2-no-mutex-lock"></a> Join Attempt 2: No Mutex Lock</h3>
<ul>
<li>
<p>Code</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// parent</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">thread_join</span><span class="params">()</span> </span>&#123; </span><br><span class="line">   Mutex_lock(&amp;m);         <span class="comment">// w</span></span><br><span class="line">   <span class="comment">// If the child process already finished executing</span></span><br><span class="line">   <span class="comment">// the parent process doesn't need to wait</span></span><br><span class="line">   <span class="keyword">if</span> (done == <span class="number">0</span>)          <span class="comment">// x</span></span><br><span class="line">       Cond_wait(&amp;c, &amp;m);  <span class="comment">// y </span></span><br><span class="line">   Mutex_unlock(&amp;m);       <span class="comment">// z </span></span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">// child</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">thread_exit</span><span class="params">()</span> </span>&#123; </span><br><span class="line">   done = <span class="number">1</span>;          <span class="comment">// a</span></span><br><span class="line">   Cond_signal(&amp;c);   <span class="comment">// b </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Intended schedule</p>
<table>
<thead>
<tr>
<th>Time</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
</tr>
</thead>
<tbody>
<tr>
<td>Parent</td>
<td></td>
<td></td>
<td>w</td>
<td>x</td>
<td>y</td>
<td>z</td>
</tr>
<tr>
<td>Child</td>
<td>a</td>
<td>b</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>Broken schedule</p>
<table>
<thead>
<tr>
<th>Time</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
</tr>
</thead>
<tbody>
<tr>
<td>Parent</td>
<td>w</td>
<td>x</td>
<td></td>
<td></td>
<td>y</td>
</tr>
<tr>
<td>Child</td>
<td></td>
<td></td>
<td>a</td>
<td>b</td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>Parent is stuck again</li>
</ul>
</li>
</ul>
<h3 id="join-attempt-3-state-mutex-lock"><a class="markdownIt-Anchor" href="#join-attempt-3-state-mutex-lock"></a> Join Attempt 3: State + Mutex Lock</h3>
<ul>
<li>
<p>Code</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// parent</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">thread_join</span><span class="params">()</span> </span>&#123; </span><br><span class="line">   Mutex_lock(&amp;m);         <span class="comment">// w</span></span><br><span class="line">   <span class="keyword">if</span> (done == <span class="number">0</span>)          <span class="comment">// x</span></span><br><span class="line">       Cond_wait(&amp;c, &amp;m);  <span class="comment">// y </span></span><br><span class="line">   Mutex_unlock(&amp;m);       <span class="comment">// z </span></span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">// child</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">thread_exit</span><span class="params">()</span> </span>&#123; </span><br><span class="line">   Mutex_lock(&amp;m);    <span class="comment">// a</span></span><br><span class="line">   done = <span class="number">1</span>;          <span class="comment">// b</span></span><br><span class="line">   Cond_signal(&amp;c);   <span class="comment">// c </span></span><br><span class="line">   Mutex_unlock(&amp;m);  <span class="comment">// d</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Schedule</p>
<table>
<thead>
<tr>
<th>Time</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
</tr>
</thead>
<tbody>
<tr>
<td>Parent</td>
<td>w</td>
<td>x</td>
<td>y</td>
<td></td>
<td></td>
<td></td>
<td>z</td>
</tr>
<tr>
<td>Child</td>
<td></td>
<td></td>
<td>a</td>
<td>b</td>
<td>c</td>
<td>d</td>
<td></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>Rule of Thumb 2</p>
<ul>
<li>Hold mutex lock while calling wait/signal</li>
<li>Ensures no race between interacting with state and wait/signal</li>
</ul>
</li>
</ul>
<h3 id="producerconsumer-problem"><a class="markdownIt-Anchor" href="#producerconsumer-problem"></a> Producer/Consumer Problem</h3>
<ul>
<li>Example: UNIX pipes
<ul>
<li>
<p>A pipe may have many writers and readers</p>
</li>
<li>
<p>Internally, there is a finite-sized buffer</p>
</li>
<li>
<p>Writers add data to the buffer</p>
<ul>
<li>Writers have to wait if buffer is full</li>
</ul>
</li>
<li>
<p>Readers remove data from the buffer</p>
<ul>
<li>Readers have to wait if buffer is empty</li>
</ul>
</li>
<li>
<p>Implementation:</p>
<ul>
<li>reads/writes to buffer require locking</li>
<li>when buffers are full, writers must wait</li>
<li>when buffers are empty, readers must wait</li>
</ul>
</li>
</ul>
</li>
</ul>
<pre>
               Start (consumer)
               |
     +---------v---------------------------+------+
Buf: |         |          data             |      |
     +---------+---------------------------^------+
                                           |
                                           End (producer)
</pre>
<ul>
<li>Producer/Consumer Problem
<ul>
<li>
<p>Producers generate data (like pipe writers)</p>
</li>
<li>
<p>Consumers grab data and process it (like pipe readers)</p>
</li>
<li>
<p>Producer/consumer problems are frequent in systems (e.g. web servers)</p>
</li>
<li>
<p>General strategy use condition variables to:</p>
<ul>
<li>make producers wait when buffers are full</li>
<li>make consumers wait when there is nothing to consume</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="pc-attempt-1-one-cv"><a class="markdownIt-Anchor" href="#pc-attempt-1-one-cv"></a> P/C Attempt 1: One CV</h3>
<ul>
<li>
<p>Code</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. Producer grabs the lock</span></span><br><span class="line"><span class="comment">// 2. Check whether the buffer is full. If so, wait.</span></span><br><span class="line"><span class="comment">// 3. Put something to the buffer</span></span><br><span class="line"><span class="comment">// 4. Signal consumers to read</span></span><br><span class="line"><span class="comment">// 5. Release the lock</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">producer</span><span class="params">(<span class="keyword">void</span> *arg)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; loops; i++) &#123;</span><br><span class="line">    Mutex_lock(&amp;m);          <span class="comment">// p1</span></span><br><span class="line">    <span class="keyword">if</span> (numfull == max)      <span class="comment">// p2</span></span><br><span class="line">      Cond_wait(&amp;cond, &amp;m);  <span class="comment">// p3</span></span><br><span class="line">    do_fill(i);              <span class="comment">// p4</span></span><br><span class="line">    Cond_signal(&amp;cond);      <span class="comment">// p5</span></span><br><span class="line">    Mutex_unlock(&amp;m);        <span class="comment">// p6</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. Consumer grabs the lock</span></span><br><span class="line"><span class="comment">// 2. Check whether the buffer is empty. If so, wait.</span></span><br><span class="line"><span class="comment">// 3. Get the content from buffer and remove it.</span></span><br><span class="line"><span class="comment">// 4. Signal consumers to write</span></span><br><span class="line"><span class="comment">// 5. Release the lock</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">consumer</span><span class="params">(<span class="keyword">void</span> *arg)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    Mutex_lock(&amp;m);         <span class="comment">// c1</span></span><br><span class="line">    <span class="keyword">if</span> (numfull == <span class="number">0</span>)       <span class="comment">// c2</span></span><br><span class="line">      Cond_wait(&amp;cond, &amp;m); <span class="comment">// c3</span></span><br><span class="line">    <span class="keyword">int</span> tmp = do_get();     <span class="comment">// c4</span></span><br><span class="line">    Cond_signal(&amp;cond);     <span class="comment">// c5</span></span><br><span class="line">    Mutex_unlock(&amp;m);       <span class="comment">// c6</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Broken schedule</p>
<table>
<thead>
<tr>
<th>Time</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
<th>11</th>
<th>12</th>
<th>13</th>
<th>14</th>
<th>15</th>
<th>16</th>
</tr>
</thead>
<tbody>
<tr>
<td>P</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>p1</td>
<td>p2</td>
<td>p4</td>
<td>p5</td>
<td>p6</td>
<td>p1</td>
<td>p2</td>
<td>p3</td>
<td></td>
<td></td>
</tr>
<tr>
<td>C1</td>
<td>c1</td>
<td>c2</td>
<td>c3</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>C2</td>
<td></td>
<td></td>
<td></td>
<td>c1</td>
<td>c2</td>
<td>c3</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>c4</td>
<td>c5</td>
</tr>
</tbody>
</table>
<ul>
<li>At time 16, Consumer 1 could signal Consumer 2 to wake up</li>
</ul>
</li>
</ul>
<h3 id="pc-attempt-2-two-cvs"><a class="markdownIt-Anchor" href="#pc-attempt-2-two-cvs"></a> P/C Attempt 2: Two CVs</h3>
<ul>
<li>
<p>How to wake the right thread? Use two condition variables</p>
</li>
<li>
<p>Code</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">producer</span><span class="params">(<span class="keyword">void</span> *arg)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; loops; i++) &#123;</span><br><span class="line">    Mutex_lock(&amp;m);          <span class="comment">// p1</span></span><br><span class="line">    <span class="keyword">if</span> (numfull == max)      <span class="comment">// p2</span></span><br><span class="line">      Cond_wait(&amp;empty, &amp;m); <span class="comment">// p3</span></span><br><span class="line">    do_fill(i);              <span class="comment">// p4</span></span><br><span class="line">    Cond_signal(&amp;fill);      <span class="comment">// p5</span></span><br><span class="line">    Mutex_unlock(&amp;m);        <span class="comment">// p6</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">consumer</span><span class="params">(<span class="keyword">void</span> *arg)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    Mutex_lock(&amp;m);         <span class="comment">// c1</span></span><br><span class="line">    <span class="keyword">if</span> (numfull == <span class="number">0</span>)       <span class="comment">// c2</span></span><br><span class="line">      Cond_wait(&amp;fill, &amp;m); <span class="comment">// c3</span></span><br><span class="line">    <span class="keyword">int</span> tmp = do_get();     <span class="comment">// c4</span></span><br><span class="line">    Cond_signal(&amp;empty);    <span class="comment">// c5</span></span><br><span class="line">    Mutex_unlock(&amp;m);       <span class="comment">// c6</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Broken schedule</p>
<table>
<thead>
<tr>
<th>Time</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
<th>11</th>
<th>12</th>
</tr>
</thead>
<tbody>
<tr>
<td>P</td>
<td></td>
<td></td>
<td></td>
<td>p1</td>
<td>p4</td>
<td>p5</td>
<td>p6</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>C1</td>
<td>c1</td>
<td>c2</td>
<td>c3</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>c4</td>
</tr>
<tr>
<td>C2</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>c1</td>
<td>c4</td>
<td>c5</td>
<td>c6</td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li>At time 12, Consumer 1 wakes up but has nothing to read</li>
<li>Note: When <code>signal()</code> is called, the thread may not resume immediately</li>
</ul>
</li>
</ul>
<h3 id="pc-attempt-3-two-cvs-with-while"><a class="markdownIt-Anchor" href="#pc-attempt-3-two-cvs-with-while"></a> P/C Attempt 3: Two CVs with While</h3>
<ul>
<li>
<p>Idea: Recheck the shared variable is still in the state you want after waking up</p>
</li>
<li>
<p>Code</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">producer</span><span class="params">(<span class="keyword">void</span> *arg)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; loops; i++) &#123;</span><br><span class="line">    Mutex_lock(&amp;m);          <span class="comment">// p1</span></span><br><span class="line">    <span class="keyword">while</span> (numfull == max)   <span class="comment">// p2</span></span><br><span class="line">      Cond_wait(&amp;empty, &amp;m); <span class="comment">// p3</span></span><br><span class="line">    do_fill(i);              <span class="comment">// p4</span></span><br><span class="line">    Cond_signal(&amp;fill);      <span class="comment">// p5</span></span><br><span class="line">    Mutex_unlock(&amp;m);        <span class="comment">// p6</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">consumer</span><span class="params">(<span class="keyword">void</span> *arg)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    Mutex_lock(&amp;m);         <span class="comment">// c1</span></span><br><span class="line">    <span class="keyword">while</span> (numfull == <span class="number">0</span>)    <span class="comment">// c2</span></span><br><span class="line">      Cond_wait(&amp;fill, &amp;m); <span class="comment">// c3</span></span><br><span class="line">    <span class="keyword">int</span> tmp = do_get();     <span class="comment">// c4</span></span><br><span class="line">    Cond_signal(&amp;empty);    <span class="comment">// c5</span></span><br><span class="line">    Mutex_unlock(&amp;m);       <span class="comment">// c6</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Rule of Thumb 3</p>
<ul>
<li>Whenever a lock is acquired, recheck assumptions about state!</li>
<li>Another thread could grab lock in between signal and wakeup from wait</li>
<li>Note that some libraries also have “spurious wakeups”</li>
<li>(may wake multiple waiting threads at signal or at any time)</li>
</ul>
</li>
</ul>
<h3 id="summary-2"><a class="markdownIt-Anchor" href="#summary-2"></a> Summary</h3>
<ul>
<li>
<p>Rules of Thumb for CVs</p>
<ol>
<li>Keep state in addition to CV’s</li>
<li>Always do wait/signal with lock held</li>
<li>Whenever thread wakes from waiting, recheck state</li>
</ol>
</li>
<li>
<p><code>wait(cond_t *cv, mutex_t *lock)</code></p>
<ul>
<li>assumes the lock is held when wait() is called</li>
<li>puts caller to sleep + releases the lock (atomically)</li>
<li>when awoken, reacquires lock before returning</li>
</ul>
</li>
<li>
<p><code>signal(cond_t *cv)</code></p>
<ul>
<li>wake a single waiting thread (if &gt;= 1 thread is waiting)</li>
<li>if there is no waiting thread, just return, doing nothing</li>
</ul>
</li>
</ul>
<h2 id="semaphores"><a class="markdownIt-Anchor" href="#semaphores"></a> Semaphores</h2>
<h3 id="introduction-2"><a class="markdownIt-Anchor" href="#introduction-2"></a> Introduction</h3>
<ul>
<li>
<p>Condition variables have no state (other than waiting queue)</p>
<ul>
<li>Programmer must track additional state</li>
</ul>
</li>
<li>
<p>Semaphores have state: track integer value</p>
<ul>
<li>State cannot be directly accessed by user program</li>
<li>But state determines behavior of semaphore operations</li>
</ul>
</li>
</ul>
<h3 id="semaphore-operations"><a class="markdownIt-Anchor" href="#semaphore-operations"></a> Semaphore Operations</h3>
<ul>
<li>
<p>Allocate and Initialize</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sem_init(<span class="keyword">sem_t</span> *s, <span class="keyword">int</span> initval) &#123;</span><br><span class="line">    s-&gt;value = initval; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>User cannot read or write value directly after initialization</li>
</ul>
</li>
<li>
<p>Wait or Test (sometime P() for Dutch) <code>sem_wait(sem_t*)</code></p>
<ul>
<li>Decrements sem value, Waits until value of sem is &gt;= 0</li>
</ul>
</li>
<li>
<p>Signal or Post (sometime V() for Dutch) <code>sem_post(sem_t*)</code></p>
<ul>
<li>Increment sem value, then wake a single waiter</li>
</ul>
</li>
</ul>
<h3 id="build-lock-from-semaphore"><a class="markdownIt-Anchor" href="#build-lock-from-semaphore"></a> Build Lock from Semaphore</h3>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span>  </span><br><span class="line">    <span class="keyword">sem_t</span> sem; </span><br><span class="line">&#125; <span class="keyword">lock_t</span>; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    sem_init(&amp;lock-&gt;sem, <span class="number">1</span>);</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">acquire</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    sem_wait(&amp;lock-&gt;sem);</span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">release</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123; </span><br><span class="line">    sem_post(&amp;lock-&gt;sem);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="join-with-cv-vs-semaphores"><a class="markdownIt-Anchor" href="#join-with-cv-vs-semaphores"></a> Join with CV vs Semaphores</h3>
<ul>
<li>
<p>Join with Condition Variable</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// parent</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">thread_join</span><span class="params">()</span> </span>&#123; </span><br><span class="line">   Mutex_lock(&amp;m);         <span class="comment">// w</span></span><br><span class="line">   <span class="keyword">if</span> (done == <span class="number">0</span>)          <span class="comment">// x</span></span><br><span class="line">       Cond_wait(&amp;c, &amp;m);  <span class="comment">// y </span></span><br><span class="line">   Mutex_unlock(&amp;m);       <span class="comment">// z </span></span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">// child</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">thread_exit</span><span class="params">()</span> </span>&#123; </span><br><span class="line">   Mutex_lock(&amp;m);    <span class="comment">// a</span></span><br><span class="line">   done = <span class="number">1</span>;          <span class="comment">// b</span></span><br><span class="line">   Cond_signal(&amp;c);   <span class="comment">// c </span></span><br><span class="line">   Mutex_unlock(&amp;m);  <span class="comment">// d</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Join with Semaphores</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">sem_t</span> s;</span><br><span class="line">sem_init(&amp;s, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">thread_join</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    sem_wait(&amp;s);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">thread_exit</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    sem_post(&amp;s);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Join with Semaphores Example 1</p>
  <pre>
    s                       s                      s
  +---+   parent wait()   +---+   child post()   +---+
  | 0 |+----------------->| -1|+---------------->| 0 |
  +---+                   +---+                  +---+
                            ^                      ^
                            |                      |
                            Parent blocked         Parent resumes
  </pre>
</li>
<li>
<p>Join with Semaphores Example 2</p>
  <pre>
    s                       s                      s
  +---+   child post()    +---+  parent wait()   +---+
  | 0 |+----------------->| 1 |+---------------->| 0 |
  +---+                   +---+                  +---+
  </pre>
</li>
</ul>
<h3 id="pc-1-producer-1-consumer-with-buffer-of-size-1"><a class="markdownIt-Anchor" href="#pc-1-producer-1-consumer-with-buffer-of-size-1"></a> P/C: 1 Producer &amp; 1 Consumer with Buffer of Size 1</h3>
<ul>
<li>
<p>Use 2 semaphores</p>
<ul>
<li>emptyBuffer: Initialize to 1</li>
<li>fullBuffer: Initialize to 0</li>
</ul>
</li>
<li>
<p>Producer</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    sem_wait(&amp;emptyBuffer);</span><br><span class="line">    Fill(&amp;buffer); </span><br><span class="line">    sem_signal(&amp;fullBuffer); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Consumer</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123; </span><br><span class="line">    sem_wait(&amp;fullBuffer);</span><br><span class="line">    Use(&amp;buffer); </span><br><span class="line">    sem_signal(&amp;emptyBuffer); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Example 1: Producer comes first</p>
<table>
<thead>
<tr>
<th>Time</th>
<th>Current Thread</th>
<th>emptyBuffer</th>
<th>fullBuffer</th>
</tr>
</thead>
<tbody>
<tr>
<td>Initial</td>
<td></td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>Producer</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>Consumer</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td>Producer</td>
<td>0</td>
<td>1</td>
</tr>
</tbody>
</table>
</li>
<li>
<p>Example 2: Consumer comes first</p>
<table>
<thead>
<tr>
<th>Time</th>
<th>Current Thread</th>
<th>emptyBuffer</th>
<th>fullBuffer</th>
</tr>
</thead>
<tbody>
<tr>
<td>Initial</td>
<td></td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>Consumer</td>
<td>1</td>
<td>-1</td>
</tr>
<tr>
<td>2</td>
<td>Producer</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>3</td>
<td>Consumer</td>
<td>1</td>
<td>0</td>
</tr>
</tbody>
</table>
</li>
</ul>
<h3 id="pc-1-producer-1-consumer-with-buffer-of-size-n"><a class="markdownIt-Anchor" href="#pc-1-producer-1-consumer-with-buffer-of-size-n"></a> P/C: 1 Producer &amp; 1 Consumer with Buffer of Size N</h3>
<ul>
<li>
<p>Use 2 semaphores</p>
<ul>
<li>emptyBuffer: Initialize to N</li>
<li>fullBuffer: Initialize to 0</li>
</ul>
</li>
<li>
<p>Producer</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    sem_wait(&amp;emptyBuffer);</span><br><span class="line">    Fill(&amp;buffer[i]); </span><br><span class="line">    i = (i + <span class="number">1</span>) % N;</span><br><span class="line">    sem_signal(&amp;fullBuffer); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Consumer</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> j = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123; </span><br><span class="line">    sem_wait(&amp;fullBuffer);</span><br><span class="line">    Use(&amp;buffer[j]);</span><br><span class="line">    j = (j + <span class="number">1</span>) % N;</span><br><span class="line">    sem_signal(&amp;emptyBuffer); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Example 1: Producer comes first (N = 3)</p>
<table>
<thead>
<tr>
<th>Time</th>
<th>Curr</th>
<th>empty<br>Buffer</th>
<th>full<br>Buffer</th>
<th>Note</th>
</tr>
</thead>
<tbody>
<tr>
<td>Initial</td>
<td></td>
<td>3</td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>1</td>
<td>P1</td>
<td>2</td>
<td>1</td>
<td>wait(emptyBuffer) + fill + signal(fullBuffer)</td>
</tr>
<tr>
<td>2</td>
<td>P2</td>
<td>1</td>
<td>2</td>
<td>wait(emptyBuffer) + fill + signal(fullBuffer)</td>
</tr>
<tr>
<td>3</td>
<td>P3</td>
<td>0</td>
<td>3</td>
<td>wait(emptyBuffer) + fill + signal(fullBuffer)</td>
</tr>
<tr>
<td>4</td>
<td>P4</td>
<td>-1</td>
<td>3</td>
<td>wait(emptyBuffer)</td>
</tr>
<tr>
<td>5</td>
<td>C1</td>
<td>0</td>
<td>2</td>
<td>wait(fullBuffer) + use + signal(emptyBuffer)</td>
</tr>
<tr>
<td>6</td>
<td>C2</td>
<td>1</td>
<td>1</td>
<td>wait(fullBuffer) + use + signal(emptyBuffer)</td>
</tr>
<tr>
<td>7</td>
<td>P4</td>
<td>0</td>
<td>2</td>
<td>fill + signal(fullBuffer)</td>
</tr>
</tbody>
</table>
</li>
<li>
<p>Example 2: Two consumers come first (N = 3)</p>
<table>
<thead>
<tr>
<th>Time</th>
<th>Curr</th>
<th>empty<br>Buffer</th>
<th>full<br>Buffer</th>
<th>Note</th>
</tr>
</thead>
<tbody>
<tr>
<td>Initial</td>
<td></td>
<td>3</td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>1</td>
<td>C1</td>
<td>3</td>
<td>-1</td>
<td>wait(fullBuffer)</td>
</tr>
<tr>
<td>2</td>
<td>C2</td>
<td>3</td>
<td>-2</td>
<td>wait(fullBuffe)</td>
</tr>
<tr>
<td>3</td>
<td>P</td>
<td>2</td>
<td>-1</td>
<td>wait(emptyBuffer) + fill + signal(fullBuffer)</td>
</tr>
<tr>
<td>4</td>
<td>C1</td>
<td>3</td>
<td>-1</td>
<td>use + signal(emptyBuffer)</td>
</tr>
</tbody>
</table>
</li>
</ul>
<h3 id="pc-multiple-producers-consumers"><a class="markdownIt-Anchor" href="#pc-multiple-producers-consumers"></a> P/C: Multiple Producers &amp; Consumers</h3>
<ul>
<li>
<p>Requirements</p>
<ul>
<li>Each consumer must grab unique filled element</li>
<li>Each producer must grab unique empty element</li>
</ul>
</li>
<li>
<p>Attempt 1</p>
<ul>
<li>
<p>Producer</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    sem_wait(&amp;emptyBuffer); </span><br><span class="line">    my_i = findempty(&amp;buffer);</span><br><span class="line">    Fill(&amp;buffer[my_i]); </span><br><span class="line">    sem_signal(&amp;fullBuffer); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Consumer</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123; </span><br><span class="line">    sem_wait(&amp;fullBuffer); </span><br><span class="line">    my_j = findfull(&amp;buffer); </span><br><span class="line">    Use(&amp;buffer[my_j]); </span><br><span class="line">    sem_signal(&amp;emptyBuffer); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Problem: <code>findfull</code> and <code>findempty</code> are not thread-safe</p>
</li>
</ul>
</li>
<li>
<p>Attempt 2</p>
<ul>
<li>
<p>Producer</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    sem_wait(&amp;mutex);</span><br><span class="line">    sem_wait(&amp;emptyBuffer); </span><br><span class="line">    my_i = findempty(&amp;buffer);</span><br><span class="line">    Fill(&amp;buffer[my_i]); </span><br><span class="line">    sem_signal(&amp;fullBuffer); </span><br><span class="line">    sem_signal(&amp;mutex);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Consumer</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123; </span><br><span class="line">    sem_wait(&amp;mutex);</span><br><span class="line">    sem_wait(&amp;fullBuffer); </span><br><span class="line">    my_j = findfull(&amp;buffer); </span><br><span class="line">    Use(&amp;buffer[my_j]); </span><br><span class="line">    sem_signal(&amp;emptyBuffer); </span><br><span class="line">    sem_signal(&amp;mutex);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Problem</p>
<ul>
<li>Deadlock: Consumer grabs <code>mutex</code> and wait for <code>fullBuffer</code> for ever</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Attempt 3</p>
<ul>
<li>
<p>Producer</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    sem_wait(&amp;emptyBuffer); </span><br><span class="line">    sem_wait(&amp;mutex);</span><br><span class="line">    my_i = findempty(&amp;buffer);</span><br><span class="line">    Fill(&amp;buffer[my_i]); </span><br><span class="line">    sem_signal(&amp;mutex);</span><br><span class="line">    sem_signal(&amp;fullBuffer); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Consumer</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123; </span><br><span class="line">    sem_wait(&amp;fullBuffer); </span><br><span class="line">    sem_wait(&amp;mutex);</span><br><span class="line">    my_j = findfull(&amp;buffer); </span><br><span class="line">    Use(&amp;buffer[my_j]); </span><br><span class="line">    sem_signal(&amp;mutex);</span><br><span class="line">    sem_signal(&amp;emptyBuffer); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Problem</p>
<ul>
<li>Cannot operate on multiple buffer locations at the same time</li>
<li>Only 1 thread at at time can be using of filling different buffers</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Attempt 4</p>
<ul>
<li>
<p>Producer</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    sem_wait(&amp;emptyBuffer); </span><br><span class="line">    sem_wait(&amp;mutex);</span><br><span class="line">    my_i = findempty(&amp;buffer);</span><br><span class="line">    sem_signal(&amp;mutex);</span><br><span class="line">    Fill(&amp;buffer[my_i]); </span><br><span class="line">    sem_signal(&amp;fullBuffer); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Consumer</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123; </span><br><span class="line">    sem_wait(&amp;fullBuffer); </span><br><span class="line">    sem_wait(&amp;mutex);</span><br><span class="line">    my_j = findfull(&amp;buffer); </span><br><span class="line">    sem_signal(&amp;mutex);</span><br><span class="line">    Use(&amp;buffer[my_j]); </span><br><span class="line">    sem_signal(&amp;emptyBuffer); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Advantage</p>
<ul>
<li>Works and increases concurrency; only finding a buffer is protected by mutex;</li>
<li>Filling or Using different buffers can proceed concurrently</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="readerwriter-locks"><a class="markdownIt-Anchor" href="#readerwriter-locks"></a> Reader/Writer Locks</h3>
<ul>
<li>
<p>Idea</p>
<ul>
<li>Let multiple reader threads grab lock (shared)</li>
<li>Only one writer thread can grab lock (exclusive)
<ul>
<li>No reader threads</li>
<li>No other writer threads</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Code</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct_rwlock_t</span> &#123;</span><br><span class="line">    <span class="keyword">sem_t</span> lock; <span class="comment">// reader lock</span></span><br><span class="line">    <span class="keyword">sem_t</span> writelock;</span><br><span class="line">    <span class="keyword">int</span> readers; <span class="comment">// number of readers</span></span><br><span class="line">&#125; <span class="keyword">rwlock_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">rwlock_init</span><span class="params">(<span class="keyword">rwlock_t</span>*rw)</span> </span>&#123;</span><br><span class="line">    rw-&gt;readers = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// initialize locks to 1, similar to mutex initialization</span></span><br><span class="line">    sem_init(&amp;rw-&gt;lock, <span class="number">1</span>);  </span><br><span class="line">    sem_init(&amp;rw-&gt;writelock, <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">rwlock_acquire_readlock</span><span class="params">(<span class="keyword">rwlock_t</span> *rw)</span> </span>&#123; </span><br><span class="line">    sem_wait(&amp;rw-&gt;lock); </span><br><span class="line">    rw-&gt;readers++; </span><br><span class="line">    <span class="keyword">if</span> (rw-&gt;readers == <span class="number">1</span>) </span><br><span class="line">        sem_wait(&amp;rw-&gt;writelock); </span><br><span class="line">    sem_post(&amp;rw-&gt;lock); </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">rwlock_release_readlock</span><span class="params">(<span class="keyword">rwlock_t</span> *rw)</span> </span>&#123; </span><br><span class="line">    sem_wait(&amp;rw-&gt;lock); </span><br><span class="line">    rw-&gt;readers--; </span><br><span class="line">    <span class="keyword">if</span> (rw-&gt;readers == <span class="number">0</span>) </span><br><span class="line">        sem_post(&amp;rw-&gt;writelock); <span class="comment">// let other writes</span></span><br><span class="line">    sem_post(&amp;rw-&gt;lock); </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">rwlock_acquire_writelock</span><span class="params">(<span class="keyword">rwlock_t</span> *rw)</span> </span>&#123;</span><br><span class="line">    sem_wait(&amp;rw-&gt;writelock); </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">rwlock_release_writelock</span><span class="params">(<span class="keyword">rwlock_t</span> *rw)</span> </span>&#123;</span><br><span class="line">    sem_post(&amp;rw-&gt;writelock); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Example</p>
<table>
<thead>
<tr>
<th>Time</th>
<th>Current Action</th>
<th>lock</th>
<th>writelock</th>
<th>readers</th>
</tr>
</thead>
<tbody>
<tr>
<td>Initial</td>
<td></td>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>T1 <code>acquire_readlock</code></td>
<td><del>0</del> 1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>T2 <code>acquire_readlock</code></td>
<td><del>0</del> 1</td>
<td>0</td>
<td>2</td>
</tr>
<tr>
<td>3</td>
<td>T3 <code>acquire_writelock</code></td>
<td>1</td>
<td>-1</td>
<td>2</td>
</tr>
<tr>
<td>4</td>
<td>T1 <code>release_readlock</code></td>
<td><del>0</del> 1</td>
<td>-1</td>
<td>1</td>
</tr>
<tr>
<td>5</td>
<td>T2 <code>release_readlock</code></td>
<td><del>0</del> 1</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
</li>
<li>
<p>Quiz 1</p>
<ul>
<li>T1: <code>acquire_readlock()</code> =&gt; T1 running</li>
<li>T2: <code>acquire_readlock()</code> =&gt; T2 running</li>
<li>T3: <code>acquire_writelock()</code> =&gt; T3 blocked, waiting for write lock</li>
</ul>
</li>
<li>
<p>Quiz 2</p>
<ul>
<li>T6: <code>acquire_writelock()</code> =&gt; T6 running</li>
<li>T4: <code>acquire_readlock()</code> =&gt; T4 blocked, waiting for read lock</li>
<li>T5: <code>acquire_readlock()</code> =&gt; T5 blocked, waiting for read lock</li>
</ul>
</li>
</ul>
<h3 id="build-zemaphore-from-lock-and-cv"><a class="markdownIt-Anchor" href="#build-zemaphore-from-lock-and-cv"></a> Build Zemaphore from Lock and CV</h3>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span> </span><br><span class="line">    <span class="keyword">int</span> value; </span><br><span class="line">    <span class="keyword">cond_t</span> cond; </span><br><span class="line">    <span class="keyword">lock_t</span> lock; </span><br><span class="line">&#125; <span class="keyword">zem_t</span>; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">zem_init</span><span class="params">(<span class="keyword">zem_t</span> *z, <span class="keyword">int</span> value)</span> </span>&#123; </span><br><span class="line">    z-&gt;value = value; </span><br><span class="line">    cond_init(&amp;z-&gt;cond); </span><br><span class="line">    lock_init(&amp;z-&gt;lock); </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">// waits until value &gt; 0. and decrement</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">zem_wait</span><span class="params">(<span class="keyword">zem_t</span> *z)</span> </span>&#123; </span><br><span class="line">    lock_acquire(&amp;z-&gt;lock); </span><br><span class="line">    z-&gt;value--; </span><br><span class="line">    <span class="keyword">while</span> (z-&gt;value &lt; <span class="number">0</span>) </span><br><span class="line">       cond_wait(&amp;z-&gt;cond); </span><br><span class="line">    lock_release(&amp;z-&gt;lock); </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">// increment value, then wake a single waiter</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">zem_post</span><span class="params">(<span class="keyword">zem_t</span> *z)</span> </span>&#123; </span><br><span class="line">    lock_acquire(&amp;z-&gt;lock); </span><br><span class="line">    z-&gt;value++; </span><br><span class="line">    cond_signal(&amp;z-&gt;cond); </span><br><span class="line">    lock_release(&amp;z-&gt;lock); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="summary-3"><a class="markdownIt-Anchor" href="#summary-3"></a> Summary</h3>
<ul>
<li>
<p>Semaphores are equivalent to locks + condition variables</p>
<ul>
<li>Can be used for both mutual exclusion and ordering</li>
</ul>
</li>
<li>
<p>Semaphores contain state</p>
<ul>
<li>How they are initialized depends on how they will be used</li>
<li>Init to 0: Join (1 thread must arrive first, then other)</li>
<li>Init to N: Number of available resources</li>
</ul>
</li>
<li>
<p>sem_wait(): Decrement and waits until value &gt;= 0</p>
</li>
<li>
<p>sem_post(): Increment value, then wake a single waiter (atomic)</p>
</li>
<li>
<p>Can use semaphores in producer/consumer and for reader/writer locks</p>
</li>
</ul>
<h2 id="concurrency-bugs"><a class="markdownIt-Anchor" href="#concurrency-bugs"></a> Concurrency Bugs</h2>
<h3 id="concurrency-in-medicine-therac-25-1980s"><a class="markdownIt-Anchor" href="#concurrency-in-medicine-therac-25-1980s"></a> Concurrency in Medicine: Therac-25 (1980’s)</h3>
<blockquote>
<p>“The accidents occurred when the high-power electron beam was activated<br>
instead of the intended low power beam, and without the beam spreader plate<br>
rotated into place. Previous models had hardware interlocks in place to prevent<br>
this, but Therac-25 had removed them, depending instead on software interlocks<br>
for safety. The software interlock could fail due to a race condition.”</p>
</blockquote>
<blockquote>
<p>“…in three cases, the injured patients later died.”</p>
</blockquote>
<ul>
<li>Source: <a href="http://en.wikipedia.org/wiki/Therac-25" target="_blank" rel="noopener">http://en.wikipedia.org/wiki/Therac-25</a></li>
</ul>
<h3 id="concurrency-study"><a class="markdownIt-Anchor" href="#concurrency-study"></a> Concurrency Study</h3>
<p><img src="https://i.imgur.com/77XWz8c.png" alt=""></p>
<h3 id="atomicity-mysql"><a class="markdownIt-Anchor" href="#atomicity-mysql"></a> Atomicity: MySQL</h3>
<ul>
<li>
<p>Bug</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Thread 1</span></span><br><span class="line"><span class="keyword">if</span> (thd-&gt;proc_info) &#123;</span><br><span class="line"> <span class="comment">// ...</span></span><br><span class="line"> <span class="built_in">fputs</span>(thd-&gt;proc_info, <span class="comment">/*...*/</span>);</span><br><span class="line"> <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Thread 2</span></span><br><span class="line">thd-&gt;proc_info = <span class="literal">NULL</span>;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Fix</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Thread 1</span></span><br><span class="line">pthread_mutex_lock(&amp;lock);</span><br><span class="line"><span class="keyword">if</span> (thd-&gt;proc_info) &#123;</span><br><span class="line"> <span class="comment">// ...</span></span><br><span class="line"> <span class="built_in">fputs</span>(thd-&gt;proc_info, <span class="comment">/*...*/</span>);</span><br><span class="line"> <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line">pthread_mutex_unlock(&amp;lock);</span><br></pre></td></tr></table></figure>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Thread 2</span></span><br><span class="line">pthread_mutex_lock(&amp;lock);</span><br><span class="line">thd-&gt;proc_info = <span class="literal">NULL</span>;</span><br><span class="line">pthread_mutex_unlock(&amp;lock);</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="ordering-mozilla"><a class="markdownIt-Anchor" href="#ordering-mozilla"></a> Ordering: Mozilla</h3>
<ul>
<li>
<p>Bug</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Thread 1</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123; </span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    mThread = PR_CreateThread(mMain, <span class="comment">/*...*/</span>);</span><br><span class="line">    <span class="comment">// ...  </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Thread 2</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">mMain</span><span class="params">(<span class="comment">/*...*/</span>)</span> </span>&#123; </span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    mState = mThread-&gt;State;</span><br><span class="line">    <span class="comment">// ...  </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Fix</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Thread 1</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123; </span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    mThread = PR_CreateThread(mMain, <span class="comment">/*...*/</span>);</span><br><span class="line"></span><br><span class="line">    pthread_mutex_lock(&amp;mtLock);</span><br><span class="line">    mtInit = <span class="number">1</span>; </span><br><span class="line">    pthread_cond_signal(&amp;mtCond);</span><br><span class="line">    pthread_mutex_unlock(&amp;mtLock);  </span><br><span class="line">    <span class="comment">// ...  </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Thread 2</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">mMain</span><span class="params">(<span class="comment">/*...*/</span>)</span> </span>&#123; </span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    pthread_mutex_lock(&amp;mtLock);</span><br><span class="line">    <span class="keyword">while</span> (mtInit == <span class="number">0</span>) </span><br><span class="line">        pthread_cond_wait(&amp;mtCond, &amp;mtLock);  </span><br><span class="line">    pthread_mutex_unlock(&amp;mtLock);  </span><br><span class="line">    </span><br><span class="line">    mState = mThread-&gt;State;</span><br><span class="line">    <span class="comment">// ...  </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="deadlock"><a class="markdownIt-Anchor" href="#deadlock"></a> Deadlock</h2>
<h3 id="definition"><a class="markdownIt-Anchor" href="#definition"></a> Definition</h3>
<ul>
<li>No progress can be made because two or more threads are waiting for the other to take some action and thus neither ever does</li>
</ul>
<h3 id="example-1-circular-dependency"><a class="markdownIt-Anchor" href="#example-1-circular-dependency"></a> Example 1: Circular Dependency</h3>
<ul>
<li>
<p>Code</p>
<table>
<thead>
<tr>
<th>Thread 1</th>
<th>Thread 2</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>lock(&amp;A);</code> <br><br><br> <code>lock(&amp;B);</code>(blocked)</td>
<td><br><code>lock(&amp;B);</code>  <br> <code>lock(&amp;A);</code>(blocked)<br><br></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>Circular Dependency<br>
<img src="https://i.imgur.com/dG4Krbd.png" alt=""></p>
<ul>
<li>Cycle in dependency graph -&gt; possible to have deadlock</li>
</ul>
</li>
<li>
<p>Fix Deadlock Code</p>
<table>
<thead>
<tr>
<th>Thread 1</th>
<th>Thread 2</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>lock(&amp;A);</code> <br><code>lock(&amp;B);</code></td>
<td><code>lock(&amp;A);</code>  <br> <code>lock(&amp;A);</code></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>Non-Circular Dependency<br>
<img src="https://i.imgur.com/yJibQZG.png" alt=""></p>
</li>
</ul>
<h3 id="example-2-encapsulation"><a class="markdownIt-Anchor" href="#example-2-encapsulation"></a> Example 2: Encapsulation</h3>
<ul>
<li>Code</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set_t</span> *set_intersection(<span class="keyword">set_t</span> *s1, <span class="keyword">set_t</span> *s2) &#123;</span><br><span class="line">   <span class="keyword">set_t</span> *rv = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(*rv));</span><br><span class="line">   mutex_lock(&amp;s1-&gt;lock);</span><br><span class="line">   mutex_lock(&amp;s2-&gt;lock);</span><br><span class="line">   <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; s1-&gt;len; i++) &#123;</span><br><span class="line">      <span class="keyword">if</span> (set_contains(s2, s1-&gt;items[i])) &#123;</span><br><span class="line">         set_add(rv, s1-&gt;items[i]);</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   mutex_unlock(&amp;s2-&gt;lock);</span><br><span class="line">   mutex_unlock(&amp;s1-&gt;lock);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>Deadlock scenario</p>
<ul>
<li>Thread 1: <code>rv = set_intersection(setA, setB);</code></li>
<li>Thread 2: <code>rv = set_intersection(setB, setA);</code></li>
</ul>
</li>
<li>
<p>Encapsulation</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (m1 &gt; m2) &#123;</span><br><span class="line">  <span class="comment">// grab locks in high-to-low address order</span></span><br><span class="line">  pthread_mutex_lock(m1);</span><br><span class="line">  pthread_mutex_lock(m2);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  pthread_mutex_lock(m2);</span><br><span class="line">  pthread_mutex_lock(m1);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Problem: Deadlock happens when <code>m1 == m2</code></li>
</ul>
</li>
</ul>
<h3 id="deadlock-theory"><a class="markdownIt-Anchor" href="#deadlock-theory"></a> Deadlock Theory</h3>
<ul>
<li>
<p>Deadlocks can only happen with these four conditions:</p>
<ol>
<li>mutual exclusion</li>
<li>hold-and-wait</li>
<li>no preemption</li>
<li>circular wait</li>
</ol>
</li>
<li>
<p>Can eliminate deadlock by eliminating any one condition</p>
</li>
</ul>
<h3 id="1-mutual-exclusion"><a class="markdownIt-Anchor" href="#1-mutual-exclusion"></a> 1. Mutual Exclusion</h3>
<ul>
<li>
<p>Problem: Threads claim exclusive control of resources that they require</p>
</li>
<li>
<p>Strategy: Eliminate locks! Replace locks with atomic primitive</p>
</li>
<li>
<p>Lock-free <code>add</code></p>
<ul>
<li>
<p>Implement <code>add</code> using lock</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> *val, <span class="keyword">int</span> amt)</span> </span>&#123;</span><br><span class="line">  Mutex_lock(&amp;m);</span><br><span class="line">  *val += amt;</span><br><span class="line">  Mutex_unlock(&amp;m);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Atomic primitive <code>CompareAndSwap</code></p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">CompareAndSwap</span><span class="params">(<span class="keyword">int</span> *address, <span class="keyword">int</span> expected, <span class="keyword">int</span> <span class="keyword">new</span>)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (*address == expected) &#123;</span><br><span class="line">    *address = <span class="keyword">new</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;  <span class="comment">// success</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;  <span class="comment">// failure</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Implement <code>add</code> without lock</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> *val, <span class="keyword">int</span> amt)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">do</span> &#123;</span><br><span class="line">    <span class="keyword">int</span> old = *value;</span><br><span class="line">  &#125; <span class="keyword">while</span> (!CompareAndSwap(val, old, old + amt);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li>
<p>Wait-free Linked List Insert</p>
<ul>
<li>
<p>Implement <code>insert</code> using lock</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">insert</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">node_t</span> *n = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(*n));</span><br><span class="line">  n-&gt;val = val;</span><br><span class="line">  lock(&amp;m);</span><br><span class="line">  n-&gt;next = head;</span><br><span class="line">  head = n;</span><br><span class="line">  unlock(&amp;m);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Implement <code>insert</code> using while loop</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">insert</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">node_t</span> *n = Malloc(<span class="keyword">sizeof</span>(*n));</span><br><span class="line">  n-&gt;val = val;</span><br><span class="line">  <span class="keyword">do</span> &#123;</span><br><span class="line">    n-&gt;next = head;</span><br><span class="line">  &#125; <span class="keyword">while</span> (!CompareAndSwap(&amp;head, n-&gt;next, n));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h3 id="2-hold-and-wait"><a class="markdownIt-Anchor" href="#2-hold-and-wait"></a> 2. Hold and Wait</h3>
<ul>
<li>
<p>Problem: Threads hold resources allocated to them while waiting for additional resources</p>
</li>
<li>
<p>Strategy: Acquire all locks atomically once. Can release locks over time, but cannot acquire again until all have been released</p>
</li>
<li>
<p>How to do this? Use a meta lock:</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lock(&amp;meta);</span><br><span class="line">lock(&amp;L1); <span class="comment">/*...*/</span> lock(&amp;L10);</span><br><span class="line">unlock(&amp;L10); <span class="comment">/*...*/</span> unlock(&amp;L1);</span><br><span class="line">unlock(&amp;meta);</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Disadvantages</p>
<ul>
<li>Locks are not fine-grained</li>
</ul>
</li>
</ul>
<h3 id="3-no-preemption"><a class="markdownIt-Anchor" href="#3-no-preemption"></a> 3. No Preemption</h3>
<ul>
<li>
<p>Problem: Resources (e.g., locks) cannot be forcibly removed from threads that are</p>
</li>
<li>
<p>Strategy: if thread can’t get what it wants, release what it holds</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">top: </span><br><span class="line">lock(A);</span><br><span class="line"><span class="keyword">if</span> (trylock(B) == <span class="number">-1</span>) &#123; <span class="comment">// try to lock B</span></span><br><span class="line">  unlock(A); <span class="comment">// if failed, also unlock A</span></span><br><span class="line">  <span class="keyword">goto</span> top;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Disadvantages</p>
<ul>
<li>Live lock: A situation in which two or more processes continuously change their states in response to changes in the other process(es) without doing any useful work</li>
</ul>
</li>
</ul>
<h3 id="circular-wait"><a class="markdownIt-Anchor" href="#circular-wait"></a> Circular Wait</h3>
<ul>
<li>
<p>Circular chain of threads such that each thread holds a resource (e.g., lock)<br>
being requested by next thread in the chain.</p>
</li>
<li>
<p>Strategy:</p>
<ul>
<li>decide which locks should be acquired before others</li>
<li>if A before B, never acquire A if B is already held!</li>
<li>document this, and write code accordingly</li>
</ul>
</li>
<li>
<p>Works well if system has distinct layers</p>
</li>
</ul>
<h2 id="concurrent-data-structures"><a class="markdownIt-Anchor" href="#concurrent-data-structures"></a> Concurrent Data Structures</h2>
<h3 id="scalability-measure"><a class="markdownIt-Anchor" href="#scalability-measure"></a> Scalability Measure</h3>
<ul>
<li>
<p>N times as much work on N cores as done on 1 core.</p>
</li>
<li>
<p>Strong scalability</p>
<ul>
<li>
<p>Fix input size, increase number of cores, can have better performance</p>
</li>
<li>
<p>e.g. Matrix multiplication: <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>A</mi><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow></msub><mo>×</mo><msub><mi>B</mi><mrow><mi>n</mi><mo>×</mo><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_{m\times n}\times B_{n\times d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.891661em;vertical-align:-0.208331em;"></span><span class="base"><span class="mord"><span class="mord mathit">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.25833100000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">m</span><span class="mbin mtight">×</span><span class="mord mathit mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"></span></span></span></span></span><span class="mord rule" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mord rule" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathit" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">n</span><span class="mbin mtight">×</span><span class="mord mathit mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"></span></span></span></span></span></span></span></span> requires <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>m</mi><mi>n</mi><mi>d</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">O(mnd)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathit">m</span><span class="mord mathit">n</span><span class="mord mathit">d</span><span class="mclose">)</span></span></span></span> FLOPS (floating point operations per second)</p>
</li>
</ul>
  <pre>
 Time 
   ^
   |
   |     **
   |     **
   |     **
   |     **
   |     **     **
   |     **     **
   |     **     **     **
   |     **     **     **     **
   +-----++-----++-----++-----++----> Number of Cores
   0     1      2      3      4
</pre></li>
</ul>

<ul>
<li>
<p>Weak scaling:</p>
<ul>
<li>
<p>Increase input size with number of cores</p>
</li>
<li>
<p>e.g. Matrix multiplication</p>
</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>A</th>
<th>B</th>
<th>FLOPS</th>
</tr>
</thead>
<tbody>
<tr>
<td>1 core</td>
<td>100 × 100</td>
<td>100 × 100</td>
<td>10<sup>6</sup></td>
</tr>
<tr>
<td>2 core</td>
<td>100 × 200</td>
<td>200 × 100</td>
<td>2×10<sup>6</sup></td>
</tr>
<tr>
<td>3 core</td>
<td>100 × 300</td>
<td>300 × 100</td>
<td>2×10<sup>6</sup></td>
</tr>
<tr>
<td>4 core</td>
<td>100 × 400</td>
<td>400 × 100</td>
<td>4×10<sup>6</sup></td>
</tr>
</tbody>
</table>
  <pre>
 Time 
   ^
   |
   |     **     **     **     **
   |     **     **     **     **
   |     **     **     **     **
   |     **     **     **     **
   |     **     **     **     **
   |     **     **     **     **
   |     **     **     **     **
   |     **     **     **     **
   +-----++-----++-----++-----++----> Number of Cores
   0     1      2      3      4
  </pre>
</li>
</ul>
<h3 id="counter"><a class="markdownIt-Anchor" href="#counter"></a> Counter</h3>
<ul>
<li>
<p>Non-thread-safe Counter</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> __<span class="title">counter_t</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> value;</span><br><span class="line">&#125; <span class="keyword">counter_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">(<span class="keyword">counter_t</span> * c)</span> </span>&#123;</span><br><span class="line">    c-&gt;value = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">increment</span><span class="params">(<span class="keyword">counter_t</span> * c)</span> </span>&#123;</span><br><span class="line">    c-&gt;value++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">get</span><span class="params">(<span class="keyword">counter_t</span> * c)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> c-&gt;value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>Problem: Two threads calls <code>increment</code> at the same time</li>
</ul>
</li>
<li>
<p>Thread-safe counter</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> __<span class="title">counter_t</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> value;</span><br><span class="line">    <span class="keyword">pthread_mutex_t</span> lock;</span><br><span class="line">&#125; <span class="keyword">counter_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">(<span class="keyword">counter_t</span> * c)</span> </span>&#123;</span><br><span class="line">    c-&gt;value = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">increment</span><span class="params">(<span class="keyword">counter_t</span> * c)</span> </span>&#123;</span><br><span class="line">    Pthread_mutex_lock(&amp;c-&gt;lock);</span><br><span class="line">    c-&gt;value++;</span><br><span class="line">    Pthread_mutex_unlock(&amp;c-&gt;lock);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">get</span><span class="params">(<span class="keyword">counter_t</span> * c)</span> </span>&#123;</span><br><span class="line">    Pthread_mutex_lock(&amp;c-&gt;lock);</span><br><span class="line">    <span class="keyword">return</span> c-&gt;value;</span><br><span class="line">    Pthread_mutex_unlock(&amp;c-&gt;lock);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Linearizability</p>
<ul>
<li>
<p>Even if two threads execute in parallel on multiple cores, the effect that you see should be as if all of them are executed in some linear order.</p>
</li>
<li>
<p>Example: T1 and T2 call <code>increment</code> first, then T3 calls <code>get</code>.</p>
</li>
<li>
<p>Since T3 arrived after T1 and T2, we would want T3 to see the values after T1 and T2 have finished executing as if these were three instructions executed by a single processor</p>
</li>
</ul>
</li>
<li>
<p>The Underlying Problem</p>
<ul>
<li>Ticket lock</li>
</ul>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">spinlock_t</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> current_ticket; <span class="comment">// turn</span></span><br><span class="line">    <span class="keyword">int</span> next_ticket;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">spin_lock</span><span class="params">(<span class="keyword">spinlock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    t = atomic_inc(lock-&gt;next_ticket)</span><br><span class="line">    <span class="keyword">while</span> (t != lock-&gt;current_ticket); <span class="comment">// spin</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">spin_unlock</span><span class="params">(<span class="keyword">spinlock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    lock-&gt;current_ticket++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>If one of the thread holds the lock,  all of the other threads need to check the lock</li>
<li>So each lock acquisition becomes more and more expensive as you go from like two to four to eight…</li>
</ul>
</li>
</ul>
<h3 id="approximate-counter-sloppy-counter"><a class="markdownIt-Anchor" href="#approximate-counter-sloppy-counter"></a> Approximate Counter (Sloppy Counter)</h3>
<ul>
<li>
<p>Motivation</p>
<ul>
<li>with standard thread-safe counter (strongest possible consistency) performance is poor under multithreads. Scalability is poor.</li>
<li>Cross-core messages are expensive under multicore system (Conclusion from “An analysis of Linux Scalability to Many Cores - Boyd-Wickizer et. al OSDI 2010, in the article they use 48core machine to benchmark linux”). This is because ticket lock in linux: if one of the core holds the lock all other cores need to check with this core holdiing the lock what is the next turn value going to be. We want to reduce the number of cross-core messages, which is very expensive under this situation. One way is to relax consistency.</li>
</ul>
</li>
<li>
<p>Idea</p>
<ul>
<li>Maintain a counter per-core and a global counter</li>
<li>Global counter lock</li>
<li>Per-core locks if more than 1 thread per-core</li>
</ul>
</li>
<li>
<p>Increment:</p>
<ul>
<li>update local counters at threshold update global</li>
</ul>
</li>
<li>
<p>Read:</p>
<ul>
<li>global counter (maybe inaccurate?)</li>
</ul>
</li>
<li>
<p>Code</p>
</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> __<span class="title">counter_t</span> &#123;</span></span><br><span class="line">  <span class="keyword">int</span> global;                      <span class="comment">// global count</span></span><br><span class="line">  <span class="keyword">pthread_mutex_t</span> glock;           <span class="comment">// global lock</span></span><br><span class="line">  <span class="keyword">int</span> local[NUMCPUS];              <span class="comment">// local count (per cpu)</span></span><br><span class="line">  <span class="keyword">pthread_mutex_t</span> llock[NUMCPUS];  <span class="comment">// ... and locks</span></span><br><span class="line">  <span class="keyword">int</span> threshold;                   <span class="comment">// update frequency</span></span><br><span class="line">&#125; <span class="keyword">counter_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// init: record threshold, init locks, init values of all local counts and</span></span><br><span class="line"><span class="comment">// global count</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">(<span class="keyword">counter_t</span>* c, <span class="keyword">int</span> threshold)</span> </span>&#123;</span><br><span class="line">  c-&gt;threshold = threshold;</span><br><span class="line">  c-&gt;global = <span class="number">0</span>;</span><br><span class="line">  pthread_mutex_init(&amp;c-&gt;glock, <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; NUMCPUS; i++) &#123;</span><br><span class="line">    c-&gt;local[i] = <span class="number">0</span>;</span><br><span class="line">    pthread_mutex_init(&amp;c-&gt;llock[i], <span class="literal">NULL</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// usually, just grab local lock and update local amount once local</span></span><br><span class="line"><span class="comment">// count has risen by ’threshold’, grab global lock and transfer local values to it</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">update</span><span class="params">(<span class="keyword">counter_t</span>* c, <span class="keyword">int</span> threadID, <span class="keyword">int</span> amt)</span> </span>&#123;</span><br><span class="line">  pthread_mutex_lock(&amp;c-&gt;llock[threadID]);</span><br><span class="line">  c-&gt;local[threadID] += amt;                 <span class="comment">// assumes amt &gt; 0</span></span><br><span class="line">  <span class="keyword">if</span> (c-&gt;local[threadID] &gt;= c-&gt;threshold) &#123;  <span class="comment">// transfer to global</span></span><br><span class="line">    pthread_mutex_lock(&amp;c-&gt;glock);</span><br><span class="line">    c-&gt;global += c-&gt;local[threadID];</span><br><span class="line">    pthread_mutex_unlock(&amp;c-&gt;glock);</span><br><span class="line">    c-&gt;local[threadID] = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  pthread_mutex_unlock(&amp;c-&gt;llock[threadID]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// get: just return global amount (which may not be perfect)</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">get</span><span class="params">(<span class="keyword">counter_t</span>* c)</span> </span>&#123;</span><br><span class="line">  pthread_mutex_lock(&amp;c-&gt;glock);</span><br><span class="line">  <span class="keyword">int</span> val = c-&gt;global;</span><br><span class="line">  pthread_mutex_unlock(&amp;c-&gt;glock);</span><br><span class="line">  <span class="keyword">return</span> val;  <span class="comment">// only approximate!</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="concurrent-linked-list"><a class="markdownIt-Anchor" href="#concurrent-linked-list"></a> Concurrent Linked List</h3>
<ul>
<li>
<p>First Attempt</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">List_Insert</span><span class="params">(<span class="keyword">list_t</span> *L, <span class="keyword">int</span> key)</span> </span>&#123;</span><br><span class="line">  pthread_mutex_lock(&amp;L-&gt;lock);</span><br><span class="line">  <span class="keyword">node_t</span> *<span class="keyword">new</span> = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">node_t</span>));</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">new</span> == <span class="literal">NULL</span>) &#123;</span><br><span class="line">    perror(<span class="string">"malloc"</span>);</span><br><span class="line">    pthread_mutex_unlock(&amp;L-&gt;lock);</span><br><span class="line">    <span class="keyword">return</span>;  <span class="comment">//  fail</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">new</span>-&gt;key = key;</span><br><span class="line">  <span class="keyword">new</span>-&gt;next = L-&gt;head;</span><br><span class="line">  L-&gt;head = <span class="keyword">new</span>;</span><br><span class="line">  pthread_mutex_unlock(&amp;L-&gt;lock);</span><br><span class="line">  <span class="keyword">return</span>;  <span class="comment">//  success</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Better Implementation (Shorter Critical Section)</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">List_Insert</span><span class="params">(<span class="keyword">list_t</span> *L, <span class="keyword">int</span> key)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">node_t</span> *<span class="keyword">new</span> = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">node_t</span>));</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">new</span> == <span class="literal">NULL</span>) &#123;</span><br><span class="line">    perror(<span class="string">"malloc"</span>);</span><br><span class="line">    <span class="keyword">return</span>;  <span class="comment">//  fail</span></span><br><span class="line">  &#125;</span><br><span class="line">  pthread_mutex_lock(&amp;L-&gt;lock);</span><br><span class="line">  <span class="keyword">new</span>-&gt;key = key;</span><br><span class="line">  <span class="keyword">new</span>-&gt;next = L-&gt;head;</span><br><span class="line">  L-&gt;head = <span class="keyword">new</span>;</span><br><span class="line">  pthread_mutex_unlock(&amp;L-&gt;lock);</span><br><span class="line">  <span class="keyword">return</span>;  <span class="comment">//  success</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="hash-table-from-list"><a class="markdownIt-Anchor" href="#hash-table-from-list"></a> Hash Table from List</h3>
<ul>
<li>
<p>Idea</p>
<ul>
<li>Avoid contention by using different locks in each buckets — more fine-grained locks &amp; reduce cross threads contentions, leads to better scalling under multithreads performane</li>
</ul>
</li>
<li>
<p>Code</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> BUCKETS (101)</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> __<span class="title">hash_t</span> &#123;</span></span><br><span class="line">  <span class="keyword">list_t</span> lists[BUCKETS];</span><br><span class="line">&#125; <span class="keyword">hash_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">Hash_Insert</span><span class="params">(<span class="keyword">hash_t</span> *H, <span class="keyword">int</span> key)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> bucket = key % BUCKETS;</span><br><span class="line">  <span class="keyword">return</span> List_Insert(&amp;H-&gt;lists[bucket], key);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="concurrent-queue"><a class="markdownIt-Anchor" href="#concurrent-queue"></a> Concurrent Queue</h3>
<ul>
<li>Idea: use 2 locks to ensure that threads can enqueue/dequeue without conflicting with each other</li>
<li>One more thing to check in the following implementation: when there is only 1 elment – head and tail points to the same thing in queue, grab both locks</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Queue_Enqueue</span><span class="params">(<span class="keyword">queue_t</span> *q, <span class="keyword">int</span> value)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">node_t</span> *tmp = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">node_t</span>));</span><br><span class="line">  assert(tmp != <span class="literal">NULL</span>);</span><br><span class="line">  tmp-&gt;value = value;</span><br><span class="line">  tmp-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">  pthread_mutex_lock(&amp;q-&gt;tailLock);</span><br><span class="line">  q-&gt;tail-&gt;next = tmp;</span><br><span class="line">  q-&gt;tail = tmp;</span><br><span class="line">  pthread_mutex_unlock(&amp;q-&gt;tailLock);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">Queue_Dequeue</span><span class="params">(<span class="keyword">queue_t</span> *q, <span class="keyword">int</span> *value)</span> </span>&#123;</span><br><span class="line">  pthread_mutex_lock(&amp;q-&gt;headLock);</span><br><span class="line">  <span class="keyword">node_t</span> *tmp = q-&gt;head;</span><br><span class="line">  <span class="keyword">node_t</span> *newHead = tmp-&gt;next;</span><br><span class="line">  <span class="keyword">if</span> (newHead == <span class="literal">NULL</span>) &#123;</span><br><span class="line">    pthread_mutex_unlock(&amp;q-&gt;headLock);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;  <span class="comment">// queue was empty</span></span><br><span class="line">  &#125;</span><br><span class="line">  *value = newHead-&gt;value;</span><br><span class="line">  q-&gt;head = newHead;</span><br><span class="line">  pthread_mutex_unlock(&amp;q-&gt;headLock);</span><br><span class="line">  <span class="built_in">free</span>(tmp);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="summary-4"><a class="markdownIt-Anchor" href="#summary-4"></a> Summary</h3>
<ul>
<li>
<p>Simple approach: Add a lock to each method’s start and end!  example: java keyword synchronized<br>
public synchronized get(){} This kind of synchronoized keyword is very standard in high level language but this may reduce performance under multicore scalablility</p>
</li>
<li>
<p>Check for scalability – weak scaling, strong scaling</p>
</li>
<li>
<p>If you are not happy with scalability properties, try to optimize by: Avoid cross-thread, cross-core traffic, using methods such as</p>
<ul>
<li>Per-core(sloppy) counter, relax consistency</li>
<li>Buckets in hashtable, reduce cross threads contention, more fine grained locks</li>
<li>keep critical section small</li>
<li>not using locks is faster than using locks</li>
</ul>
</li>
</ul>

      
      <!-- reward -->
      
    </div>
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/OS/">OS</a></li></ul>


    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-Boyer–Moore majority vote algorithm" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/03/25/Boyer–Moore majority vote algorithm/"
    >Boyer–Moore majority vote algorithm</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2019/03/25/Boyer–Moore majority vote algorithm/" class="article-date">
  <time datetime="2019-03-25T03:38:32.000Z" itemprop="datePublished">2019-03-24</time>
</a>
      
      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h1 id="boyermoore-majority-vote-algorithm"><a class="markdownIt-Anchor" href="#boyermoore-majority-vote-algorithm"></a> Boyer–Moore majority vote algorithm</h1>
<p>Boyer–Moore majority vote algorithm is an algorithm that finds the majority element and its count from a given sequence in O(N)TIME O(1)SPACE.</p>
<h2 id="pseudocode"><a class="markdownIt-Anchor" href="#pseudocode"></a> Pseudocode</h2>
<ul>
<li>Initialize an element m and a counter i with i = 0</li>
<li>For each element x of the input sequence:
<ul>
<li>If i = 0, then assign m = x and i = 1</li>
<li>else if m = x, then assign i = i + 1</li>
<li>else assign i = i − 1</li>
</ul>
</li>
<li>Return m<br>
初始化major元素 major = arr[0]，counter = 1<br>
遍历序列中每个元素 1:end<br>
if counter == 0 reset: major to be current pointer and counter to be 1<br>
else if major == current element increment counter<br>
else (current element is not major and counter need not to be reset) decrement counter</li>
</ul>
<h2 id="example"><a class="markdownIt-Anchor" href="#example"></a> Example</h2>
<p>Leetcode 169<br>
Given an array of size n, find the majority element. The majority element is the element that appears more than ⌊ n/2 ⌋ times.<br>
You may assume that the array is non-empty and the majority element always exist in the array.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">    public int majorityElement(int[] num) &#123;</span><br><span class="line">        int major=num[0], count = 1;</span><br><span class="line">        for(int i=1; i&lt;num.length;i++)&#123;</span><br><span class="line">            if(count==0)&#123;</span><br><span class="line">                count++;</span><br><span class="line">                major=num[i];</span><br><span class="line">            &#125;else if(major==num[i])&#123;</span><br><span class="line">                count++;</span><br><span class="line">            &#125;else count--;</span><br><span class="line">        &#125;</span><br><span class="line">        return major;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Reference:<br>
<a href="https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_majority_vote_algorithm" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Boyer–Moore_majority_vote_algorithm</a><br>
<a href="https://www.zhihu.com/question/49973163/answer/235921864" target="_blank" rel="noopener">https://www.zhihu.com/question/49973163/answer/235921864</a></p>

      
      <!-- reward -->
      
    </div>
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Algorithm-and-Data-Structures/">Algorithm and Data Structures</a></li></ul>


    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-Threaded Binary Tree and Morris Traversal" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/03/23/Threaded Binary Tree and Morris Traversal/"
    >Threaded Binary Tree and Morris Traversal</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2019/03/23/Threaded Binary Tree and Morris Traversal/" class="article-date">
  <time datetime="2019-03-22T20:58:08.000Z" itemprop="datePublished">2019-03-22</time>
</a>
      
      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h1 id="threaded-binary-tree-and-morris-traversal"><a class="markdownIt-Anchor" href="#threaded-binary-tree-and-morris-traversal"></a> Threaded Binary Tree and Morris Traversal</h1>
<h2 id="motivation"><a class="markdownIt-Anchor" href="#motivation"></a> Motivation</h2>
<p>对于有着空的左孩子右孩子指针的节点 内存被浪费了，所以在TBT里我们利用这些内存来储存一些地址</p>
<h2 id="transform-a-normal-binary-tree-to-tbt"><a class="markdownIt-Anchor" href="#transform-a-normal-binary-tree-to-tbt"></a> Transform a normal binary tree to TBT</h2>
<ol>
<li>最左边最右边的空指针不改动</li>
<li>将其他的空指针改为：
<ul>
<li>
<pre><code>Left ptr = inorder predecessor 因为该节点没有inorder predecessor 中序遍历第一个节点
</code></pre>
</li>
<li>
<pre><code>Right ptr = inorder successor 因为该节点没有inorder successor 中序遍历最后一个节点
</code></pre>
</li>
</ul>
</li>
</ol>
<p><img src="https://i.imgur.com/sr6MQQ7.jpg" alt=""><br>
我们可以在节点里加入两个flag来代表左指针右指针指向的是ancestor还是child<br>
最后对于中序遍历的起点和终点的左右指针 连向dummy node flag设为ancestor<br>
<img src="https://i.imgur.com/OE9qckF.png" alt=""></p>
<p>莫里斯遍历利用线段树的概念可以实现iterative inorder traversal of tree without using stack TIME O(N) SPACE O(1)<br>
Pseudocode</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Initialize current as root </span><br><span class="line">While current is not NULL</span><br><span class="line">   If current does not has a left child</span><br><span class="line">      a) access current&apos;s data</span><br><span class="line">      b) Go to the right, i.e., current = current-&gt;right</span><br><span class="line">   Else</span><br><span class="line">      a) Make current as right child of the rightmost </span><br><span class="line">         node in current&apos;s left subtree</span><br><span class="line">      b) Go to that left child, i.e., current = current-&gt;left  (set current&apos;s left to be null)</span><br></pre></td></tr></table></figure>
<p>LeetCode94: use above method to achieve inorder traversal</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">    public List&lt;Integer&gt; inorderTraversal(TreeNode node) &#123;</span><br><span class="line">        List&lt;Integer&gt; list = new ArrayList();</span><br><span class="line"></span><br><span class="line">        while(node != null) &#123;</span><br><span class="line">            if(node.left == null) &#123;</span><br><span class="line">                list.add(node.val);</span><br><span class="line">                node = node.right;</span><br><span class="line">            &#125;</span><br><span class="line">            else &#123;</span><br><span class="line">                TreeNode nextNode = node.left;</span><br><span class="line">                TreeNode p = node.left;</span><br><span class="line">                while(p.right != null) p = p.right;</span><br><span class="line">                p.right = node;//p:rightmost node in the leftsubtree</span><br><span class="line">                node.left = null;</span><br><span class="line">                node = nextNode;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return list;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
      <!-- reward -->
      
    </div>
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Algorithm-and-Data-Structures/">Algorithm and Data Structures</a></li></ul>


    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-Database" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/03/19/Database/"
    >Database Management System - Relational Design Theory</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2019/03/19/Database/" class="article-date">
  <time datetime="2019-03-18T18:00:41.000Z" itemprop="datePublished">2019-03-18</time>
</a>
      
      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h1 id="cs564-dbms-relational-design-theory"><a class="markdownIt-Anchor" href="#cs564-dbms-relational-design-theory"></a> <strong>CS564 - DBMS - Relational Design Theory</strong></h1>
<h2 id="sql"><a class="markdownIt-Anchor" href="#sql"></a> SQL</h2>
<h3 id="relational-algebra-and-calculus"><a class="markdownIt-Anchor" href="#relational-algebra-and-calculus"></a> Relational algebra and Calculus</h3>
<p><img src="https://i.imgur.com/kksvzjk.png" alt=""></p>
<h3 id="keys"><a class="markdownIt-Anchor" href="#keys"></a> Keys</h3>
<ul>
<li>A<strong>superkey</strong> is a set of one or more attributes that, taken collectively, allow us to identify uniquely a tuple in the relation</li>
<li>Such minimal superkeys are called <strong>candidate keys</strong>.</li>
<li>We shall use the term <strong>primary key</strong> to denote a candidate key that is chosen by the database designer as the principal means of identifying tuples within a relation.</li>
<li><strong>Foreign Key</strong> is a set of attributes in a referencing relation, such that for each tuple in the referencing relation, the values of the foreign key attributes are guaranteed to occur as the primary key value of a tuple in the referenced relation.</li>
</ul>
<h3 id="join"><a class="markdownIt-Anchor" href="#join"></a> Join</h3>
<ul>
<li>natural join combines two tables based on identical columns</li>
<li>Cartesian product operation combines tuples from two relations, but unlike the join operation, its result contains all pairs of tuples from the two relations</li>
</ul>
<h3 id="sql-language"><a class="markdownIt-Anchor" href="#sql-language"></a> SQL Language</h3>
<ul>
<li>SQL allows us to use the keyword all to specify explicitly that duplicates are not removed</li>
<li><strong>varchar(n)</strong>: A variable-length character string with user-specified maximum length n. The full form, character varying, is equivalent.</li>
<li><strong>numeric(p, d)</strong>:Afixed-point numberwith user-specified precision. The number consists of p digits (plus a sign), and d of the p digits are to the right of the decimal point.</li>
<li><strong>Percent (%)</strong>: The % character matches any substring.</li>
<li><strong>Underscore (_)</strong>: The character _ matches any character.</li>
<li>The set operation automatically eliminates duplicates</li>
</ul>
<p><img src="https://i.imgur.com/G2hgY3K.png" alt=""></p>
<h2 id="database-design-er-model"><a class="markdownIt-Anchor" href="#database-design-er-model"></a> Database Design (ER Model)</h2>
<h3 id="terms"><a class="markdownIt-Anchor" href="#terms"></a> Terms</h3>
<ul>
<li>Entity</li>
<li>Attribute
<ul>
<li>Domain</li>
<li>Key</li>
<li>Primary Key can not be null</li>
</ul>
</li>
<li>Relationship
<ul>
<li>Descriptive attribute, the attribute of the entity in between two entities</li>
<li>A relationship should be uniquely identified</li>
<li>Instance of relationship set is a set of relationships</li>
<li>Sometimes a relationship can involve two identities in the same enetity set</li>
</ul>
</li>
<li>Constraints
<ul>
<li>Participation constraint, total, partial</li>
<li>weak enetity set</li>
<li>ISA inheritance relationship set
<ul>
<li>specialzation, generalization</li>
<li>overlap, covering constraint</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="the-relational-model"><a class="markdownIt-Anchor" href="#the-relational-model"></a> The Relational Model</h3>
<ul>
<li>Integrity Constriant
<ul>
<li>Foreign key constraint</li>
</ul>
</li>
</ul>
<h2 id="relational-design-theory"><a class="markdownIt-Anchor" href="#relational-design-theory"></a> Relational Design Theory</h2>
<h3 id="函数依赖-functional-dependency"><a class="markdownIt-Anchor" href="#函数依赖-functional-dependency"></a> 函数依赖 Functional Dependency</h3>
<ul>
<li>
<p>考虑如下的university database schema<br>
<img src="https://i.imgur.com/rjGtPin.png" width="500" height="200"><br>
将表instructor和department替换为其自然连接的结果不是一个好的选择<br>
<img src="https://i.imgur.com/JltoS4y.png" width="400"><br>
因为对于每个instructor都有部门budget信息大量重复 我们需要保证任何更新操作都要同步budget。 另一个缺点是natural inner join会去除左右两边为null的情况，所以没有instructor的部门就无法在表中被表示。<br>
<strong>但如果我们先有inst_dept表，我们该如何知道这个设计不好并且应该被分解成instructor和department呢？</strong><br>
我们需要发现每个department必须只有1个building,每个department必须只有一个budget。<br>
Not every ER design can be precise enough to avoid such problems，so we need to allow designers to specify rules such as “<strong>each specific value of dept_name corresponds to at most one budget</strong>” even in cases where dept_name is not the primary key for the schema.<br>
In this case, we need to write a rule “<strong>if there were a schema(dept_name,budget),then dept_name is able to serve as the primary key</strong>.” This rule is specified as a functional dependency:<br>
<img src="https://i.imgur.com/aaCGsjY.png" width="250"><br>
This gives sufficient information to recognize the problem of inst_dept schema. Therefore functional dependency says what relational instances are allowed under certain constraints.<br>
Functional depedency generalizes notions of key in a relation. It depicts relationship between attributes.</p>
</li>
<li>
<p><strong>Definition</strong>: A relational instance satisfies functional dependency from attribute A-&gt;B if (any) two tuples having same value of attribute A also have same value of attribute B. i.e. A uniquely determines B</p>
</li>
<li>
<p><strong>A trivial functional dependency</strong> is the one which will always hold in a relation. <strong>A-&gt;B and B is a subset of A.</strong></p>
</li>
<li>
<p><strong>Non-Trivial functional dependency</strong> may or may not hold in a relation. <strong>A-&gt;B and B is NOT a subset of A.</strong></p>
</li>
<li>
<p><strong>Properties of functional dependency</strong><br>
“Armstrong’s Axioms”<br>
<img src="https://i.imgur.com/zkhjneI.png" alt=""><br>
Other<br>
<img src="https://i.imgur.com/nNsRewf.png" alt=""><br>
<img src="https://i.imgur.com/D9pWMoO.png" alt=""></p>
</li>
<li>
<p><strong>&quot;A set of functional dependencies&quot; F</strong> is a set of FD constraints on legal relational instances in a relation.</p>
</li>
<li>
<p><strong>&quot;The closure of FDs set F&quot; F+</strong> is a set of all FDs that can be inferred from given the set F (<strong>Note that this includes all FDs in F itself</strong>).</p>
</li>
<li>
<p><strong>Attribute Closure</strong>: Attribute closure of an attribute set A is a set of all attributes that can be functionally determined from elements of set A (<strong>Note that this includes attributes in A itself</strong>).<br>
Examples:<br>
<img src="https://i.imgur.com/hf0hLCc.png" alt=""></p>
</li>
<li>
<p><strong>Determining equivalence of functional dependencies</strong><br>
Check whether 2 FD sets are subset of each other’s closure.</p>
</li>
<li>
<p><strong>Computing minimal cover</strong><br>
A minimal cover of a FD set A is the smallest set of FDs that covers A.<br>
<img src="https://i.imgur.com/ItMURpT.png" alt=""><br>
<img src="https://i.imgur.com/HOT0QpT.png" alt=""></p>
</li>
<li>
<p><strong>Other notes</strong><br>
所有非主属性都完全函数依赖于每个候选键<br>
所有主属性都完全函数依赖于每个不包含它的候选键<br>
没有任何属性完全函数依赖于非候选键的任何一组属性</p>
</li>
</ul>
<h3 id="数据异常-data-anomalies"><a class="markdownIt-Anchor" href="#数据异常-data-anomalies"></a> 数据异常 Data Anomalies</h3>
<p>以下的学生课程关系的函数依赖为 Sno, Cname -&gt; Sname, Sdept, Mname, Grade，键码为 {Sno, Cname}。也就是说，确定学生和课程之后，就能确定其它信息。</p>
<table>
<thead>
<tr>
<th style="text-align:center">Sno</th>
<th style="text-align:center">Sname</th>
<th style="text-align:center">Sdept</th>
<th style="text-align:center">Mname</th>
<th style="text-align:center">Cname</th>
<th style="text-align:center">Grade</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">学生-1</td>
<td style="text-align:center">学院-1</td>
<td style="text-align:center">院长-1</td>
<td style="text-align:center">课程-1</td>
<td style="text-align:center">90</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">学生-2</td>
<td style="text-align:center">学院-2</td>
<td style="text-align:center">院长-2</td>
<td style="text-align:center">课程-2</td>
<td style="text-align:center">80</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">学生-2</td>
<td style="text-align:center">学院-2</td>
<td style="text-align:center">院长-2</td>
<td style="text-align:center">课程-1</td>
<td style="text-align:center">100</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">学生-3</td>
<td style="text-align:center">学院-2</td>
<td style="text-align:center">院长-2</td>
<td style="text-align:center">课程-2</td>
<td style="text-align:center">95</td>
</tr>
</tbody>
</table>
<p>不符合范式的关系，会产生很多异常，主要有以下四种异常：</p>
<ul>
<li>冗余数据：例如 <code>学生-2</code> 出现了两次。</li>
<li>修改异常：修改了一个记录中的信息，但是另一个记录中相同的信息却没有被修改。</li>
<li>删除异常：删除一个信息，那么也会丢失其它信息。例如删除了 <code>课程-1</code> 需要删除第一行和第三行，那么 <code>学生-1</code> 的信息就会丢失。</li>
<li>插入异常：例如想要插入一个学生的信息，如果这个学生还没选课，那么就无法插入。</li>
</ul>
<h3 id="范式-normal-form"><a class="markdownIt-Anchor" href="#范式-normal-form"></a> 范式 Normal Form</h3>
<p>范式理论是为了解决以上提到四种异常。<br>
高级别范式的依赖于低级别的范式，1NF 是最低级别的范式。<br>
<img src="https://i.imgur.com/v1zy4Cw.png" width="250" height="200"></p>
<h4 id="分解"><a class="markdownIt-Anchor" href="#分解"></a> 分解</h4>
<p><strong>Universal Relation:</strong> A relation that captures all the information in schema and is decomposable into smaller relations.</p>
<ul>
<li>
<p>Decomposition of a relation is done when a relation in relational model is not in appropriate normal form. A good/detailed ER model should end up directly as a 3NF or BCNF. The functional dependencies guide us to determine entities and their relationships</p>
</li>
<li>
<p>Ideal decomposition should be <strong>lossless</strong> and <strong>dependency preserving</strong>.<br>
For relation R decomposed into R1 and R2:<br>
<img src="https://i.imgur.com/LIH6YcZ.png" width="300"></p>
</li>
<li>
<p>Example:<br>
<img src="https://i.imgur.com/HRk77Rk.png" width="300"><br>
<img src="https://i.imgur.com/BKpXIIy.png" width="300"><br>
employee表被分解为employee1表和employee2表：因为employee可以重名，所以我们将分解结果natural join会无法还原employee表。</p>
</li>
<li>
<p><strong>Lossless decomposition(lossless join decomposition) Requirements</strong><br>
<img src="https://i.imgur.com/7it87CU.png" alt=""></p>
</li>
<li>
<p><strong>Dependency preserving decomposition</strong><br>
If we decompose a relation R into relations R1 and R2, All dependencies of R either must be a part of R1 or R2 or must be derivable from combination of FD’s of R1 and R2.</p>
<ul>
<li>Example:</li>
</ul>
<ol>
<li>R (A, B, C, D) with FD set{A-&gt;BC} is decomposed into R1(ABC) and R2(AD) which is dependency preserving because FD A-&gt;BC is a part of R1(ABC).</li>
<li>R(A,B,C,D) and functional dependencies A-&gt;B and C-&gt;D. Then the decomposition of R into R1(AB) and R2(CD) is dependency preserving but not lossless join because it violates the second condition of lossless join and A-&gt;B can be ensured in R1(AB) and C-&gt;D can be ensured in R2(CD). Hence it is dependency preserving decomposition.</li>
</ol>
</li>
</ul>
<h4 id="1-第一范式-1nf-atomicity原子性"><a class="markdownIt-Anchor" href="#1-第一范式-1nf-atomicity原子性"></a> 1. 第一范式 (1NF) Atomicity(原子性)</h4>
<p>表的属性不可分（表的属性不可为复合属性）。然而注意复合属性有时也是有用的并被大量实际使用于面向对象数据库。</p>
<h4 id="2-boycecodd-normal-formbcnf-每个表中只有一个候选键"><a class="markdownIt-Anchor" href="#2-boycecodd-normal-formbcnf-每个表中只有一个候选键"></a> 2. Boyce–Codd normal form(BCNF) 每个表中只有一个候选键</h4>
<p>BCNF is a slightly stronger version of 3NF.<br>
Every BCNF satisfies 3NF. It eliminates all redundancy that can be discovered based on functional dependencies.<br>
<strong>A database design is in BCNF</strong> if each member of the set of relation schemas that constitutes the design is in BCNF.</p>
<p><strong>Definition：</strong><br>
A relational schema R is in BCNF with respect to a set of functional dependencies F if for all functional dependencies in F+ of form A-&gt;B where A,B are subsets of R, at least one of the following holds:</p>
<ul>
<li>A-&gt;B is a trivial functional dependency (B is a subset of A)</li>
<li>A is a super key of schema R</li>
</ul>
<p><strong>Another equivalent definition (important):</strong><br>
For all nontrivial FD A-&gt;B, A must be a super key of schema R.<br>
<strong>The negated definition</strong><br>
A relational schema R is not in BCNF w.r.t FDs set F if there exists a FD in F+ of form A-&gt;B where A,B are subsets of R s.t.<br>
A-&gt;B is a nontrivial FD (B is not a subset of A) <strong>AND</strong> A is not a super key of schema R.<br>
<strong>Example</strong>:<br>
inst_dept (ID, name, salary, dept_name, building, budget) is not in BCNF because dept_name-&gt;budget is a nontrivial FD and dept_name is not a super key of inst_dept.<br>
The schema instructor and department are not in BCNF because for all nontrivial FDs, either left side is not super key, or is super key. (in that case: ID, dept_name can be super key for each schema).<br>
<strong>Decomposing relational schema to BCNF</strong><br>
For a relational schema R not in BCNF, we must have at least 1 nontrivial FD A-&gt;B s.t. A is not a super key for R.<br>
We decompose R into 2 schemas:<br>
<img src="https://i.imgur.com/NbVERSD.png" width="180"><br>
For inst_dept, A=dept_name, B={building,budget}, it can be decomposed to (dept_name, building, budget) AND (ID,name,salary,dept_name)<br>
<strong>Problem of BCNF:</strong></p>
<ul>
<li>BCNF is not dependency preserving.</li>
</ul>
<h4 id="3-第三范式-3nf-2nf消除传递函数依赖"><a class="markdownIt-Anchor" href="#3-第三范式-3nf-2nf消除传递函数依赖"></a> 3. 第三范式 (3NF) 2NF&amp;消除传递函数依赖</h4>
<p>BCNF requires A to be a superkey for nontrival FD A-&gt;B. 3NF relaxes the constraints by allowing A to not be a super key.<br>
<strong>Definition：</strong><br>
A relational schema R is in 3NF with respect to a set of functional dependencies F if for all functional dependencies in F+ of form A-&gt;B where A,B are subsets of R, at least one of the following holds:</p>
<ul>
<li>A-&gt;B is a trivial functional dependency (B is a subset of A)</li>
<li>A is a super key of schema R</li>
<li>Each attribute X in B-A is contained in a candidate key in R</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center">Sno</th>
<th style="text-align:center">Sname</th>
<th style="text-align:center">Sdept</th>
<th style="text-align:center">Mname</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">学生-1</td>
<td style="text-align:center">学院-1</td>
<td style="text-align:center">院长-1</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">学生-2</td>
<td style="text-align:center">学院-2</td>
<td style="text-align:center">院长-2</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">学生-3</td>
<td style="text-align:center">学院-2</td>
<td style="text-align:center">院长-2</td>
</tr>
</tbody>
</table>
<p>存在以下transitive functional dependency：</p>
<ul>
<li>Sno -&gt; Sdept -&gt; Mname</li>
</ul>
<p>可以进行以下分解：</p>
<table>
<thead>
<tr>
<th style="text-align:center">Sno</th>
<th style="text-align:center">Sname</th>
<th style="text-align:center">Sdept</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">学生-1</td>
<td style="text-align:center">学院-1</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">学生-2</td>
<td style="text-align:center">学院-2</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center">学生-3</td>
<td style="text-align:center">学院-2</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:center">Sdept</th>
<th style="text-align:center">Mname</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">学院-1</td>
<td style="text-align:center">院长-1</td>
</tr>
<tr>
<td style="text-align:center">学院-2</td>
<td style="text-align:center">院长-2</td>
</tr>
</tbody>
</table>
<p><img src="https://i.imgur.com/iLeQOu8.png" alt=""></p>
<h3 id="multi-dimensional-database"><a class="markdownIt-Anchor" href="#multi-dimensional-database"></a> Multi-dimensional database</h3>
<p><img src="https://i.imgur.com/1RU9DJz.jpg" alt=""></p>
<p>Think spreadsheets and reporting but generalized.</p>
<ul>
<li>A star schema is the simplest form of a dimensional model, in which data is organized into facts and dimensions.  A fact is an event that is counted or measured, such as a sale or login.  A dimension contains reference information about the fact, such as date, product, or customer. A star schema is diagramed by surrounding each fact with its associated dimensions. The resulting diagram resembles a star.<br>
<img src="https://i.imgur.com/7xGywCG.png" alt=""></li>
<li>Example:<br>
<img src="https://i.imgur.com/n4OrKwb.jpg" alt=""></li>
</ul>
<h3 id="levels-of-abstraction-in-dbms"><a class="markdownIt-Anchor" href="#levels-of-abstraction-in-dbms"></a> Levels of abstraction in DBMS</h3>
<ul>
<li>Physical Schema is the way the relations are actually stored in SSD/HDD. It also defines indexes, statistics etc. defined on the table. (Indexes are defined using DDL.)</li>
<li>Logical (Conceptual) Schema is the DDL for creating the table. (It can sometimes specify the physical schema.)</li>
<li>External Schema is the DDL that define’s the external user’s view of the database. Though some “base” tables are directly visible, most of it is protected through views.</li>
</ul>
<h2 id="storage-and-file-structure"><a class="markdownIt-Anchor" href="#storage-and-file-structure"></a> Storage and File Structure</h2>
<h3 id="storage-overview"><a class="markdownIt-Anchor" href="#storage-overview"></a> Storage Overview</h3>
<ul>
<li>Persistent storage nonvolatile memory
<ul>
<li>Data in a DBMS has to be persistent</li>
<li>SSD: flash memory based, faster and more expensive</li>
<li>HDD: magnetic storage, slower and cheaper</li>
<li>Tapes: disks are the new tapes, still great for archiving</li>
<li>Cloud server</li>
</ul>
</li>
<li>Volatile storage
<ul>
<li>DRAM</li>
</ul>
</li>
</ul>
<h3 id="memory-hierarchy"><a class="markdownIt-Anchor" href="#memory-hierarchy"></a> Memory hierarchy</h3>
<p><img src="https://i.imgur.com/1EP43L3.jpg" alt=""></p>
<h3 id="disk"><a class="markdownIt-Anchor" href="#disk"></a> Disk</h3>
<p><img src="https://i.imgur.com/RJ2GrlY.png" alt=""></p>
<ul>
<li>
<p>The disk surface is logically divided into tracks, which are subdivided into sectors.</p>
<ul>
<li>A <strong>sector</strong> is the smallest unit of information that can be read from or written to the disk.</li>
<li>The <strong>read–write head</strong> stores information on a sector magnetically as reversals of the direction of magnetization of the magnetic material.</li>
<li>The <strong>platters</strong> that are <strong>fixed on a spindle rod</strong> spin, say 90 rps</li>
<li>Arm assembly moves in or out to position a head on desired track.</li>
<li>The tracks make an imaginary 空心<strong>cylinder</strong>: tracks with the same radius on all surfaces of disks platters     <strong>#cylinder = #tracks/surface</strong></li>
<li>#surface = #tracks/#cylinder = 2#platters</li>
<li>Only one head used at a time</li>
<li><strong>Block size</strong> is a multiple of sector size (fixed, usually 512 bytes)</li>
<li><strong>capacity</strong> = heads(#surfaces) x cylinder x sectors x 512 (typical size of one sector in bytes) =  #surfaces * #tracks * #sectors per track * bytes per sector</li>
</ul>
</li>
<li>
<p>Seek time: the time for repositioning the arm to change track.</p>
</li>
<li>
<p>Rotational delay: the time for getting to the right sector = 0.5(60s/磁盘转速rpm)   0.5为average</p>
</li>
<li>
<p>transfer time: actual overhead for transfering data = moving head across block</p>
</li>
</ul>
<p>Seek time + rotational delay is the major contributor to delay.<br>
<strong>Formatting</strong>: defining polar coordinate system on disk surface.<br>
<strong>wear leveling</strong>: storing hot data on less weared sectors and storing cold data on more weared sector to extend service time of the disk.</p>
<ul>
<li>
<p>RAID 0 Data stripping<br>
RAID 0 consists of striping, but no mirroring or parity. Compared to a spanned volume, the capacity of a RAID 0 volume is the same; it is the sum of the capacities of the disks in the set. But because striping distributes the contents of each file among all disks in the set, the failure of any disk causes all files, the entire RAID 0 volume, to be lost. A broken spanned volume at least preserves the files on the unfailing disks. The benefit of RAID 0 is that the throughput of read and write operations to any file is multiplied by the number of disks because, unlike spanned volumes, reads and writes are done concurrently,[11] and the cost is complete vulnerability to drive failures.</p>
</li>
<li>
<p>RAID 1 Mirroring<br>
RAID 1 consists of data mirroring, without parity or striping. Data is written identically to two drives, thereby producing a “mirrored set” of drives. Thus, any read request can be serviced by any drive in the set. If a request is broadcast to every drive in the set, it can be serviced by the drive that accesses the data first (depending on its seek time and rotational latency), improving performance. Sustained read throughput, if the controller or software is optimized for it, approaches the sum of throughputs of every drive in the set, just as for RAID 0. Actual read throughput of most RAID 1 implementations is slower than the fastest drive. Write throughput is always slower because every drive must be updated, and the slowest drive limits the write performance. The array continues to operate as long as at least one drive is functioning.</p>
</li>
<li>
<p>RAID 5 Stripping with Distributed Parity<br>
Upon failure of a single drive, subsequent reads can be calculated from the distributed parity such that no data is lost. RAID 5 requires at least three disks.</p>
</li>
<li>
<p>RAID 6 two parity disks<br>
RAID 6 consists of block-level striping with double distributed parity. Double parity provides fault tolerance up to two failed drives. This makes larger RAID groups more practical, especially for high-availability systems, as large-capacity drives take longer to restore. RAID 6 requires a minimum of four disks. As with RAID 5, a single drive failure results in reduced performance of the entire array until the failed drive has been replaced.[11] With a RAID 6 array, using drives from multiple sources and manufacturers, it is possible to mitigate most of the problems associated with RAID 5. The larger the drive capacities and the larger the array size, the more important it becomes to choose RAID 6 instead of RAID 5.</p>
</li>
</ul>
<h3 id="database-buffer"><a class="markdownIt-Anchor" href="#database-buffer"></a> Database Buffer</h3>
<ul>
<li>A major goal of the database system is to minimize the number of block transfers between the disk and memory.</li>
<li>The subsystem responsible for the allocation of buffer space is called the buffer manager.</li>
</ul>
<h3 id="file-organization"><a class="markdownIt-Anchor" href="#file-organization"></a> File Organization</h3>
<p><img src="https://i.imgur.com/V8RvRQk.jpg" alt=""></p>
<p><strong>A fixed length record</strong> is one where the length of the fields in each record has been set to be a certain maximum number of characters long. Suppose a field that was going to contain a name was set to be 25 characters long. This means that the field could only ever contain up to 25 characters. If all the fields in the record have a fixed length like this then the record is said to be a fixed length record. The problem with fixed length records is that each field very rarely contains the maximum number of characters allowed. This means that a lot of space is needlessly set aside and wasted. Also, values sometimes cannot be entered because they are too large to fit inside the allowed space in a field. The advantage of fixed length records is that they make file processing much easier because the start and end of each record is always a fixed number of characters apart. This makes it much easier to locate both indicidual records and fields.<br>
<img src="https://i.imgur.com/FdzIIl7.png" alt=""></p>
<p><img src="https://i.imgur.com/O6PKrwj.jpg" alt=""><br>
A <strong>variable length record</strong> is one where the length of a field can change to allow data of any size to fit. The advantage of variable length records is that space is not wasted, only the space needed is ever used. The main problem with variable length records is that it is much more difficult to locate the start and end of individual records and fields. This is because they are not separated by a fixed amount of characters. To separate variable length recordseach field has a special character to mark where it ends- called an end- of- field marker. When records need to be located the computer must count through the end- of- field markers to locate individual records and fields.</p>
<p><img src="https://i.imgur.com/VBlJR9B.png" alt=""></p>
<p><img src="https://i.imgur.com/6NoscfG.png" alt=""><br>
<img src="https://i.imgur.com/TXo6UxW.png" alt=""><br>
<img src="https://i.imgur.com/t6f8Eqi.png" alt=""><br>
<img src="https://i.imgur.com/cdRtHS5.png" alt=""></p>
<ul>
<li>Columnar storage<br>
A column-oriented DBMS (or columnar database management system) is a database management system (DBMS) that stores data tables by column rather than by row. Practical use of a column store versus a row store differs little in the relational DBMS world. Both columnar and row databases can use traditional database query languages like SQL to load data and perform queries. Both row and columnar databases can become the backbone in a system to serve data for common extract, transform, load (ETL) and data visualization tools. However, by storing data in columns rather than rows, the database can more precisely access the data it needs to answer a query rather than scanning and discarding unwanted data in rows. Query performance is increased for certain workloads.</li>
</ul>
<h3 id="storage-summary"><a class="markdownIt-Anchor" href="#storage-summary"></a> Storage summary</h3>
<ul>
<li>Databases must have persistent storage: SSD, HDD Their performance characteristics affect database design</li>
<li>Buffer manager tries to keep the optimal set of data blocks (pages) in memory to minimize I/O</li>
<li>must be able to “lock” (pin) a page in memory</li>
<li>must be able to write / flush page to disk on demand</li>
<li>Rows comprise both fixed and variable length fields</li>
<li>Slotted page format is flexible to keep records organized and accessible on a page</li>
<li>Single column values could be stored in fixed length records, but are usually compressed via encodings</li>
<li>Compression is used at both column and block level Heap files are ok but most databases use B+ trees</li>
<li>Columnar storage is another tool in the database tool-kit, soon all DBMS vendors will have it</li>
</ul>
<h2 id="indexing-and-hashing"><a class="markdownIt-Anchor" href="#indexing-and-hashing"></a> Indexing and Hashing</h2>
<h3 id="b-tree"><a class="markdownIt-Anchor" href="#b-tree"></a> B+ tree</h3>
<ul>
<li><strong>Properties</strong>
<ul>
<li>
<p>It can be shown that the number of I/O operations needed in the worst case for an insertion is proportional to logn/2(N), where n is the maximum number of pointers in a node, and N is the number of records in the file being indexed.</p>
</li>
<li>
<p>It contains up to n − 1 search-key values K1 , K2 , . . . , Kn − 1 , and n pointers  P1 , P2 , . . . , Pn . The search-key values within a node are kept in sorted order; thus, if i &lt; j, then Ki &lt; Kj<br>
<img src="https://i.imgur.com/ApVXPRo.png" alt=""></p>
</li>
<li>
<p>Each <strong>non-leaf</strong> node in the tree has between n/2 and n children, where n is fixed for a particular tree.</p>
</li>
<li>
<p>A <strong>non-leaf</strong> node may hold up to n pointers, and must hold at least n/2 pointers. The number of pointers in a node is called the fanout of the node.</p>
</li>
<li>
<p>Each <strong>leaf</strong> can hold up to n − 1 values. We allow leaf nodes to contain as few as (n − 1)/2 values. With n = 4 in our example B±tree, each leaf must contain at least 2 values, and at most 3 values.</p>
</li>
<li>
<p>Since, n = 4 and 1 &lt; (n − 1)/2, we must either merge the node with a sibling node, or redistribute the entries between the nodes, to ensure that each node is at least half-full.</p>
</li>
</ul>
</li>
<li>Insertion
<ul>
<li>Split</li>
<li>Coalesce</li>
</ul>
</li>
<li>Deletion
<ul>
<li>if the occupancy of a node falls below 2n/3, the system attempts to borrow an entry from one of the sibling nodes</li>
<li>Borrow left, pick max one</li>
<li>Borrow right, pick min one</li>
<li>Merge left, shift left, change parent</li>
<li>Merge right, shift right, change parent</li>
</ul>
</li>
<li><strong>Non-unique search key</strong>: If a relation can have more than one record containing the same search key value (that is, two or more records can have the same values for the indexed attributes), the search key is said to be a non-unique search key.</li>
<li><strong>Bulk-loading in B+ tree</strong>
<ul>
<li>Insertion of a large number of entries at a time into an index is referred to as bulk loading of the index.</li>
<li>sort the file on the search key of the index being constructed</li>
<li>There is a significant benefit to sorting the entries before inserting them into the B+tree.</li>
<li>nodes will never have to be read from disk during bulk load, if the B+ tree was empty to start with. Each leaf node will thus incur only one I/O operation even though many entries may be inserted into the node.</li>
</ul>
</li>
<li><strong>bottom-up B+ tree construction</strong>
<ul>
<li>it can be constructed faster by building it bottom-up, from the leaf level, instead of using the usual insert procedure.</li>
<li>we break up the sorted entries into blocks, keeping as many entries in a block as can fit in the block; the resulting blocks form the leaf level of the B±tree. The minimum value in each block, alongwith the pointer to the block, is used to create entries in the next level of the B±tree, pointing to the leaf blocks</li>
</ul>
</li>
</ul>
<h3 id="hashing"><a class="markdownIt-Anchor" href="#hashing"></a> HASHING</h3>
<h4 id="static-hashing"><a class="markdownIt-Anchor" href="#static-hashing"></a> Static Hashing</h4>
<ul>
<li>We use the term <strong>bucket</strong> to denote a unit of storage that can store one or more records.</li>
<li>let <strong>K</strong> denote the set of all search-key values, and let <strong>B</strong> denote the set of all bucket addresses. A <strong>hash function h</strong> is a function from K to B. Let h denote a hash function.</li>
<li>Hash function should be random and uniform</li>
<li>Algorithm is similiar to Data Structure Hash Table</li>
</ul>
<h4 id="dynamic-hashing"><a class="markdownIt-Anchor" href="#dynamic-hashing"></a> Dynamic Hashing</h4>
<p><img src="https://i.imgur.com/jAg67QV.png" alt=""></p>
<h3 id="bitmap"><a class="markdownIt-Anchor" href="#bitmap"></a> BITMAP</h3>
<ul>
<li>A <strong>bitmap</strong> is simply an array of bits. In its simplest form, a bitmap index on the attribute A of relation r consists of one bitmap for each value that A can take. Each bitmap has as many bits as the number of records in the relation. The ith bit of the bitmap for value vj is set to 1 if the record numbered i has the value vj for attribute A. All other bits of the bitmap are set to 0.</li>
</ul>
<p><img src="https://i.imgur.com/bjJkZQR.png" alt=""></p>
<ul>
<li>To recognize deleted records,we can store an <strong>existence bitmap</strong>, in which bit i is 0 if record i does not exist and 1 otherwise.
<ul>
<li>If some records have been deleted, however, just computing the complement of a bitmap is not sufficient. Bits corresponding to such records would be 0 in the original bitmap, but would become 1 in the complement, although the records don’t exist.</li>
</ul>
</li>
<li><strong>Limitation</strong>
<ul>
<li>If there are further conditions, the fraction of records satisfying all the conditions is likely to be quite small.</li>
<li>If the fraction is large, scanning the entire relation would remain the cheaper alternative.</li>
</ul>
</li>
<li><strong>Counting the number of bits that are 1 in a bitmap</strong> can be done quickly by a clever technique. We can maintain an array with 256 entries, where the ith entry stores the number of bits that are 1 in the binary representation of i.</li>
</ul>
<h3 id="储存与索引总结"><a class="markdownIt-Anchor" href="#储存与索引总结"></a> 储存与索引总结</h3>
<p>atomicity problem:  transaction is executed totally or not at all<br>
integrated storage structure: index file 和record file一起<br>
seperate file: 相反</p>
<p>clustered index 与原数据同顺序<br>
clustered indexes do not guarantee sequential storage on the disk. Managing exactly where data is placed on the disk is the job of the OS, not the DBMS. But it suggests that items are ordered generally according to the clustering key.</p>
<p>With a non clustered index there is a second list that has pointers to the physical rows. You can have many non clustered indexes, although each new index will increase the time it takes to write new records.</p>
<p>It is generally faster to read from a clustered index if you want to get back all the columns. You do not have to go first to the index and then to the table.</p>
<p>Writing to a table with a clustered index can be slower, if there is a need to rearrange the data</p>
<p>primary index: using primary key for indexing</p>
<p>secondary index: otherwise</p>
<p>index以block为单位进行index  within block用offset</p>
<p>hash index  通过哈希函数生成hash address to a bucket with possible overflow chain for managing collision<br>
cheaper than B+tree if no overflow occurs Access: O(1+#overflow buckets)<br>
所以hash索引的最大的特点就是等值查询快，不能进行范围索引。<br>
位图索引适合静态low-cardinality重复数据<br>
b树索引同时支持范围及等值查询</p>
<p>b tree m-way(order m, m fanout, m-1info fields) search tree with additional constraints:  叶子层高度相同 root 2 key  其他节点至少半满ceiling(order/2)来尽量减少高度    若想要插入的位置已满  recursively按中序遍历顺序将中点上移 同时将前驱后继节点分开 始终保持节点半满的要求<br>
b+ tree 更贴近多级索引，是在b树基础上, nonleaf node sparse index 减少disk page access  支持equality search 在叶子层将nonleaf节点key按中序遍历顺序拷贝下来 叶子层包含record ptrs 保持中序遍历顺序建立链表 形成dense &amp; clustered index 从而支持range search<br>
删除： 左合并 右合并 来满足半满的限制  split if necessary can propagate to root.<br>
order=#ptr fields = p    /node<br>
#k,v fields = p-1          /node</p>
<p>(p-1)(key_ptr_size + record_ptr_size) + p(block_ptr_size) &lt;= blocksize=512</p>
<p>static hashing: linear congruential hash function with fixed #hash buckets  use overflow chain to manage contention</p>
<p>extendible hashing: nonlinear hashing congruential function such as h_k(v)=h(v) mod 2^k  use directory of size 2^k to store ptrs to hash buckets<br>
when collisions happen increment k value and maps it elsewhere</p>

      
      <!-- reward -->
      
    </div>
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Database/">Database</a></li></ul>


    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-Operating System - Virtualization" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/03/16/Operating System - Virtualization/"
    >Operating System - Virtualization</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2019/03/16/Operating System - Virtualization/" class="article-date">
  <time datetime="2019-03-15T20:06:41.000Z" itemprop="datePublished">2019-03-15</time>
</a>
      
      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h1 id="cs537-operating-system-summary-part-1-virtualization"><a class="markdownIt-Anchor" href="#cs537-operating-system-summary-part-1-virtualization"></a> <strong>CS537 - Operating System Summary Part 1 Virtualization</strong></h1>
<h1 id="virtualization"><a class="markdownIt-Anchor" href="#virtualization"></a> Virtualization</h1>
<h2 id="process"><a class="markdownIt-Anchor" href="#process"></a> Process</h2>
<h3 id="what-is-a-process"><a class="markdownIt-Anchor" href="#what-is-a-process"></a> What is a process</h3>
<ul>
<li>A running program is a process</li>
<li>Stream of executing instructions and their “context”</li>
</ul>
<h3 id="thread"><a class="markdownIt-Anchor" href="#thread"></a> Thread</h3>
<ul>
<li>Can have multiple threads within a single process</li>
<li>Lightweight process</li>
<li>Share an address space</li>
</ul>
<h3 id="why-do-we-need-processes"><a class="markdownIt-Anchor" href="#why-do-we-need-processes"></a> Why do we need processes?</h3>
<ul>
<li>Share CPU: Time sharing</li>
</ul>
<h3 id="os-scheduler"><a class="markdownIt-Anchor" href="#os-scheduler"></a> OS Scheduler</h3>
<ul>
<li>Scheduler save context when process is pause</li>
<li>Restore context on resumption</li>
</ul>
<h3 id="goals-for-cpu-virtualization"><a class="markdownIt-Anchor" href="#goals-for-cpu-virtualization"></a> Goals for CPU Virtualization</h3>
<ul>
<li>
<p>Policy goals</p>
<ul>
<li>Virtualize CPU resource using processes</li>
<li>Reschedule process for fairness? efficiency?</li>
</ul>
</li>
<li>
<p>Mechanism goals</p>
<ul>
<li>Efficiency: Time sharing should not add overhead</li>
<li>Control: OS should be able to intervene when required</li>
</ul>
</li>
</ul>
<h2 id="mechanism"><a class="markdownIt-Anchor" href="#mechanism"></a> Mechanism</h2>
<h3 id="system-call"><a class="markdownIt-Anchor" href="#system-call"></a> System call</h3>
<ul>
<li>
<p>User mode and kernel mode</p>
<ul>
<li>User processes run in user mode (restricted mode)</li>
<li>OS runs in kernel mode (not restricted)</li>
</ul>
</li>
<li>
<p>System call</p>
<ul>
<li>Separate user mode from kernel mode for security</li>
<li>Use system call to invoke kernel mode functions</li>
</ul>
</li>
<li>
<p>Procedure for calling read()</p>
<ol>
<li>Set system call table index to 6 <code>movl $6, %eax</code></li>
<li>Call trap with id 64 <code>int $64</code></li>
</ol>
</li>
</ul>
<p><img src="https://i.imgur.com/7hmjTrj.png" alt=""></p>
<h3 id="dispatch-mechanism"><a class="markdownIt-Anchor" href="#dispatch-mechanism"></a> Dispatch mechanism</h3>
<ul>
<li>
<p>Dispatch loop</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">while (1) &#123;	</span><br><span class="line">    run	process	A for some time-slice	</span><br><span class="line">    stop process A and save its context	</span><br><span class="line">    load context of another process B	</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Cooperative Multi-tasking</p>
<ul>
<li>Trust process to relinquish CPU through traps</li>
<li>Provide special yield() system call</li>
<li>Processes can <strong>misbehave</strong></li>
</ul>
</li>
<li>
<p>Timer-based Multi-tasking</p>
<ul>
<li>Hardware generates timer interrupt (CPU or separate chip)</li>
<li>User must not be able to mask timer interrupt</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/eE325zz.png" alt=""></p>
<h2 id="policy"><a class="markdownIt-Anchor" href="#policy"></a> Policy</h2>
<h3 id="vocabulary"><a class="markdownIt-Anchor" href="#vocabulary"></a> Vocabulary</h3>
<ul>
<li>Workload: set of jobs (arrival time, run_time)</li>
<li>Job ~ Current execution of a process</li>
<li>Scheduler: Decides which ready job to run</li>
<li>Metric: measurement of scheduling quality</li>
<li>Turnaround time = completion time - arrival time</li>
<li>Response time = first run time - arrival time</li>
</ul>
<h3 id="fifo-first-in-first-out"><a class="markdownIt-Anchor" href="#fifo-first-in-first-out"></a> FIFO (First In, First Out)</h3>
<ul>
<li>Disadvantage: Turnaround time suffers when short jobs must wait for long jobs (Convoy Effect)</li>
</ul>
<img src="https://i.imgur.com/p6B5iuB.png" width="75%" style="margin:auto; display: block;">
<h3 id="sjf-shortest-job-first"><a class="markdownIt-Anchor" href="#sjf-shortest-job-first"></a> SJF (Shortest job first)</h3>
<ul>
<li>Disadvantage: Only schedule new job when previous job voluntarily relinquishes CPU</li>
</ul>
<img src="https://i.imgur.com/4L0JHF6.png" width="75%" style="margin:auto; display: block;">
<h3 id="stcf-shortest-time-to-completion-first"><a class="markdownIt-Anchor" href="#stcf-shortest-time-to-completion-first"></a> STCF (Shortest Time-to-Completion First)</h3>
<ul>
<li>Preemptive: Schedule different job by taking CPU away from running job</li>
<li>Always run job that will complete the quickest</li>
</ul>
<img src="https://i.imgur.com/F97B6qw.png" width="75%" style="margin:auto; display: block;">
<h3 id="round-robin"><a class="markdownIt-Anchor" href="#round-robin"></a> Round Robin</h3>
<ul>
<li>Goal: reduce response time</li>
<li>Trade-off: increase turnaround time</li>
</ul>
<img src="https://i.imgur.com/aNCUwiF.png" width="75%" style="margin:auto; display: block;">
<h3 id="io-aware-scheduling"><a class="markdownIt-Anchor" href="#io-aware-scheduling"></a> I/O Aware Scheduling</h3>
<ul>
<li>Goal: process won’t hold CPU when doing IO</li>
</ul>
<img src="https://i.imgur.com/S8TUga8.png" width="75%" style="margin:auto; display: block;">
<h3 id="multilevel-feedback-queue"><a class="markdownIt-Anchor" href="#multilevel-feedback-queue"></a> Multilevel Feedback Queue</h3>
<ul>
<li>
<p>Motivation: Run-time of each job is not known</p>
</li>
<li>
<p>Approach</p>
<ul>
<li>Multiple levels of round-robin</li>
<li>Each level has higher priority than lower level</li>
<li>Can preempt them</li>
</ul>
</li>
<li>
<p>Rules</p>
<ol>
<li>If priority(A) &gt; Priority(B), A runs</li>
<li>If priority(A) == Priority(B), A &amp; B run in RR</li>
<li>Processes start at top priority</li>
<li>If job uses whole slice, demote process (longer time slices at lower priorities)</li>
</ol>
</li>
<li>
<p>Avoid starvation</p>
<ul>
<li>Problem: Low priority job may never get scheduled</li>
<li>Solution: Periodically boost priority of all jobs (or all jobs thathaven’t been scheduled)</li>
</ul>
</li>
</ul>
<img src="https://i.imgur.com/RL4PuJC.png" width="50%" style="margin:auto; display: block;">
<h1 id="memory-virtualization"><a class="markdownIt-Anchor" href="#memory-virtualization"></a> Memory Virtualization</h1>
<h2 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h2>
<h3 id="goals"><a class="markdownIt-Anchor" href="#goals"></a> Goals</h3>
<ul>
<li><strong>Transparency</strong>: Process is unaware of sharing</li>
<li><strong>Protection</strong>: Cannot corrupt OS or other process memory</li>
<li><strong>Efficiency</strong>: Do not waste memory or slow down processes</li>
<li><strong>Sharing</strong>: Enable sharing between cooperating processes</li>
</ul>
<h3 id="address-space"><a class="markdownIt-Anchor" href="#address-space"></a> Address space</h3>
<ul>
<li>Stack: No fragmentation</li>
<li>Heap: Consists of allocated and free areas (holes)<br>
<img src="https://i.imgur.com/we79L5F.png" alt=""></li>
</ul>
<h3 id="memory-access-example"><a class="markdownIt-Anchor" href="#memory-access-example"></a> Memory Access Example</h3>
<table>
<thead>
<tr>
<th>Assembly</th>
<th>Access for Instruction</th>
<th>Access for Execution</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>0x10: movl 0x8(%rbp), %edi</code></td>
<td>Fetch instruction at 0x10</td>
<td>Load from 0x208</td>
</tr>
<tr>
<td><code>0x13: addl $0x3, %edi</code></td>
<td>Fetch instruction at 0x13</td>
<td>No memory access</td>
</tr>
<tr>
<td><code>0x19: movl %edi, 0x8(%rbp)</code></td>
<td>Fetch instruction at 0x19</td>
<td>Store to 0x208</td>
</tr>
</tbody>
</table>
<h2 id="basic-mechanisms"><a class="markdownIt-Anchor" href="#basic-mechanisms"></a> Basic Mechanisms</h2>
<h3 id="time-sharing"><a class="markdownIt-Anchor" href="#time-sharing"></a> Time Sharing</h3>
<ul>
<li>On process switch, save current process’s memory to disk and load another process’s memory from disk.</li>
<li>Ridiculously poor performance</li>
</ul>
<h3 id="static-relocation"><a class="markdownIt-Anchor" href="#static-relocation"></a> Static Relocation</h3>
<ul>
<li>
<p>Idea</p>
<ul>
<li>OS rewrites each program before loading it as a process in memory</li>
<li>Each rewrite for different process uses different addresses and pointers</li>
<li>Change jumps, loads of static data</li>
</ul>
</li>
<li>
<p>Disadvantage</p>
<ul>
<li>Process can destroy OS or other processes</li>
<li>No privacy</li>
<li>Cannot move address space after it has been placed</li>
<li>May not be able to allocate new process</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/840IDak.png" alt=""></p>
<h3 id="dynamic-relocation-introduction"><a class="markdownIt-Anchor" href="#dynamic-relocation-introduction"></a> Dynamic Relocation: Introduction</h3>
<ul>
<li>
<p>Goal: Protect processes from one another</p>
</li>
<li>
<p>Memory Management Unit (MMU)</p>
<ul>
<li>MMU dynamically changes process address at every memory reference</li>
<li>Process generates <strong>logical</strong> or <strong>virtual</strong> addresses (in their address space)</li>
<li>Memory hardware uses <strong>physical</strong> or <strong>real</strong> addresses</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/1rZVwO8.png" alt=""></p>
<ul>
<li>Two operating modes
<ul>
<li>
<p>Kernel mode</p>
<ul>
<li>Can manipulate contents of MMU</li>
<li>Allows OS to access all of physical memory</li>
</ul>
</li>
<li>
<p>User mode</p>
<ul>
<li>Perform translation of logical address to physical address</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="dynamic-relocation-base-register"><a class="markdownIt-Anchor" href="#dynamic-relocation-base-register"></a> Dynamic Relocation: Base Register</h3>
<ul>
<li>Translation on every memory access of user process</li>
<li>MMU adds base register to logical address to form physical address</li>
<li>Store offset in base register</li>
<li>Each process has different value in base register</li>
<li>Dynamic relocation by changing value of base register.</li>
</ul>
<p><img src="https://i.imgur.com/Eika7Rs.png" alt=""></p>
<ul>
<li>
<p>Quiz</p>
<ul>
<li>What entity should do translation of addresses with base register? <strong>Hardware</strong></li>
<li>What entity should modify the base register? <strong>OS</strong></li>
</ul>
</li>
<li>
<p>Problem: No protection</p>
</li>
</ul>
<h3 id="dynamic-relocation-base-bounds"><a class="markdownIt-Anchor" href="#dynamic-relocation-base-bounds"></a> Dynamic Relocation: Base + Bounds</h3>
<ul>
<li>
<p>Idea</p>
<ul>
<li>limit the address space with a bounds register</li>
<li>Base register: smallest physical addr (or starting location)</li>
<li>Bounds register: size of this process’s virtual address space</li>
<li>OS kills process if process loads/stores beyond bounds</li>
</ul>
</li>
<li>
<p>Implementation</p>
<ul>
<li>MMU compares logical address to bounds register</li>
<li>if logical address is greater, then generate error</li>
<li>MMU adds base register to logical address to form physical address</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/Qoqdgtb.png" alt=""></p>
<ul>
<li>
<p>Context switch</p>
<ol>
<li>Change to privileged mode</li>
<li>Save base and bounds registers of old process</li>
<li>Load base and bounds registers of new process</li>
<li>Change to user mode and jump to new process</li>
</ol>
</li>
<li>
<p>Advantages</p>
<ul>
<li>Provides protection (both read and write) across address spaces</li>
<li>Supports dynamic relocation</li>
<li>Simple, inexpensive implementation: Few registers, little logic in MMU</li>
<li>Fast: Add and compare in parallel</li>
</ul>
</li>
<li>
<p>Disadvantages</p>
<ul>
<li>Each process must be allocated contiguously in physical memory</li>
<li>Must allocate memory that may not be used by process</li>
<li>No partial sharing: Cannot share limited parts of address space</li>
</ul>
</li>
</ul>
<h3 id="segmentation"><a class="markdownIt-Anchor" href="#segmentation"></a> Segmentation</h3>
<ul>
<li>
<p>Idea</p>
<ul>
<li>MMU contains Segment Table (per process)</li>
<li>Each segment has own base and bounds, protection bits</li>
<li>Example: 14 bit logical address, 4 segments;</li>
</ul>
</li>
<li>
<p>Example</p>
<ul>
<li>
<p>Segment Table</p>
<table>
<thead>
<tr>
<th>Segment</th>
<th>Base</th>
<th>Bounds</th>
<th>R W</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0x2000</td>
<td>0x6ff</td>
<td>1 0</td>
</tr>
<tr>
<td>1</td>
<td>0x0000</td>
<td>0x4ff</td>
<td>1 1</td>
</tr>
<tr>
<td>2</td>
<td>0x3000</td>
<td>0xfff</td>
<td>1 1</td>
</tr>
<tr>
<td>3</td>
<td>0x0000</td>
<td>0x000</td>
<td>0 0</td>
</tr>
</tbody>
</table>
</li>
<li>
<p>Translation</p>
<table>
<thead>
<tr>
<th>Logical address</th>
<th>Segment</th>
<th>Base</th>
<th>Physical address</th>
</tr>
</thead>
<tbody>
<tr>
<td>0x0240</td>
<td>0</td>
<td>0x2000</td>
<td>0x2240</td>
</tr>
<tr>
<td>0x1108</td>
<td>1</td>
<td>0x0000</td>
<td>0x1108</td>
</tr>
<tr>
<td>0x256c</td>
<td>2</td>
<td>0x3000</td>
<td>0x356c</td>
</tr>
<tr>
<td>0x3002</td>
<td>3</td>
<td>0x0000</td>
<td>Fail</td>
</tr>
</tbody>
</table>
</li>
</ul>
</li>
<li>
<p>Advantages</p>
<ul>
<li>No extra memory access</li>
<li>Enables sparse allocation of address space</li>
<li>Stack and heap can grow independently</li>
<li>Enables sharing of selected segments</li>
<li>Read-only status for code</li>
<li>Supports dynamic relocation of each segment</li>
</ul>
</li>
<li>
<p>Disadvantages</p>
<ul>
<li>Each segment must be allocated contiguously</li>
<li>May not have sufficient physical memory for large segments?</li>
<li>External Fragmentation</li>
</ul>
</li>
</ul>
<h3 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h3>
<table>
<thead>
<tr>
<th>Description</th>
<th>Name of approach</th>
</tr>
</thead>
<tbody>
<tr>
<td>One process uses RAM at a time</td>
<td>Time Sharing</td>
</tr>
<tr>
<td>Rewrite code and addresses before running</td>
<td>Static Relocation</td>
</tr>
<tr>
<td>Add per-process starting location to virt addr to obtain phys addr</td>
<td>Base</td>
</tr>
<tr>
<td>dynamic approach that verifies address is in valid range</td>
<td>Base + Bounds</td>
</tr>
<tr>
<td>Several base+bound pairs per process</td>
<td>Segmentation</td>
</tr>
</tbody>
</table>
<h2 id="paging"><a class="markdownIt-Anchor" href="#paging"></a> Paging</h2>
<h3 id="fragmentation"><a class="markdownIt-Anchor" href="#fragmentation"></a> Fragmentation</h3>
<ul>
<li>
<p>Definition</p>
<ul>
<li>Free memory that can’t be usefully allocated</li>
</ul>
</li>
<li>
<p>Types of fragmentation</p>
<ul>
<li>External: Visible to allocator (e.g., OS)</li>
<li>Internal: Visible to requester</li>
</ul>
</li>
</ul>
<h3 id="introduction-for-paging"><a class="markdownIt-Anchor" href="#introduction-for-paging"></a> Introduction for Paging</h3>
<ul>
<li>
<p>Goal</p>
<ul>
<li>Eliminate requirement that address space is contiguous</li>
<li>Eliminate external fragmentation</li>
<li>Grow segments as needed</li>
</ul>
</li>
<li>
<p>Idea</p>
<ul>
<li>Divide address spaces and physical memory into fixed-sized pages (usually 4KB)</li>
</ul>
</li>
</ul>
<h3 id="translation-of-page-addresses"><a class="markdownIt-Anchor" href="#translation-of-page-addresses"></a> Translation of Page Addresses</h3>
<ul>
<li>Logical address
<ul>
<li>High-order bits of address designate page number</li>
<li>Low-order bits of address designate offset within page</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/EuMGAwS.png" alt=""></p>
<ul>
<li>
<p>Address Format</p>
<table>
<thead>
<tr>
<th>Page Size</th>
<th>Low Bits</th>
<th>Virt Addr Bits</th>
<th>High Bits</th>
<th>Virt Pages</th>
</tr>
</thead>
<tbody>
<tr>
<td>16 bytes</td>
<td>log(16) = 4</td>
<td>10</td>
<td>10 - 4 = 6</td>
<td>2 ^ 6 = 64</td>
</tr>
<tr>
<td>1 KB</td>
<td>log(1K) = 10</td>
<td>20</td>
<td>20 - 10 = 10</td>
<td>2 ^ 10 = 1024</td>
</tr>
<tr>
<td>1 MB</td>
<td>log(1M) = 20</td>
<td>32</td>
<td>32 - 20 = 12</td>
<td>2 ^ 12 = 4K</td>
</tr>
<tr>
<td>512 bytes</td>
<td>log(512) = 9</td>
<td>16</td>
<td>16 - 9 = 7</td>
<td>2 ^ 7 = 128</td>
</tr>
<tr>
<td>4 KB</td>
<td>log(4K) = 12</td>
<td>32</td>
<td>32 -12 = 20</td>
<td>2 ^ 20 = 1M</td>
</tr>
</tbody>
</table>
</li>
<li>
<p>Address Translation</p>
<ul>
<li>Number of bits in virtual address <strong>need not equal</strong> number of bits in physical address</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/HZcAtTC.png" alt=""></p>
<h3 id="pagetables"><a class="markdownIt-Anchor" href="#pagetables"></a> Pagetables</h3>
<ul>
<li>
<p>How should OS translate VPN to PPN?</p>
<ul>
<li>Simple solution: Linear page table aka array</li>
</ul>
</li>
<li>
<p>Example<br>
<img src="https://i.imgur.com/uWlRJnw.png" alt=""></p>
<ul>
<li>Page table for P1: 3, 1, 7, 10</li>
<li>Page table for P2: 0, 4, 2, 6</li>
<li>Page table for P3: 8, 5, 9, 11</li>
</ul>
</li>
<li>
<p>How big is a pagetable</p>
<ul>
<li>Given 32-bit address space, 4KB pages, 4 byte entries</li>
<li>4KB pages =&gt; 12 bit for offset</li>
<li>32-bit address space =&gt; 20 bit for VPN =&gt; 2 ^ 20 = 1MB entries</li>
<li>1MB entries * 4 byte per entry = 4MB</li>
</ul>
</li>
<li>
<p>Where are pagetables stored</p>
<ul>
<li>Store each page table in memory</li>
<li>Hardware finds page table base with register (e.g., CR3 on x86)</li>
</ul>
</li>
<li>
<p>What happens on a context-switch?</p>
<ul>
<li>Change contents of page table base register to newly scheduled process</li>
<li>Save old page table base register in PCB of descheduled process</li>
</ul>
</li>
<li>
<p>What other info is in pagetable entries besides translation?</p>
<ul>
<li>valid bit</li>
<li>protection bits</li>
<li>present bit (needed later)</li>
<li>reference bit (needed later)</li>
<li>dirty bit (needed later)</li>
</ul>
</li>
</ul>
<h3 id="memory-access-with-paging"><a class="markdownIt-Anchor" href="#memory-access-with-paging"></a> Memory Access with Paging</h3>
<ul>
<li>
<p>Given</p>
<ul>
<li>Current instruction: <code>0x0010: movl 0x1100, %edi</code></li>
<li>Assume PT is at phys addr 0x5000</li>
<li>Assume PTE’s are 4 bytes</li>
<li>Assume 4KB pages =&gt; 12 bits for offset</li>
<li>Page table for current process: 2, 0, 80, 99</li>
</ul>
</li>
<li>
<p>Fetch instruction at logical addr 0x0010</p>
<ul>
<li>Access page table to get ppn for vpn 0</li>
<li>Mem ref 1: 0x5000</li>
<li>Learn vpn 0 is at ppn 2</li>
<li>Fetch instruction at 0x2010 (Mem ref 2)</li>
</ul>
</li>
<li>
<p>Exec, load from logical addr 0x1100</p>
<ul>
<li>Access page table to get ppn for vpn 1</li>
<li>Mem ref 3: 0x5000</li>
<li>Learn vpn 1 is at ppn 0</li>
<li>movl from 0x0100 into reg (Mem ref 4)</li>
</ul>
</li>
</ul>
<h3 id="advantages-of-paging"><a class="markdownIt-Anchor" href="#advantages-of-paging"></a> Advantages of Paging</h3>
<ul>
<li>
<p>No external fragmentation</p>
<ul>
<li>Any page can be placed in any frame in physical memory</li>
</ul>
</li>
<li>
<p>Fast to allocate and free</p>
<ul>
<li>Alloc: No searching for suitable free space</li>
<li>Free: Doesn’t have to coalesce with adjacent free space</li>
</ul>
</li>
<li>
<p>Simple to swap-out portions of memory to disk (later lecture)</p>
<ul>
<li>Page size matches disk block size</li>
<li>Can run process when some pages are on disk</li>
<li>Add “present” bit to PTE</li>
</ul>
</li>
</ul>
<h3 id="disadvantages-of-paging"><a class="markdownIt-Anchor" href="#disadvantages-of-paging"></a> Disadvantages of Paging</h3>
<ul>
<li>
<p>Internal fragmentation: Page size may not match size needed by process</p>
<ul>
<li>Wasted memory grows with larger pages</li>
<li>Tension?</li>
</ul>
</li>
<li>
<p>Additional memory reference to page table -&gt; Very inefficient</p>
<ul>
<li>Page table must be stored in memory</li>
<li>MMU stores only base address of page table</li>
</ul>
</li>
<li>
<p>Storage for page tables may be substantial</p>
<ul>
<li>Simple page table: Requires PTE for all pages in address space</li>
<li>Entry needed even if page not allocated?</li>
</ul>
</li>
</ul>
<h3 id="paging-translation-steps"><a class="markdownIt-Anchor" href="#paging-translation-steps"></a> Paging Translation Steps</h3>
<ol>
<li>extract VPN (virt page num) from VA (virt addr)</li>
<li>calculate addr of PTE (page table entry)</li>
<li>read PTE from memory</li>
<li>extract PFN (page frame num)</li>
<li>build PA (phys addr)</li>
<li>read contents of PA from memory into register</li>
</ol>
<h2 id="tlb"><a class="markdownIt-Anchor" href="#tlb"></a> TLB</h2>
<h3 id="motivative-example-iterating-array"><a class="markdownIt-Anchor" href="#motivative-example-iterating-array"></a> Motivative Example: Iterating Array</h3>
<ul>
<li>
<p>Code</p>
  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++)&#123; </span><br><span class="line">    sum += a[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Memory Access</p>
<table>
<thead>
<tr>
<th>What virtual addresses?</th>
<th>What physical addresses?</th>
</tr>
</thead>
<tbody>
<tr>
<td>load 0x3000</td>
<td>load 0x100C <br>load 0x7000</td>
</tr>
<tr>
<td>load 0x3004</td>
<td>load 0x100C <br>load 0x7004</td>
</tr>
<tr>
<td>load 0x3008</td>
<td>load 0x100C <br>load 0x7008</td>
</tr>
<tr>
<td>load 0x300C</td>
<td>load 0x100C <br>load 0x7008</td>
</tr>
</tbody>
</table>
</li>
</ul>
<h3 id="introduction-2"><a class="markdownIt-Anchor" href="#introduction-2"></a> Introduction</h3>
<ul>
<li>Strategy: Cache Page Translations</li>
<li>TLB stands for Translation Lookaside Buffer<br>
<img src="https://i.imgur.com/mEwtslZ.png" alt=""></li>
</ul>
<h3 id="tlb-organization"><a class="markdownIt-Anchor" href="#tlb-organization"></a> TLB Organization</h3>
<ul>
<li>
<p>TLB Entry</p>
<table>
<thead>
<tr>
<th>Tag (virtual page number)</th>
<th>Physical page number (page table entry)</th>
</tr>
</thead>
<tbody></tbody>
</table>
</li>
<li>
<p>Fully associative</p>
<ul>
<li>Any given translation can be anywhere in the TLB</li>
<li>Hardware will search the entire TLB in parallel</li>
</ul>
</li>
</ul>
<h3 id="example-iterating-array-with-tlb"><a class="markdownIt-Anchor" href="#example-iterating-array-with-tlb"></a> Example: Iterating Array with TLB</h3>
<ul>
<li>
<p>Code</p>
  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2048</span>; i++)&#123; </span><br><span class="line">    sum += a[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li>
<p>Page table for current process (starting at 0x0000)</p>
  <table>
      <tbody>
          <tr>
              <td>PPN</td>
              <td>1</td>
              <td>5</td>
              <td>4</td>
              <td>…</td>
          </tr>
          <tr>
              <td>VPN</td>
              <td>0</td>
              <td>1</td>
              <td>2</td>
              <td>3</td>
          </tr>
      </tbody>
  </table>
</li>
<li>
<p>TLB</p>
<table>
<thead>
<tr>
<th>Valid</th>
<th>VPN</th>
<th>PPN</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>1</td>
<td>5</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>4</td>
</tr>
</tbody>
</table>
</li>
<li>
<p>Memory Access</p>
<table>
<thead>
<tr>
<th>What virtual addresses?</th>
<th>What physical addresses?</th>
</tr>
</thead>
<tbody>
<tr>
<td>load 0x1000</td>
<td>load 0x0004 <br>load 0x5000</td>
</tr>
<tr>
<td>load 0x1004</td>
<td>(TLB hit) <br>load 0x5004</td>
</tr>
<tr>
<td>load 0x1008</td>
<td>(TLB hit) <br>load 0x5008</td>
</tr>
<tr>
<td>load 0x100C</td>
<td>(TLB hit) <br>load 0x500C</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
</tr>
<tr>
<td>load 0x2000</td>
<td>load 0x0008 <br>load 0x4000</td>
</tr>
<tr>
<td>load 0x2004</td>
<td>(TLB hit) <br>load 0x4004</td>
</tr>
</tbody>
</table>
</li>
<li>
<p>Performance</p>
<ul>
<li># TLB lookups = number of accesses to a = 2048</li>
<li># TLB misses = 2</li>
<li>Miss rate = 2/2048 = 0.1%</li>
<li>Hit rate = 1 – miss rate = 99.9%</li>
</ul>
</li>
</ul>
<h3 id="tlb-replacement-policies"><a class="markdownIt-Anchor" href="#tlb-replacement-policies"></a> TLB Replacement Policies</h3>
<ul>
<li>
<p>Access Patterns</p>
<ul>
<li>Sequential array accesses almost always hit in TLB: Very fast!</li>
<li>Highly random, with no repeat accesses: Slow</li>
</ul>
</li>
<li>
<p>Code Example</p>
<table>
<thead>
<tr>
<th>Workload A</th>
<th>Workload B</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="https://i.imgur.com/fg4fYXO.png" alt=""></td>
<td><img src="https://i.imgur.com/b3eYUnz.png" alt=""></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td><img src="https://i.imgur.com/HWMGImG.png" alt=""></td>
<td><img src="https://i.imgur.com/iMYOS03.png" alt=""></td>
</tr>
</tbody>
</table>
</li>
<li>
<p>Workload Locality</p>
<ul>
<li>Spatial Locality: future access will be to nearby addresses</li>
<li>Temporal Locality: future access will be repeats to the same data</li>
</ul>
</li>
<li>
<p>What TLB characteristics are best for each type?</p>
<ul>
<li>
<p>Spatial:</p>
<ul>
<li>Access same page repeatedly; need same vpn à ppn translation</li>
<li>Same TLB entry re-used</li>
</ul>
</li>
<li>
<p>Temporal:</p>
<ul>
<li>Access same address near in future</li>
<li>Same TLB entry re-used in near future</li>
<li>How near in future? How many TLB entries are there?</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Replacement policies</p>
<ul>
<li>LRU: evict Least-Recently Used TLB slot when needed</li>
<li>Random: Evict randomly choosen entry</li>
</ul>
</li>
</ul>
<h3 id="context-switches"><a class="markdownIt-Anchor" href="#context-switches"></a> Context Switches</h3>
<ul>
<li>
<p>What happens if a process uses cached TLB entries from another process?</p>
<ol>
<li>
<p>Flush TLB on each switch</p>
<ul>
<li>Costly</li>
<li>lose all recently cached translations</li>
</ul>
</li>
<li>
<p>Track which entries are for which process</p>
<ul>
<li>Address Space Identifier</li>
<li>Tag each TLB entry with an 8-bit ASID</li>
</ul>
</li>
</ol>
</li>
<li>
<p>TLB Example with ASID</p>
<ul>
<li>
<p>Pagetable</p>
<ul>
<li>P1 (ASID 11): 1, 5, 4, …</li>
<li>P2 (ASID 12): 6, 2, 3, …</li>
</ul>
</li>
<li>
<p>TLB</p>
<table>
<thead>
<tr>
<th>Valid</th>
<th>Virt</th>
<th>Phys</th>
<th>ASID</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>1</td>
<td>9</td>
<td>11</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>5</td>
<td>11</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>2</td>
<td>12</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>1</td>
<td>11</td>
</tr>
</tbody>
</table>
</li>
<li>
<p>Memory access</p>
<table>
<thead>
<tr>
<th>Virtual</th>
<th>Physical</th>
</tr>
</thead>
<tbody>
<tr>
<td>load 0x1444 with ASID 12</td>
<td>0x2444</td>
</tr>
<tr>
<td>load 0x1444 with ASID 11</td>
<td>0x5444</td>
</tr>
</tbody>
</table>
</li>
</ul>
</li>
<li>
<p>TLB Performance</p>
<ul>
<li>
<p>Context switches are expensive</p>
</li>
<li>
<p>Even with ASID, other processes “pollute” TLB</p>
<ul>
<li>Discard process A’s TLB entries for process B’s entries</li>
</ul>
</li>
<li>
<p>Architectures can have multiple TLBs</p>
<ul>
<li>1 TLB for data, 1 TLB for instructions</li>
<li>1 TLB for regular pages, 1 TLB for “super pages”</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="tlb-misses"><a class="markdownIt-Anchor" href="#tlb-misses"></a> TLB Misses</h3>
<ul>
<li>
<p>Who Handles TLB MISS? Hardware or OS?</p>
</li>
<li>
<p>Hardware: CPU must know where pagetables are</p>
<ul>
<li>CR3 register on x86</li>
<li>Pagetable structure fixed and agreed upon between HW and OS</li>
<li>HW “walks” the pagetable and fills TLB</li>
</ul>
</li>
<li>
<p>OS: “Software-managed TLB”</p>
<ul>
<li>CPU traps into OS upon TLB miss</li>
<li>OS interprets pagetables as it chooses</li>
<li>Modifying TLB entries is privileged</li>
<li>Need same protection bits in TLB as pagetable - rwx</li>
</ul>
</li>
</ul>
<h3 id="summary-2"><a class="markdownIt-Anchor" href="#summary-2"></a> Summary</h3>
<ul>
<li>
<p>Pages are great, but accessing page tables for every memory access is slow</p>
</li>
<li>
<p>Cache recent page translations -&gt; TLB</p>
<ul>
<li>Hardware performs TLB lookup on every memory access</li>
</ul>
</li>
<li>
<p>TLB performance depends strongly on workload</p>
<ul>
<li>Sequential workloads perform well</li>
<li>Workloads with temporal locality can perform well</li>
</ul>
</li>
<li>
<p>In different systems, hardware or OS handles TLB misses</p>
</li>
<li>
<p>TLBs increase cost of context switches</p>
<ul>
<li>Flush TLB on every context switch</li>
<li>Add ASID to every TLB entry</li>
</ul>
</li>
</ul>
<h2 id="smaller-page-tables"><a class="markdownIt-Anchor" href="#smaller-page-tables"></a> Smaller Page Tables</h2>
<h3 id="motivation"><a class="markdownIt-Anchor" href="#motivation"></a> Motivation</h3>
<ul>
<li>
<p>How big are page tables</p>
<ol>
<li>
<p>PTE’s are 2 bytes, and 32 possible virtual page numbers</p>
<ul>
<li>2 bytes * 32 = 64 bytes</li>
</ul>
</li>
<li>
<p>PTE’s are 2 bytes, virtual addrs are 24 bits, pages are 16 bytes</p>
<ul>
<li>16 bytes page =&gt; 4 bit offset =&gt; 20 bit VPN</li>
<li>=&gt; 2^20 Pages =&gt;  2^20 * 2 = 2MB for page tables</li>
</ul>
</li>
<li>
<p>PTE’s are 4 bytes, virtual addrs are 32 bits, and pages are 4 KB</p>
<ul>
<li>4KB page =&gt; 12 bit offset =&gt; 20 bit VPN</li>
<li>=&gt; 2^20 Pages =&gt;  2^20 * 4 = 4MB for page tables</li>
</ul>
</li>
<li>
<p>PTE’s are 4 bytes, virtual addrs are 64 bits, and pages are 4 KB</p>
<ul>
<li>4KB page =&gt; 12 bit offset =&gt; 52 bit VPN</li>
<li>=&gt; 2^52 Pages =&gt;  2^52 * 4 = 18.0143985 PB for page tables</li>
</ul>
</li>
</ol>
</li>
<li>
<p>Why are Page Tables so Large?</p>
<ul>
<li>Many invalid PT entries</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/hw6UrkL.png" alt=""></p>
<ul>
<li>Summary
<ul>
<li>
<p>Storage for page tables may be substantial</p>
</li>
<li>
<p>Simple page table: Requires PTE for all pages in address space</p>
</li>
<li>
<p>Entry needed even if page not allocated.</p>
</li>
</ul>
</li>
</ul>
<h3 id="smaller-page-tables-2"><a class="markdownIt-Anchor" href="#smaller-page-tables-2"></a> Smaller Page Tables</h3>
<ul>
<li>
<p>Use more complex page tables, instead of just big array</p>
</li>
<li>
<p>Any data structure is possible with software-managed TLB</p>
<ul>
<li>
<p>Hardware looks for vpn in TLB on every memory access</p>
</li>
<li>
<p>If TLB does not contain vpn, TLB miss</p>
<ul>
<li>Trap into OS and let OS find vpn-&gt;ppn translation</li>
<li>OS notifies TLB of vpn-&gt;ppn for future accesses</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Other approaches</p>
<ol>
<li>
<p>Segmented Pagetables</p>
</li>
<li>
<p>Multi-level Pagetables</p>
<ul>
<li>Page the page tables</li>
<li>Page the pagetables of page tables…</li>
</ul>
</li>
<li>
<p>Inverted Pagetables</p>
</li>
</ol>
</li>
</ul>
<h3 id="paging-with-segmentation"><a class="markdownIt-Anchor" href="#paging-with-segmentation"></a> Paging with Segmentation</h3>
<ul>
<li>
<p>Idea</p>
<ul>
<li>
<p>Divide address space into segments (code, heap, stack)</p>
</li>
<li>
<p>Divide each segment into fixed-sized pages</p>
</li>
<li>
<p>Logical address divided into three portions</p>
<table>
<thead>
<tr>
<th>seg # (4 bits)</th>
<th>page number (8 bits)</th>
<th>page offset (12 bits)</th>
</tr>
</thead>
<tbody></tbody>
</table>
</li>
</ul>
</li>
<li>
<p>Implementation</p>
<ul>
<li>Each segment has a page table</li>
<li>Each segment track base (physical address) and bounds of the page table</li>
</ul>
</li>
<li>
<p>Quiz</p>
<ul>
<li>
<p>Logical address layout</p>
<table>
<thead>
<tr>
<th>seg # (4 bits)</th>
<th>page number (8 bits)</th>
<th>page offset (12 bits)</th>
</tr>
</thead>
<tbody></tbody>
</table>
</li>
<li>
<p>Segment Table</p>
<table>
<thead>
<tr>
<th>Segment</th>
<th>Base</th>
<th>Bounds</th>
<th>R W</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0x002000</td>
<td>0xff</td>
<td>1 0</td>
</tr>
<tr>
<td>1</td>
<td>0x000000</td>
<td>0x00</td>
<td>0 0</td>
</tr>
<tr>
<td>2</td>
<td>0x001000</td>
<td>0x0f</td>
<td>1 1</td>
</tr>
</tbody>
</table>
</li>
<li>
<p>Translation</p>
<table>
<thead>
<tr>
<th>Virtual</th>
<th>Seg</th>
<th>Base</th>
<th>Offset</th>
<th>PPN</th>
<th>Physical</th>
<th>Note</th>
</tr>
</thead>
<tbody>
<tr>
<td>0x002070 R</td>
<td>0</td>
<td>0x002000</td>
<td>2</td>
<td>0x004</td>
<td>0x004070</td>
<td></td>
</tr>
<tr>
<td>0x202016 R</td>
<td>2</td>
<td>0x001000</td>
<td>2</td>
<td>0x003</td>
<td>0x003016</td>
<td></td>
</tr>
<tr>
<td>0x104c84 R</td>
<td>1</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>R = 0</td>
</tr>
<tr>
<td>0x010424 W</td>
<td>0</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>W = 0</td>
</tr>
<tr>
<td>0x210014 W</td>
<td>2</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>bounds</td>
</tr>
<tr>
<td>0x203568 W</td>
<td>2</td>
<td>0x001000</td>
<td>3</td>
<td>0x02a</td>
<td>0x02a568</td>
<td></td>
</tr>
</tbody>
</table>
</li>
</ul>
</li>
<li>
<p>Advantages</p>
<ul>
<li>
<p>Advantages of Segments</p>
<ul>
<li>Supports sparse address spaces.</li>
<li>Decreases size of page tables. If segment not used, not need for page table</li>
</ul>
</li>
<li>
<p>Advantages of Pages</p>
<ul>
<li>No external fragmentation</li>
<li>Segments can grow without any reshuffling</li>
<li>Can run process when some pages are swapped to disk (next lecture)</li>
</ul>
</li>
<li>
<p>Advantages of Both</p>
<ul>
<li>Increases flexibility of sharing: Share either single page or entire segment</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Disadvantages</p>
<ul>
<li>Potentially large page tables (for each segment)</li>
<li>Must allocate each page table contiguously</li>
<li>More problematic with more address bits</li>
</ul>
</li>
</ul>
<h3 id="multilevel-page-tables"><a class="markdownIt-Anchor" href="#multilevel-page-tables"></a> Multilevel Page Tables</h3>
<ul>
<li>
<p>Goal: Allow each page tables to be allocated non-contiguously</p>
</li>
<li>
<p>Idea: Page the page tables</p>
<ul>
<li>Creates multiple levels of page tables; outer level “page directory”</li>
<li>Only allocate page tables for pages in use</li>
<li>Used in x86 architectures (hardware can walk known structure)</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/9bSULQI.png" alt=""></p>
<ul>
<li>
<p>Multilevel Pagetable Translation</p>
<ul>
<li>
<p>Page directory and page tables</p>
<table>
<thead>
<tr>
<th></th>
<th>0x0</th>
<th>0x1</th>
<th>…</th>
<th>0xE</th>
<th>0xF</th>
</tr>
</thead>
<tbody>
<tr>
<td>Page directory</td>
<td>0x3</td>
<td>-</td>
<td>…</td>
<td>-</td>
<td>0x92</td>
</tr>
<tr>
<td>PT @PPN 0x3</td>
<td>0x10</td>
<td>0x23</td>
<td>…</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>PT @PPN 0x92</td>
<td>-</td>
<td>-</td>
<td>…</td>
<td>0x55</td>
<td>0x45</td>
</tr>
</tbody>
</table>
</li>
<li>
<p>Address layout</p>
<table>
<thead>
<tr>
<th>outer page (4)</th>
<th>inner page (4)</th>
<th>page offset (12)</th>
</tr>
</thead>
<tbody></tbody>
</table>
</li>
</ul>
<ol>
<li>
<p>Translate 0x01ABC</p>
<ul>
<li>Outer page = 0x0 =&gt; Use page table at 0x3</li>
<li>Inner page = 0x1 =&gt; PPN = 0x23</li>
<li>Physical address = 0x23ABC</li>
</ul>
</li>
<li>
<p>Translate 0xFEED0</p>
<ul>
<li>Outer page = 0xF =&gt; Use page table at 0x92</li>
<li>Inner page = 0xE =&gt; PPN = 0x55</li>
<li>Physical address = 0x55ED0</li>
</ul>
</li>
</ol>
</li>
<li>
<p>Address Format for Multilevel Paging</p>
<ul>
<li>Given 30-bit address with 4KB page size</li>
<li>#bits for page offset = log(4K) = 12</li>
<li>4 bytes per PTE =&gt; 1K entries per page =&gt; #bits for inner page = log(1K) = 10</li>
<li>#bits for outer page = 30 - 10 - 12 = 8</li>
</ul>
</li>
<li>
<p>Pagetable with 3 levels</p>
<ul>
<li>
<p>Problem</p>
<ul>
<li>Page directories (outer level) may not fit in a page</li>
</ul>
</li>
<li>
<p>Solution</p>
<ul>
<li>Split page directories into pieces</li>
<li>Use another page dir to refer to the page dir pieces.</li>
</ul>
</li>
<li>
<p>Memory Addressability Comparison</p>
<ul>
<li>1 level = 2<sup>10</sup> * 2<sup>12</sup> = 4MB</li>
<li>2 level = (2<sup>10</sup>)<sup>2</sup> * 2<sup>12</sup> = 4GB</li>
<li>3 level = (2<sup>10</sup>)<sup>3</sup> * 2<sup>12</sup> = 4TB</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Quiz: Count Memory Access</p>
<ul>
<li>
<p>Assumption</p>
<ul>
<li>3-level page table</li>
<li>256-byte pages</li>
<li>16-bit addresses</li>
<li>ASIC of current process is 211</li>
</ul>
</li>
<li>
<p>TLB</p>
<table>
<thead>
<tr>
<th>ASID</th>
<th>VPN</th>
<th>PFN</th>
<th>Valid</th>
</tr>
</thead>
<tbody>
<tr>
<td>211</td>
<td>0xbb</td>
<td>0x91</td>
<td>1</td>
</tr>
<tr>
<td>211</td>
<td>0xff</td>
<td>0x23</td>
<td>1</td>
</tr>
<tr>
<td>122</td>
<td>0x05</td>
<td>0x91</td>
<td>1</td>
</tr>
<tr>
<td>211</td>
<td>0x05</td>
<td>0x12</td>
<td>0</td>
</tr>
</tbody>
</table>
</li>
</ul>
<ol>
<li>
<p>0xAA10: movl 0x1111, %edi</p>
<ul>
<li>
<p>TLB miss for 0xAA10 =&gt; 3 memory accesses for page table + 1 more to get the instruction</p>
</li>
<li>
<p>TLB miss for 0x1111 =&gt; 3 memory accesses for page table + 1 more to get the instruction</p>
</li>
<li>
<p>Total: 4 memory accesses</p>
</li>
</ul>
</li>
<li>
<p>0xBB13: addl $0x3, %edi</p>
<ul>
<li>TLB hit for 0xBB13 =&gt; 1 access more to get the instruction</li>
</ul>
</li>
<li>
<p>0x0519: movl %edi, 0xFF10</p>
<ul>
<li>
<p>TLB miss for 0x0519 =&gt; 3 memory access for page table + 1 more to get the instruction</p>
</li>
<li>
<p>TLB hit for 0xFF10 =&gt; 1 access more to get the instruction</p>
</li>
<li>
<p>Total: 5 memory accesses</p>
</li>
</ul>
</li>
</ol>
</li>
</ul>
<h3 id="inverted-page-table"><a class="markdownIt-Anchor" href="#inverted-page-table"></a> Inverted Page Table</h3>
<ul>
<li>
<p>Only need entries for virtual pages w/ valid physical mappings</p>
</li>
<li>
<p>Naïve approach:</p>
<ul>
<li>Search through data structure &lt;ppn, vpn+asid&gt; to find match</li>
<li>Too much time to search entire table</li>
</ul>
</li>
<li>
<p>Better:</p>
<ul>
<li>Find possible matches entries by hashing vpn+asid</li>
<li>Smaller number of entries to search for exact match</li>
</ul>
</li>
<li>
<p>Managing inverted page table requires software-controlled TLB</p>
</li>
</ul>
<h2 id="swapping"><a class="markdownIt-Anchor" href="#swapping"></a> Swapping</h2>
<h3 id="motivation-2"><a class="markdownIt-Anchor" href="#motivation-2"></a> Motivation</h3>
<ul>
<li>Support processes when not enough physical memory</li>
<li>Single process with very large address space</li>
<li>Multiple processes with combined address spaces</li>
</ul>
<h3 id="idea"><a class="markdownIt-Anchor" href="#idea"></a> Idea</h3>
<ul>
<li>
<p>OS keeps unreferenced pages on disk</p>
<ul>
<li>Slower, cheaper backing store than memory</li>
</ul>
</li>
<li>
<p>Process can run when not all pages are loaded into main memory</p>
</li>
<li>
<p>OS and hardware cooperate to make large disk seem like memory</p>
<ul>
<li>Same behavior as if all of address space in main memory</li>
</ul>
</li>
</ul>
<h3 id="locality-of-reference"><a class="markdownIt-Anchor" href="#locality-of-reference"></a> Locality of Reference</h3>
<ul>
<li>
<p>Leverage locality of reference within processes</p>
<ul>
<li>Spatial: reference memory addresses near previously referenced addresses</li>
<li>Temporal: reference memory addresses that have referenced in the past</li>
<li>Processes spend majority of time in small portion of code</li>
</ul>
</li>
<li>
<p>Implication:</p>
<ul>
<li>Process only uses small amount of address space at any moment</li>
<li>Only small amount of address space must be resident in physical memory</li>
</ul>
</li>
<li>
<p>Memory Hierarchy</p>
<p><img src="https://i.imgur.com/pi58bfR.png" alt=""></p>
</li>
</ul>
<h3 id="mechanism-2"><a class="markdownIt-Anchor" href="#mechanism-2"></a> Mechanism</h3>
<ul>
<li>
<p>Each page in virtual address space maps to one of three locations:</p>
<ul>
<li>Physical main memory: Small, fast, expensive</li>
<li>Disk (backing store): Large, slow, cheap</li>
<li>Nothing (error): Free</li>
</ul>
</li>
<li>
<p>Extend page tables with an extra bit: present</p>
<ul>
<li>permissions (r/w), valid, present</li>
<li>Page in memory: present bit set in PTE</li>
<li>Page on disk: present bit cleared
<ul>
<li>PTE points to block on disk</li>
<li>Causes trap into OS when page is referenced</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Procedure</p>
  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Hardware checks TLB</span><br><span class="line"><span class="keyword">if</span> TLB hit</span><br><span class="line">    address translation is done</span><br><span class="line">    page in physical memory</span><br><span class="line"><span class="keyword">else</span> <span class="comment">// TLB miss</span></span><br><span class="line">    Hardware <span class="keyword">or</span> OS walk page tables</span><br><span class="line">    <span class="keyword">if</span> PTE designates page is present</span><br><span class="line">        page in physical memory (i.e., present bit is cleared)</span><br><span class="line">    <span class="keyword">else</span> <span class="comment">// page fault</span></span><br><span class="line">        Trap into OS (<span class="keyword">not</span> handled by hardware)</span><br><span class="line">        OS selects victim page in memory to replace</span><br><span class="line">        <span class="keyword">if</span> victim page is modified</span><br><span class="line">            write victim page out to disk</span><br><span class="line">        OS reads referenced page from disk into memory</span><br><span class="line">        Page table is updated, present bit is <span class="built_in">set</span></span><br><span class="line">        Process continues execution</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="policy-page-selection"><a class="markdownIt-Anchor" href="#policy-page-selection"></a> Policy: Page selection</h3>
<ul>
<li>
<p>When should a page on disk be brought into memory?</p>
</li>
<li>
<p>Demand paging: Load page only when page fault occurs</p>
<ul>
<li>Intuition: Wait until page must absolutely be in memory</li>
<li>When process starts: No pages are loaded in memory</li>
<li>Problems: Pay cost of page fault for every newly accessed page</li>
</ul>
</li>
<li>
<p>Prepaging (anticipatory, prefetching): Load page before referenced</p>
<ul>
<li>OS predicts future accesses (oracle) and brings pages into memory early</li>
<li>Works well for some access patterns (e.g., sequential)</li>
</ul>
</li>
<li>
<p>Hints: Combine above with user-supplied hints about page references</p>
<ul>
<li>User specifies: may need page in future, don’t need this page anymore, or sequential access pattern, …</li>
<li>Example: madvise() in Unix</li>
</ul>
</li>
</ul>
<h3 id="policy-page-replacement"><a class="markdownIt-Anchor" href="#policy-page-replacement"></a> Policy: Page replacement</h3>
<ul>
<li>
<p>Which resident page in memory should be thrown out to disk?</p>
</li>
<li>
<p>OPT: Replace page not used for longest time in future</p>
<ul>
<li>Advantages: Guaranteed to minimize number of page faults</li>
<li>Disadvantages: Requires that OS predict the future; Not practical, but good for comparison</li>
</ul>
</li>
<li>
<p>FIFO: Replace page that has been in memory the longest</p>
<ul>
<li>Intuition: First referenced long time ago, done with it now</li>
<li>Advantages: Fair: All pages receive equal residency; Easy to implement</li>
<li>Disadvantage: Some pages may always be needed</li>
</ul>
</li>
<li>
<p>LRU: Replace page not used for longest time in past</p>
<ul>
<li>Intuition: Use past to predict the future</li>
<li>Advantages: With locality, LRU approximates OPT</li>
<li>Disadvantages: Harder to implement and does not handle all workloads well</li>
</ul>
</li>
<li>
<p>Comparison</p>
<table>
<thead>
<tr>
<th>LRU, OPT</th>
<th>FIFO</th>
</tr>
</thead>
<tbody>
<tr>
<td>Guaranteed to  have fewer page faults<br>Smaller memory sizes ⊆ larger memory sizes<br>Smaller cache ⊆ bigger cache</td>
<td>Usually have fewer page faults <br>May actually have more page faults!</td>
</tr>
</tbody>
</table>
</li>
</ul>
<h3 id="implementing-lru"><a class="markdownIt-Anchor" href="#implementing-lru"></a> Implementing LRU</h3>
<ul>
<li>
<p>Software Perfect LRU</p>
<ul>
<li>OS maintains ordered list of physical pages by reference time</li>
<li>When page is referenced: Move page to front of list</li>
<li>When need victim: Pick page at back of list</li>
<li>Trade-off: Slow on memory reference, fast on replacement</li>
</ul>
</li>
<li>
<p>Hardware Perfect LRU</p>
<ul>
<li>Associate timestamp register with each page</li>
<li>When page is referenced: Store system clock in register</li>
<li>When need victim: Scan through registers to find oldest clock</li>
<li>Trade-off: Fast on memory reference, slow on replacement (especially as size of memory grows)</li>
</ul>
</li>
<li>
<p>Approximating LRU: Clock Algorithm</p>
<ul>
<li>
<p>Hardware</p>
<ul>
<li>Keep use (or reference) bit for each page frame</li>
<li>When page is referenced: set use bit (page was used recently)</li>
</ul>
</li>
<li>
<p>Operating System</p>
<ul>
<li>Page replacement: Look for page with use bit cleared (has not been referenced for a while)</li>
</ul>
<ol>
<li>Keep pointer to last examined page frame</li>
<li>Traverse pages in circular buffer</li>
<li>Clear use bits as search</li>
<li>Stop when find page with already cleared use bit, replace this page</li>
</ol>
</li>
</ul>
</li>
</ul>
<img src="https://i.imgur.com/WYNCIhZ.png" style="margin:auto; display: block;">
<h2 id="summary-3"><a class="markdownIt-Anchor" href="#summary-3"></a> Summary</h2>
<ul>
<li>
<p>Abstraction: Virtual address space with code, heap, stack</p>
</li>
<li>
<p>Address translation</p>
<ul>
<li>Contiguous memory: base, bounds, segmentation</li>
<li>Using fixed sizes pages with page tables</li>
</ul>
</li>
<li>
<p>Challenges with paging</p>
<ul>
<li>Extra memory references: avoid with TLB</li>
<li>Page table size: avoid with multi-level paging, inverted page tables etc.</li>
</ul>
</li>
<li>
<p>Larger address spaces: Swapping mechanisms, policies (LRU, Clock)</p>
</li>
</ul>

      
      <!-- reward -->
      
    </div>
      <!-- copyright -->
      
    <footer class="article-footer">
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/OS/">OS</a></li></ul>


    </footer>

  </div>

  

  
  
  

  

</article>
    
  </article>
  

  
  <nav class="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">下一页</a>
  </nav>
  
</section>
</div>

      <footer class="footer">
  <div class="outer">
    <ul class="list-inline">
      <li>
        &copy;
        2016-2020
        th2zz
      </li>
      <li>
        
      </li>
    </ul>
    <ul class="list-inline">
      <li>
        
      </li>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>
  </div>
</footer>
    <div class="to_top">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>
      </div>
    </main>
      <aside class="sidebar">
        <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="th2zz"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Suche">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
      </aside>
      <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
      <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.justifiedGallery.min.js"></script>
<script src="/js/lazyload.min.js"></script>
<script src="/js/busuanzi-2.3.pure.min.js"></script>
<script src="/js/share.js"></script>



<script>
  try {
    var typed = new Typed("#subtitle", {
    strings: ['生きるとはつまり螺旋のことだったんだよ！','',''],
    startDelay: 0,
    typeSpeed: 200,
    loop: true,
    backSpeed: 100,
    showCursor: true
    });
  } catch (err) {
  }
  
</script>




<script>
  var ayerConfig = {
    mathjax: false
  }
</script>

<script src="/js/ayer.js"></script>

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">


<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>




<script type="text/javascript" src="https://js.users.51.la/20544303.js"></script>
  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>

</html>