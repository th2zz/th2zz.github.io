<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>th2zz</title>
  
  <subtitle>th2zz&#39;s notes</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://th2zz.github.io/"/>
  <updated>2020-03-10T14:33:32.401Z</updated>
  <id>http://th2zz.github.io/</id>
  
  <author>
    <name>th2zz</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>网络,OS,DB,分布式-一万字知识总结</title>
    <link href="http://th2zz.github.io/2020/02/16/%E7%BD%91%E7%BB%9COS%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    <id>http://th2zz.github.io/2020/02/16/网络OS数据库分布式/</id>
    <published>2020-02-15T18:14:41.000Z</published>
    <updated>2020-03-10T14:33:32.401Z</updated>
    
    <content type="html"><![CDATA[<h1 id="网络模型"><a class="markdownIt-Anchor" href="#网络模型"></a> 网络模型</h1><ul><li>电路交换<ul><li>不灵活 成本高 需要专有物理线路 需要建立专有连接 线路利用率低 没有转发机制</li><li>容易受网络中断影响</li></ul></li><li>包交换<ul><li>更灵活 成本低 不需要专用线路 可以线路复用  线路利用率高</li><li>不容易受网络中断影响</li></ul></li><li>我们的网络：**统计复用包交换网络 ** 统计复用=排队<ul><li>Internet:<strong>不可靠网络</strong> IP-service model / IP best-effort network /最大努力网络<ul><li>包可以<strong>丢失重复重排</strong> packets may <strong>lose, duplicate, reorder</strong></li><li><strong>无连接最大努力目的地转发</strong> connectionelss best-effort destination based forwarding.</li></ul></li><li>可靠：保证包能够<strong>不丢失 不重复 按序到达 无差错</strong></li></ul></li></ul><h1 id="传输过程和基本术语"><a class="markdownIt-Anchor" href="#传输过程和基本术语"></a> 传输过程和基本术语</h1><p><img src="https://img-blog.csdnimg.cn/20181201104548931.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2EzMTkyMDQ4,size_16,color_FFFFFF,t_70" alt="img"></p><ul><li>包在每个网络节点传输方式：<strong>上至下层层封装header 下至上层层解包</strong><ul><li>Message “报文” <strong>应用层</strong>的名称</li><li>Segment “报文段”  起始于<strong>传输层</strong>的信息单元</li><li>Datagram  “数据报 ” 使用<strong>udp等无连接服务</strong>的<strong>网络层</strong>信息单元</li><li>Packet “分组/包” 起始于<strong>网络层</strong>的信息单元</li><li>Frame“帧” 起始于<strong>链路层</strong>的传输单元</li><li>bit “比特” <strong>物理层</strong>单元</li></ul></li><li>Links: 链路 连接节点的物理介质</li><li>服务/接口: 不同层之间</li><li>协议：平级的peer之间</li><li>端对端 Client to Server  点对点 otherwise | 应用和传输层端对端<ul><li>E2E总时延 = 排队时延 + 处理时延 + 传输时延 + 传播时延</li><li>P2P总时延 = 传输时延 + 传播时延</li></ul></li><li>连接建立断开：通常需要多次握手/挥手</li><li><strong>两个port+ip 定义一个tcp stream / udp message</strong></li><li><strong>流量控制：保证接受者buffer能承受住  拥塞控制： 保证网络不过于堵塞</strong></li><li>可靠：保证包能够<strong>不丢失不重复按序到达无差错</strong>   重发丢失/损坏的包</li><li>根据信息在传输线上的传送方向，分为以下三种通信方式：<ul><li>单工通信Simplex：单向传输</li><li>半双工通信Half-duplex：双向<strong>交替</strong>传输</li><li>全双工通信Duplex：双向<strong>同时</strong>传输</li></ul></li><li>局域网：多种不同结构<ul><li>局域网是一种典型的广播信道，主要特点是网络为一个单位所拥有，且地理范围和站点数目均有限。有多种局域网技术，其中以太网占主导地位。可以按照网络拓扑结构对局域网进行分类：星 环 直线</li></ul></li><li>以太网：星形结构局域网 中间使用集线器或交换机连接</li><li>MAC地址 链路层地址 48位 设备网卡的唯一标识 有多少个适配器=多少个mac地址 os可更换</li><li>网络设备<ul><li>Hub 集线器 <strong>[layer 1 物理层]</strong>  作用于物理层的 能使多个主机 创建一个广播频道(only floods)的设备 具备多个网口，专门实现多台计算机的互联作用。</li><li>Repeater 中继器**[layer 1 物理层]** 接收并重复信号</li><li>Switch 交换机 <strong>[layer 2 数据链路层]</strong> 收处理转发以太网帧到网络中的其他设备 会维护一个&lt;mac link/接口&gt; 表 “交换表” 表类似一个LRU缓存 因此能够实现mac地址识别=说它具有“学习能力”. 支持同时存在多个点对点连接。</li><li>Bridge 网桥**[layer 2 数据链路层]** 连接两个局域网</li><li>Router 路由 <strong>[layer 3 网络层]</strong> 根据routing table提供转发和路由两种功能 转发：将数据包移送到合适输出端 路由：决定数据包的路由路径。</li><li>Gateway 网关 <strong>[layer 3 物理层]</strong>  两个不同网络之间的关口设备</li></ul></li></ul><h1 id="网络io模型"><a class="markdownIt-Anchor" href="#网络io模型"></a> 网络IO模型</h1><ul><li>同步<ul><li>阻塞IO  更高CPU利用率  进程被阻塞 内核代替进程完成操作后返回状态码 进程恢复</li><li>非阻塞IO 浪费cpu  轮询 不可用则内核返回错误代码</li><li>IO复用: 让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O<ul><li>早期的实现<ul><li>select 等待固定数量的fd中1个或多个成为就绪状态  适用于实时性要求高的情况</li><li>poll 等待一组描述符中1个成为就绪状态   适合实时性要求相对宽松情况</li></ul></li><li>更现代的事件驱动实现<ul><li>epoll linux的io事件通知机制 监视多个fd等待任意一个可用  使用红黑树管理监视中的fd <strong>适用于linux上管理大量长连接情况</strong><ul><li>epoll_create创建一个epoll实例 epoll_ctl把一个事件添加到epoll列表 epoll_wait等待一个io事件就绪 否则阻塞calling thread</li><li>默认level triggered: epoll_wait监测到事件发生通知进程 进程可以不处理 下次调用时再处理</li><li>edge triggered发生事件立即通知 进程要立即处理</li></ul></li></ul></li></ul></li><li>信号驱动 使用较少 非阻塞等待创建signal handler 数据就绪后 os 发信号代表可以开始io 比非阻塞cpu利用率更高</li></ul></li><li>异步: 进程调用aio_read后立即返回 当io完成后os内核向进程发信号</li></ul><h1 id="分层架构"><a class="markdownIt-Anchor" href="#分层架构"></a> 分层架构</h1><ul><li>OSI architecture 7层协议 注重通信协议必要功能<ul><li>应用层：<strong>e2e 用户服务</strong>  <strong>HTTP FTP DNS DHCP</strong> 远程登录 邮件<ul><li>表示层：数据表示, 压缩, 加密</li><li>会话层：建立及管理会话 <strong>SSL RPC</strong></li></ul></li><li>传输层：<strong>e2e 为应用进程提供端对端通信+在应用层网络层之间multiplexing和demultiplexing TCP UDP</strong></li><li>网络层：<strong>p2p 无连接通讯，寻址，路由</strong> 控制数据在子网中的运行.  <strong>IP ICMP RIP OSPF BGP</strong> ARP</li><li>数据链路层： <strong>p2p 相邻网络节点/主机的数据的格式化与传输控制</strong> <strong>LAN WAN LLC MAC</strong> ARP MTU</li><li>物理层：点对点比特流传输 01=电流强弱 数模转换 模数转换</li></ul></li><li>TCP/IP architecture 4层协议 计算机上实现应关心的 除了传输层 网络层 其他上下合并<ul><li>应用层：应用+表示+会话</li><li>传输层，网络层</li><li>链路层：数据链路+物理</li></ul></li></ul><h2 id="数据链路层"><a class="markdownIt-Anchor" href="#数据链路层"></a> 数据链路层</h2><p>Data Link Layer 点对点<strong>相邻网络节点/主机的数据的格式化与传输控制</strong> e.g. <strong>LAN WAN LLC MAC</strong> ARP MTU</p><ul><li>包装成帧<strong>Framing</strong> 把网络层传下来的包封装成帧 加个开始和结束</li><li>点对点传输控制<strong>P2P transmission control</strong>: <strong>Logical link control (LLC)</strong><ul><li><strong>Error Detection</strong> CRC checksum</li><li><s><strong>Flow Control</strong> &quot; only used in wireless networks</s></li></ul></li><li>广播控制<strong>Broadcast</strong>: <strong>Media access control (MAC)</strong><ul><li><strong>Frames synchronization</strong> 帧的同步 clock based, character counting, byte stuffing. STX ETX</li><li><strong>Channel sharing</strong> 信道共享方法:<ul><li>信道复用：时分，频分，码分</li><li>交替：轮询，令牌传递</li><li>随机访问   主要例子：Aloha, Ethernet<ul><li>Ethernet MAC采用CSMA/CD协议 (Carrier Sense Multiple Access / Collision Detection) 载波监听多点接入/碰撞检测<ul><li>线路空闲立即发送 (Carrier Sense 载波监听)</li><li>如果繁忙等待 “inter-frame gap” = 96 bit time</li><li>冲突发现，发送 jam signal, 进行二进制指数后退{1,2,4,8,…}, 然后延迟k*51.2 μs&quot; collision domain 冲突域 = 1 RTT</li></ul></li></ul></li></ul></li></ul></li></ul><h2 id="网络层"><a class="markdownIt-Anchor" href="#网络层"></a> 网络层</h2><p><strong>点对点无连接通讯，寻址，路由</strong> 控制数据在子网中的运行. 涉及协议： IP, ARP, ICMP, RIP, OSPF, BGP  IP是个不可靠的协议因为无连接 它的可靠性需要通过上层如TCP实现</p><ul><li>寻址<ul><li><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/85c05fb1-5546-4c50-9221-21f231cdc8c5.jpg" alt="img" style="zoom:40%;"></li><li>IP: 沙漏结构的中点，连接异构网络，使之看起来统一<ul><li><strong>地址系统</strong><ul><li>Class-based addressing (过去版本):  lead to problem of large# networks in routing table</li><li>Subnetting and supernetting 子网与超网<ul><li>子网 方便管理和路由效率 subnet ip = subnet mask &amp; host ip address</li><li>超网 用于跨网路由 CIDR 无分类跨网地址系统<ul><li>ip地址=网络前缀+主机号 128.14.35.7/20 表示前 20 位为网络前缀。</li><li>意义：减少了路由表项   查找时采取最长前缀匹配原则选择哪一个</li></ul></li></ul></li></ul></li></ul></li></ul></li><li>路由<ul><li><strong>ARP：Broadcast &amp; Responds路由器确定设备MAC</strong><ul><li>routers and hosts maintain an <strong>dynammic &lt;IP, MAC&gt; LRU cache</strong> called ARP table. For unkown IP, router <strong>broadcast ARP request</strong>, <strong>hosts</strong> with that IP address <strong>reply its MAC</strong></li></ul></li><li>Routing types and protocols<ul><li>网内路由Intra-domain<ul><li>RIP Routing Information Protocol:  rely on local computation in all nodes<ul><li>Distance Vector Protocol (based on <strong>Bellman-ford</strong>)</li></ul></li><li>OSPF Open Shortest Path First Protocol: no local computation  <strong>faster nonegative edge weight-loop-free convergence</strong><ul><li>Link state Protocol (based on <strong>Dijkstra’s shortest path</strong>)</li></ul></li></ul></li><li>跨网路由Inter-domain: <strong>BGP Border Gateway Protocol</strong></li></ul></li></ul></li><li><strong>报文的拆分重组</strong> Fragmentation/Reassembly: 使得异构网络能够以最大传输大小传输包<ul><li>和tcp合作 tcp负责mtu discovery<ul><li>TCP MTU Discovery: 不断增大发送数据包大小直到获得数据包过大的ICMP响应得出mtu</li></ul></li><li>和数据链路层合作 mtu协议定义链路支持最大传输大小</li></ul></li><li><strong>错误报告和控制</strong> ICMP</li><li><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/aa29cc88-7256-4399-8c7f-3cf4a6489559.png" alt="img" style="zoom:30%;">- **封装在 IP 数据报中**，但是不属于高层协议。</li><li>ping 用来测试两台主机之间的连通性 通过icmp echo实现</li><li>Traceroute 追踪一个数据包路径: 封装一个<strong>无法交付的udp包</strong>, 利用IP协议的**“ttl”字段**，尝试从每个网关到某个主机的路径引发ICMP 超时响应。</li></ul><h2 id="传输层tcpudp"><a class="markdownIt-Anchor" href="#传输层tcpudp"></a> 传输层TCP/UDP</h2><p><strong>端对端为应用进程提供端到端的通信服务 在应用层和网络层之间multiplexing和demultiplexing</strong> e.g. TCP UDP</p><ul><li>UDP: bare-bone protocol<ul><li><strong>无连接 不可靠 无流量拥塞控制</strong> 无时限吞吐量安全保证</li><li>但更可控更自由 可以在应用层实现可靠传输: RUDP</li><li>UDP header：src port, dest port, header length, checksum</li></ul></li><li>TCP: 面向连接 可靠 流量拥塞控制 基于字节流 全双工 差错校验<ul><li><strong>TCP header:</strong><ul><li>SRC，DST ports (16-bit each)</li><li><strong>Sequence #序号,     Ack #确认号</strong>(32-bit each) 序号：当前数据段第一个字节编号 tcp要用序号拼接数据 确认号：期望下个数据段第一个字节编号</li><li>Header length(data offset), reserve</li><li>Flags(indicate pkt types): <strong>SYN FIN ACK</strong> URG(紧急指针) PSH(不在接受者缓冲区等待) RST重制连接标志</li><li><strong>Receive window</strong> (16-bits 发送者接收窗口的大小) 用于<strong>流量控制flow control</strong></li><li><strong>Check sum: for error detection</strong></li><li><strong>Urgent Ptr: 优先级</strong></li><li>Options</li></ul></li><li>全双工：建立连接后可以双向收发数据</li><li>以连接为导向： 意味着需要主动建立连接</li><li>TCP提供包级别的可靠传输 (IP最大努力网络不能保证)<ul><li>UDP只提供位级别的可靠传输 由checksum实现 只能进行简单的检测看看数据是否污染</li></ul></li><li><strong>如何实现可靠传输</strong>：不丢失 不重复 按序到达 无差错<ul><li>不丢失<ul><li>确定包收到了：ack机制</li><li>确定包没收到：<strong>计时器/超时检测机制Retransmission Timeout</strong> 制定了超时标准要比RTT稍微多一点尽量接近RTT, RTO新= RTO旧*2  by karn’s algorithm</li><li>丢包补救：快重传+urgent ptr</li></ul></li><li>不重复 按序到达<ul><li>滑动窗口</li></ul></li><li>无差错<ul><li>Check sum</li></ul></li></ul></li><li>提供流量控制：确保接收方的buffer不会overflow<ul><li>receiver发送的ack报文中的receiver window表示自己仍可缓存的容量 若超过这个限制 sender必须等待receiver的ack和更新。将窗口字段设置为 0，则sender停止发送数据。这实际上调整了sender发送窗口大小和发送速率。</li></ul></li><li>提供拥塞控制：与整个网络有关, 网络比较拥挤的时候控制发送方的窗口。增加一个congestion window CWND<ul><li><strong>send window (#unacknowledge pkts in flight) = min(CWND, RWND</strong>) 当cwnd更小时，我们就进入了一个拥塞控制的模式<ul><li>慢开始与拥塞避免<ul><li>cwnd := 1, cwnd++ for each ack == cwnd*=2 each RTT 慢慢探测网络容量 指数增长 但是又被临界值限制 到达临界值后线性增长避免拥塞</li><li>cwnd &gt;= ssthresh do congestion avoidance: cwnd++ for each RTT;</li></ul></li><li>快重传和快恢复： 快重传解决丢包重发问题（3个重复包=包丢失），快恢复临界值减半后线性增长拥塞窗口：适应性的避免网络拥塞 on dupack (pkt loss) fast retransmit the next sequence from receiver side.  Fast recover it by setting ssthresh = cwnd/2, cwnd = ssthresh, do congestion avoidance</li></ul></li></ul></li></ul></li></ul><h3 id="三次握手-四次挥手"><a class="markdownIt-Anchor" href="#三次握手-四次挥手"></a> 三次握手 四次挥手</h3><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/e92d0ebc-7d46-413b-aec1-34a39602f787.png" alt="img" style="zoom:35%;"><ul><li><p><strong>为什么三次握手</strong>：TCP是一个<strong>全双工</strong>通信协议，也就是说它是<strong>双向收发</strong>的。<strong>初始序号是两边都要随机选择</strong>:因为安全问题要避免TCP sequence prediction attack。<strong>所以双方都要告诉对方自己的初始序号</strong> = 也就是<strong>通信双方数据原点的位置</strong>，<strong>所以至少要4次握手</strong>。SYN  ACK SYN ACK, <strong>然后因为tcp header里reserve flags部分SYN ACK是可以同时为1的 中间两个步骤可以合并</strong> 所以3次就够。</p></li><li><p>第三次握手过程中sender可以piggypack data而receiver只能在这次握手结束才可以。</p></li><li><p>在linux socket编程中，客户端执行connect()时，将触发三次握手。<br><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/f87afe72-c2df-4c12-ac03-9b8d581a8af8.jpg" alt="img" style="zoom:50%;"></p></li><li><p><strong>为什么四次挥手</strong>因为tcp全双工+tcp半关闭造成的。假如client主动关闭，那么直到client收到server的ack前，数据传输仍然可以从server—&gt;client进行，tcp是半关闭的client-server关了但server-client方向还没关，这也是为什么有close-wait状态的原因，服务器端要等待最后这一波数据传输的完成。所以这也解释了中间两次为什么不能像建立连接一样合并。当服务器没有数据要传时他就可以通过fin来释放自己方向的连接了。</p></li><li><p><strong>TIME_WAIT / 2MSL等待状态</strong>:</p><ul><li>确保server收到ack<ul><li>server接受了ack不需要TIME_WAIT，因为它已经完成同步了可以释放资源了。</li><li>client必须等待确定server收到ack，否则client直接关闭server会可能收不到ack无法正常关闭。</li><li>ack最久要1MSL到达server或者最坏情况没收到。取上界=1MSL</li><li>等待server回复的超时重传消息=最坏情况又1MSL</li><li>最坏要2MSL client才知道ack有没有到达</li></ul></li><li>避免新旧连接混淆</li></ul></li><li><p>在linux socket编程中，任何一方执行close()操作即可产生挥手操作。</p></li></ul><h3 id="滑动窗口"><a class="markdownIt-Anchor" href="#滑动窗口"></a> 滑动窗口</h3><ul><li>TCP使用滑动窗口实现流量控制和乱序重排和去重 (虽然tcp byte-oriented 以下为了方便说明 改为包/sequence 而不是字节)<ul><li>流量控制：<ul><li>Receive window用于接收方通知发送方自己还有可用缓冲区大小，发送方据此调整发送数据多少, 从而保证流量控制</li></ul></li><li>sender缓存：<strong>已发送但未确认的包</strong></li><li>receiver缓存：<strong>未按序到达的包</strong></li><li>sender发送流水线化  提高信道利用率</li><li>receiver回复cumulative ack:<ul><li>receiver只对窗口内最后一个按序到达的包进行确认 = 之前全部按序到达窗口向右滑动</li><li>对于按序未到达的包 sender收不到ack超时重传</li><li>receiver收到该包，如果【该包+已缓存的未按序到达的包 】构成一段连续有序的segment 那么他们可以被交付给应用进程，窗口向右滑动</li></ul></li></ul></li><li>sender</li></ul><table><thead><tr><th>窗口外已发送并收到确认</th><th><strong>已发送未确认</strong></th><th><strong>可发但未发</strong></th><th>窗口外不可发送</th></tr></thead><tbody><tr><td></td><td></td><td></td><td></td></tr></tbody></table><ul><li>receiver</li></ul><table><thead><tr><th>窗口外按序到达acked且交付的</th><th><strong>按序未到达</strong></th><th><strong>未按序到达</strong></th><th>允许接受</th><th>窗口外不许接收</th></tr></thead><tbody><tr><td></td><td></td><td></td><td></td><td></td></tr></tbody></table><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/a3253deb-8d21-40a1-aae4-7d178e4aa319.jpg" alt="img" style="zoom:40%;"><h3 id="拥塞控制"><a class="markdownIt-Anchor" href="#拥塞控制"></a> 拥塞控制</h3><p>如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。<br><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/51e2ed95-65b8-4ae9-8af3-65602d452a25.jpg" alt="img" style="zoom:30%;"><br><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/910f613f-514f-4534-87dd-9b4699d59d31.png" alt="img" style="zoom:30%;"></p><h4 id="慢开始与拥塞避免"><a class="markdownIt-Anchor" href="#慢开始与拥塞避免"></a> 慢开始与拥塞避免</h4><ul><li>Slow start: 初始 cwnd = 1，每收到1个ack cwnd++，cwnd指数增长：2、4、8 …</li><li>为cwnd避免过快，设置一个慢开始门限 ssthresh，当 cwnd &gt;= ssthresh 时，进入拥塞避免-每个轮次cwnd++ 线性增长</li><li>若超时: 令 ssthresh = cwnd / 2，重新执行慢开始。</li></ul><h4 id="快重传与快恢复"><a class="markdownIt-Anchor" href="#快重传与快恢复"></a> 快重传与快恢复</h4><ul><li>如何确定报文丢失：接收方只对最后一个收到的有序报文段进行确认。在发送方，如果收到<strong>三个重复确认</strong>，那么可以知道接收方下一个报文段丢失，此时执行快重传</li><li>只是丢失个别报文段而不是网络拥塞：执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，直接进入拥塞避免cwnd线性增长<br><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/f61b5419-c94a-4df1-8d4d-aed9ae8cc6d5.png" alt="img" style="zoom:40%;"></li><li>SYN flood: client发第一个syn后下线server没收到ack不断尝试直到超时 linux:5次 1+2+…+32=63秒才断开连接，可被恶意利用<ul><li>防护:linux提供tcp_syncookies的参数 当syn队列满了 server通过该参数回发SYN cookie 若client非恶意会回复SYN cookie 直到连接成功建立</li></ul></li></ul><h2 id="应用层"><a class="markdownIt-Anchor" href="#应用层"></a> 应用层</h2><ul><li>2种架构: Client Server / Peer to Peer平级</li><li>Socket = 门, 传输层 = 走廊</li><li>主机和进程可以被ip+端口定义</li><li>远程登录： SSH  TELNET</li><li>邮件： 发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。</li><li>不同情况下应用有不同需求 数据丢失 vs 实时性 vs 吞吐量</li></ul><h3 id="常用端口"><a class="markdownIt-Anchor" href="#常用端口"></a> 常用端口</h3><table><thead><tr><th>应用</th><th>应用层协议</th><th>端口号</th><th>传输层协议</th><th>备注</th></tr></thead><tbody><tr><td><strong>域名解析</strong></td><td><strong>DNS</strong></td><td><strong>53</strong></td><td><strong>UDP/TCP</strong></td><td><strong>长度超过 512 字节时使用 TCP</strong></td></tr><tr><td><strong>动态主机配置协议</strong></td><td><strong>DHCP</strong></td><td><strong>67/68</strong></td><td><strong>UDP</strong></td><td></td></tr><tr><td><strong>超文本传送协议</strong></td><td><strong>HTTP</strong></td><td><strong>80</strong></td><td><strong>TCP</strong></td><td></td></tr><tr><td><strong>文件传送协议</strong></td><td><strong>FTP</strong></td><td><strong>20/21</strong></td><td><strong>TCP</strong></td><td>数据连接 20，控制连接 21</td></tr><tr><td>远程终端协议</td><td>TELNET</td><td>23</td><td>TCP</td><td>ssh = 22</td></tr><tr><td>简单邮件传送协议</td><td>SMTP</td><td>25</td><td>TCP</td><td></td></tr><tr><td>邮件读取协议</td><td>POP3</td><td>110</td><td>TCP</td><td></td></tr><tr><td>网际报文存取协议</td><td>IMAP</td><td>143</td><td>TCP</td><td></td></tr></tbody></table><h3 id="ftp"><a class="markdownIt-Anchor" href="#ftp"></a> FTP</h3><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/03f47940-3843-4b51-9e42-5dcaff44858b.jpg" alt="img" style="zoom:50%;"><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/be5c2c61-86d2-4dba-a289-b48ea23219de.jpg" alt="img" style="zoom:50%;"><ul><li><p>服务器主动(客户端配置服务端firewall) 服务器被动(只需开放端口号 不安全)</p></li><li><p>2个TCP连接： TCP数据连接端口20, TCP控制连接端口21.</p></li></ul><h3 id="dhcp"><a class="markdownIt-Anchor" href="#dhcp"></a> DHCP</h3><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/23219e4c-9fc0-4051-b33a-2bd95bf054ab.jpg" alt="img" style="zoom:50%;"><p>只适用于动态ip分配的情形，如进入一个新的移动网络。 主机不知道自己ip地址 ask dhcp server, 配置好IP地址,子网掩码,网关 IP 地址.</p><ul><li>client使用udp同子网内广播discover报文</li><li>dhcp server返回offer 包括多种选择</li><li>client选择一个ip 发送request</li><li>dhcp server返回ack</li></ul><h3 id="dns"><a class="markdownIt-Anchor" href="#dns"></a> DNS</h3><img src="https://s2.ax1x.com/2020/02/03/1NTl4S.png" alt="dns" style="zoom:31%;"><img src="https://s2.ax1x.com/2020/02/03/1NTMAf.png" alt="dns" style="zoom:31%;"><img src="https://s2.ax1x.com/2020/02/03/1NTuHP.png" alt="recdns" style="zoom:30%;">DNS 可以使用 **UDP 或者 TCP** 进行传输，**使用的端口号都为 53**。大多数情况下 DNS 使用 **UDP** 进行传输，这就要求域名解析器和域名服务器都必须**自己处理超时和重传**从而保证可靠性。在两种**特殊情况下会使用 TCP** 进行传输：<ul><li>如果返回的响应超过 512 字节（UDP 最大只支持 512 字节的数据）。</li><li>DNS zone transfer</li></ul><h4 id="dns-负载均衡"><a class="markdownIt-Anchor" href="#dns-负载均衡"></a> DNS 负载均衡</h4><p>同一主机在dns服务器里配置多个主机记录=多个不同服务器ip，dns服务器解析域名时会轮询，这就完成了简单的负载均衡。</p><h3 id="http-https"><a class="markdownIt-Anchor" href="#http-https"></a> HTTP HTTPS</h3><ul><li>URI 包含 URL 和 URN。</li><li>HTTP是无状态的<ul><li>请求互相独立， 类似事务</li><li>编程，本地储存，cookie，session是用来提高用户体验的</li></ul></li><li>HTTPS 并不是新协议，而是让 <strong>HTTP 先和 SSL（Secure Sockets Layer）通信，再由 SSL 和 TCP 通信</strong>，也就是说 HTTPS 使用了隧道进行通信。<ul><li>SSL使用RSA算法 public key加密 private key解密</li></ul></li><li>API<ul><li>Get 从服务器获取数据</li><li>Post 提交数据给服务器</li><li>Head 获取报文头部</li><li>Put/Delete 上传文件/删除文件 不安全没有验证机制</li><li>Patch 部分修改资源</li></ul></li><li>状态码<ul><li>200 OK</li><li>3XX 重定向</li><li>4XX 客户端错误 如 404 NOT FOUND</li><li>5XX 服务端错误</li></ul></li></ul><div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/HTTP_RequestMessageExample.png" width=""> </div><br><div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/HTTP_ResponseMessageExample.png" width=""> </div><br><table><thead><tr><th>HTTP1.0</th><th>http1.1</th><th>http2.0</th></tr></thead><tbody><tr><td>默认短连接: 一次TCP连接进行一次HTTP通信. 如需使用长连接，使用 <code>Connection : Keep-Alive</code></td><td>默认长连接persistent connection: 建立一次 TCP 连接就能进行多次 HTTP 通信. 断开连接需要client/server使用 <code>Connection : close</code></td><td>Header压缩</td></tr><tr><td>请求发出后需要等待响应才能发下一个请求</td><td>引入流水线: 同一条长连接上不等待响应连续发出请求, 减少延迟</td><td>解决了流水线情况下HOL blocking 类似饥饿现象</td></tr><tr><td>N/A</td><td>引入cookie保存状态信息</td><td>N/A</td></tr></tbody></table><h3 id="get-post比较"><a class="markdownIt-Anchor" href="#get-post比较"></a> Get Post比较</h3><ul><li>get将请求信息放url里 post放报文体中</li><li>get符合<strong>幂等性</strong>和<strong>安全性</strong>(只读) post不符合(因为是修改操作)</li><li>get<strong>可被缓存 绝大多数get请求都被cdn缓存 减少web服务器压力</strong> 可被储存到浏览器记录和书签中 而post不行</li></ul><h3 id="cookie-session"><a class="markdownIt-Anchor" href="#cookie-session"></a> cookie session</h3><ul><li>cookie: 存在于client边的保存用户状态信息的文本文件，由浏览器储存到client本地。 方便未来向服务器查询用户信息使用。渐渐被淘汰，现在新的浏览器直接支持将数据储存在client本地。存在浏览器中不加密会不安全。但可以减少服务器负担。<ul><li>http request - http response &amp; set-cookie</li><li>http request &amp; cookie - http response</li></ul></li><li>session：存在于server边，用于维护用户登录状态，关闭浏览器 一定时间后会失效<ul><li>由cookie实现<ul><li>server分配给每个session唯一的jsessionID server从redis缓存中验证用户信息密码 key=session id</li><li>返回http response set-cookie包含session id client收到后将cookie值存入浏览器 之后对sever的请求会包含该cookie值 = session id</li></ul></li></ul></li></ul><h3 id="web页面请求过程"><a class="markdownIt-Anchor" href="#web页面请求过程"></a> Web页面请求过程</h3><ul><li>DHCP配置基本信息(假设主机最开始没有 IP 地址及其它信息)<ul><li>DHCP udp broadcast - DHCP server offer - select IP - ack(assigned ip, dns server ip, 网关ip, 子网掩码)</li><li>因为我们广播过了 ethernet learning switch knows host’s &lt;MAC, link&gt;</li><li>DHCP ack到达主机，主机得到ip地址 DNS服务器地址 网关IP 子网掩码 完成配置</li></ul></li><li>需要知道域名IP地址, 先看DNS缓存(browser-os-router-isp), 如果缓存没有, DNS根服务器查询IP 迭代或递归的 从顶级域名到次级域名</li><li>得知ip地址，主机通过浏览器和服务器三次握手生成一个 TCP socket，向服务器发送HTTP GET</li><li>层层路由  (通过IP获取设备MAC-ARP broadcast &amp; responds) 路由取决于要不要跨网 涉及不同协议</li><li>到达服务器，服务器从socket读取 HTTP GET 报文，回复 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。</li><li>浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。</li></ul><h3 id="缓存"><a class="markdownIt-Anchor" href="#缓存"></a> 缓存</h3><ul><li>使用代理服务器或client浏览器进行缓存</li><li>http 1.1 使用cache-control字段控制缓存  no-store no-cache(使用缓存先验证有效性) private public<ul><li>max-age: 可在server缓存最大时间  expires 过期时间</li></ul></li><li>验证缓存是否有效：If-none-match: + etag: 资源的唯一标识   备用方案：last modified</li></ul><h1 id="os"><a class="markdownIt-Anchor" href="#os"></a> OS</h1><h2 id="进程线程"><a class="markdownIt-Anchor" href="#进程线程"></a> 进程线程</h2><ol><li>进程是资源分配的基本单位：正在执行中的指令和上下文。实体：pcb</li><li>上下文：pcb里的内容 对应着 用户堆栈 内核堆栈 代码段 寄存器</li><li>进程切换=<strong>上下文切换成本高</strong> <strong>IPC通信成本高且困难</strong> 故引入线程</li><li>线程同进程内一个执行单元/可调度实体 共享同进程资源：代码段，堆，pid, open fds, 当前目录, 用户和用户组id</li><li>线程独立内容：tid, 寄存器(pc, ip, esp)，本地栈</li><li>用户内核线程管理取决于内核支不支持内核级线程：多对1，1对1</li><li>并行parallelism强调多核和硬件支持是并发的子集: 并发concurrency仅表示<strong>多线程/多进程交替执行</strong>，不要求同时，也不限定cpu数量  =  <strong>同时处理</strong>多任务 <strong>vs</strong> <strong>轮流处理</strong>多任务</li><li>fork COW<ul><li>实现：把页表里某些<strong>页标记为</strong><br><strong>只读</strong>，count references 只有当write实际发生才分配新页进行拷贝<br>其他例子：内存的获取：弄一页对应全0的物理内存共享给所有malloc但还没写的引用，使得系统有更多可用虚拟内存</li></ul></li></ol><h2 id="6种ipc方式"><a class="markdownIt-Anchor" href="#6种ipc方式"></a> 6种IPC方式</h2><p><strong>Pipe</strong> ⾮非命名管道，⽣命周期属于对应的⽗⼦进程</p><p><strong>Named Pipe</strong> 命名管道(FIFO)不同于无名管道之处在于它提供了一个路径名,与之关联， 以 FIFO 的⽂件形式存在于文件系统中，这样，即使与 FIFO 的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过 FIFO 相互通信，因此，通过 FIFO 不不相关的进程也能交换数据。 常用于客户**-**服务器应用程序中，FIFO ⽤作汇聚点，在客户进程和服务器进程之间传递数据。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int mkfifo(const char *path, mode_t mode);</span><br><span class="line">int mkfifoat(int fd, const char *path, mode_t mode);</span><br></pre></td></tr></table></figure><p><strong>Message queue</strong> 消息队列列，主要是提供⼀一种<strong>异步</strong>通信方式，消息被保存到队列里，接受者有需要就取回 有很多开源的实现:<strong>Apache activeMQ rocketMQ</strong> 但是异步的缺点是 接受者要进行<strong>polling</strong> 轮询操作才能接受到最近消息。 优点:⽐信号传递更多信息， ⽐管道 可以提供有格式的消息 不需要同步。<br><strong>Semaphore</strong><br><strong>Shared Memory</strong> 实现困难 要os层面支持 而且要同步不同进程对内存的访问<br><strong>Socket</strong> 不同机器</p><h2 id="调度"><a class="markdownIt-Anchor" href="#调度"></a> 调度</h2><ul><li>合作机制：中断interrupt<ul><li>硬件设备中断：异步的到来 但会被同步 timer / io设备等</li><li>软件中断：同步的 系统调用或异常(trap实现)。均有handler处理</li></ul></li><li>cpu虚拟化：公平，高效，安全的分配计算资源</li><li>安全机制：用户内核双态转换 通过系统调用作为interface 涉及cpu上下文切换<ul><li>系统调用由trap机制实现 通过索引syscall table呼叫对应trap</li></ul></li><li>调度: 在io的时候充分利用cpu    快速响应=RR=高周转时间 tradeoff 可调度进程在ready queue里<ul><li>批处理：需求-高吞吐量/短周转时间<ul><li>FCFS 非抢占 护送效应“短等长”</li><li>SJF 非抢占 长作业饥饿</li><li>SCTF 抢占 贪婪 较优</li></ul></li><li>交互式系统：快速响应<ul><li>RR 抢占 低响应时间 高周转时间 时间片太小 上下文切换开销大 太大 不能保证实时性</li><li>MLFQ 可抢占 同时保证吞吐量和响应性 多级队列 高级有先同级RR 用完demote 周期性boost防饥饿</li></ul></li><li>实时系统： 一个确定时间段内响应<ul><li>多用抢占式保证及时响应</li></ul></li></ul></li></ul><h2 id="并发控制"><a class="markdownIt-Anchor" href="#并发控制"></a> 并发控制</h2><ul><li><p>cpu pipeline有效提高性能 但有pipeline hazards问题:</p><ul><li>数据依赖hazards | 分支hazards</li></ul></li><li><p>解决方式：cpu指令重排序/乱序执行 | 分支预测</p></li><li><p>缓存不一致：多核cpu上多级缓存不同步</p></li><li><p>内存可见性/一致性问题：缓存内容未同步至主存  cpu编译器指令重排 <strong>内存乱序访问</strong></p></li><li><p>内存屏障: <strong>编译时防止指令重排 运行时保证内存可见性</strong></p></li><li><p>锁实现</p><ul><li>软件：困难 peterson算法 <strong>过时</strong> 现代处理器会乱序执行</li><li>硬件:<ul><li>原子操作：<ul><li>TestAndSet xchgl 更新并返回旧值供外层循环检测</li><li>CompareAndSwap CAS 满足期望值则更新。返回旧值供外层循环检测 cmpxchgl</li><li>FetchAndAdd xaddl 加上1个数 返回旧值共外层循环检测</li></ul></li><li>内存屏障</li></ul></li></ul></li><li><p>锁类型：<strong>公平=无饥饿</strong></p><ul><li>自旋忙等待：需搭配抢占式调度 适合多核短持锁时间 <strong>饥饿</strong></li><li>yield自旋：自旋很短时间然后yield 减少了响应时间 <strong>饥饿</strong></li><li>排号自旋锁: 使用faa，新来拿号，不到回合自旋，<strong>fifo公平 饥饿</strong> | 改进：排号yield</li><li>队列锁: os支持 饥饿者扔到waiting queue挂起 锁可用再放回ready queue <strong>公平</strong></li><li>混合锁: 定时自旋+队列 linux futex  <strong>公平</strong></li></ul></li></ul><h3 id="条件变量管程信号量协程"><a class="markdownIt-Anchor" href="#条件变量管程信号量协程"></a> 条件变量，管程，信号量，协程</h3><ul><li><p>cv: 条件等待队列</p><ul><li>wait(mutex,cv) 放锁挂起caller，醒后拿锁返回</li><li>signal(cv) 唤醒一个挂起的线程</li></ul></li><li><p>sv：用于检测状态变化 从而进行wait/signal</p></li><li><p>monitor: mutex + cv + sv 任何时刻只有1个线程进入管程 属于高级同步原语</p><ul><li>mesa: 唤醒和线程恢复执行非原子 sv可变 需while检测</li><li>hoare: 原子唤醒+恢复执行 sv不变 if检测即可</li><li>java在语言层级上支持通过管程机制同步 同步方式有两种：<strong>互斥lock sychronized 合作cv Object.wait( ) Object.notify( )</strong>  <strong>每个java对象都有一个锁和cv</strong></li><li>2 cvs [empty + fill] + 1 mutex 解决pc问题<ul><li>p wait(empty, mutex) put(i) signal(fill)</li><li>c wait(fill, mutex) get() signal(empty)</li></ul></li></ul></li><li><p>semaphore: 初始非负的同步计数器 power(sem) = power(cv + lock)</p><ul><li>–wait: sem-- &lt;0挂起 &gt;=0通过</li><li><ins>signal: sem</ins> 唤醒一个挂起的线程</li><li>0=占用 正=最多几个线程同时访问 负=等待中线程数量</li><li>sem(1) = mutex, sem(0) = cv, sem(可用资源量) = 共享资源访问控制</li><li>3 sem 解决pc问题</li></ul></li><li><p>2 sem read lock + write lock + reader_counter 实现读写锁<br>- 读锁：拿起rl, [若reader_counter=0,拿起wl], 放下rl  同理释放<br>- 写锁：拿起wl，同理释放</p></li><li><p>协程：用户态特殊函数 可挂起恢复 threadlocal不需要同步 多协程-串行执行</p></li></ul><h3 id="死锁"><a class="markdownIt-Anchor" href="#死锁"></a> 死锁</h3><ul><li>哲学家就餐：不可同时拿左手叉子 会造成环形等待 只让<strong>最后一个哲学家先拿右手叉子</strong>即可破解环形等待 | 原子化吃饭</li><li>条件与预防 | os调度预防：银行家算法<ul><li>互斥: 获得资源的独占控制            |  预防：不使用锁</li><li>占有且等待： 拿着这个还等别的  | 预防：2 phase locking或大粒度锁</li><li>不可抢占 | 预防： 得不到锁就释放资源</li><li>环形等待 | 预防：决定好锁获得顺序</li></ul></li><li>解决：<ul><li>鸵鸟策略</li><li>检测 | 恢复：抢占，回滚，kill，重启系统<ul><li>单个资源：资源waits-for图环判断(拓拓扑排序/dfs)</li><li>多个资源：超时检测 标记清除[满足所有可满足+释放资源 长时间不可满足=死锁]</li></ul></li></ul></li></ul><h2 id="内存管理虚拟化"><a class="markdownIt-Anchor" href="#内存管理虚拟化"></a> 内存管理虚拟化</h2><ul><li><p><strong>动态加载</strong>: 调⽤时加载 lazy loading | <strong>动态链接</strong>: 函数执行时lazy定位和链接</p></li><li><p>静态重定位: 进程装⼊入内存前一次性完成逻辑/物理地址的变换 固定的不可变不安全</p></li><li><p>动态重定位：内存虚拟化 访问内存前转换</p></li><li><p><strong>内部碎片</strong>： 分配单元内部的浪费 如padding | <strong>外部碎片</strong>：对于os的无法被分配的小内存洞</p></li><li><p><strong>虚拟化内存</strong>：物理内存通过<strong>分页分段 + on-demand paging</strong>映射为更大逻辑内存</p></li><li><p>页表：映射关系 + 元信息</p></li><li><p>分页：逻辑和物理空间分为固定大小页 4KB=blocksize of disk</p><ul><li>消除物理内存外部碎片，造成逻辑内存空间连续的假象</li><li>按需置换提供更多可用虚拟内存</li></ul></li><li><p>分段：地址空间分段code, stack,heap 每个段分配一些固定大小页，每段都有对应页表</p><ul><li>模块化方便共享保护</li></ul></li><li><p>分页分表合用好处：段自由生长，模块化方便共享保护，稀疏地址空间有效减少页表大小</p></li><li><p>TLB: cpu上缓存 mmu组件 含最近访问页表项翻译内容 减少内存访问</p></li><li><p>MMU: cpu上负责逻辑物理地址转换的部分 table walk unit + 多个tlb</p></li><li><p>页置换策略：按需加载：代价page fault 提前加载：只适用于sequential workload 可与用户暗示结合advise</p><ul><li>OPT: 未来最⻓长时间不不⽤用的 理论最优不实际</li><li>FIFO: 进入内存最久的 可能把最常用的踢掉</li><li>LRU: 若workload合适 近似opt 但实现困难 要维护一个所有页面链表</li><li>Clock: LRU近似 遍历环形buffer ref_bit=0停 清除经过的1</li></ul></li></ul><h2 id="文件系统和linux"><a class="markdownIt-Anchor" href="#文件系统和linux"></a> 文件系统和Linux</h2><ul><li><p>硬连接/实体链接: <strong>两路径同inode号</strong> 不可链接⽬录/跨文件系统 ln file hardlink</p></li><li><p>软连接/符号链接: <strong>data block指向路径</strong> ln <strong>-s</strong> file softlink</p></li><li><p>fd_table - file table(各种访问模式read/write/r&amp;w) - inode table  | <strong>stdin out err 0 1 2</strong></p></li><li><p>sigchld: 供父进程用wait/waitpid等子进程的信号</p></li><li><p>孤儿进程：父进程先退出 子进程仍在运行</p></li><li><p>僵尸进程：⼦进程先退出 子进程资源未释放。处理：kill⽗进程使之成为孤⼉ init会回收资源。</p></li><li><p><img src="https://s2.ax1x.com/2020/03/07/3jNHbV.png" alt="3jNHbV.png"></p></li></ul><h1 id="数据库架构"><a class="markdownIt-Anchor" href="#数据库架构"></a> 数据库架构</h1><ul><li>储存管理storage manager： 将数据库文件以数据库pages形式表示 管理pages读写 pages内可用空间使用 数据库的一页通常和os虚拟内存中的页或硬件的页不同 大小取决于数据库设置<ul><li>文件的表示形式：heapfile sortedfile 说的是pages内记录有序或无序</li><li>pages的管理：链表 或 page directory（一个包含所有pages元信息的特殊page）</li><li>不同数据类型的表示 固定长度的整数浮点数 不定长度的VARCHAR TEXT BLOB。 数据库系统元信息表</li><li>储存模型：row-store适合OLTP workloads, column-store适合OLAP workloads</li></ul></li><li>缓存管理 buffer manager  管理数据库缓存池(磁盘中读来的数据库页)<ul><li>实现：使用哈希表维护当前内存中的页  每个页被修改了就要标记为脏, 此外还有pin counter计数正在使用他的线程数量  正在使用中的页不可以被淘汰</li><li>策略：<strong>LRU-k</strong> 普通的LRU和clock会存在sequential flooding问题：顺序扫描冲掉缓存中所有内容</li><li>优化：顺序读取情况下根据query plan预读</li></ul></li><li>解析引擎SQL parser：创建语法树 制定logical query plan  &amp; physical query plan(如各种join算法block nested join, hash join)</li><li>优化器衡量不同plan的优劣: cost-based search, 抽样统计, 大的策略是尽量走索引。</li><li>执行引擎: 按照query plan从上到下执行</li><li>锁管理： HashMap&lt;obj_name, &lt;granted_set_txns, lock_mode, wait_queue&gt; + lock upgrade等多粒度锁控制</li><li>日志管理：UNDO log: 未完成/aborted事务  REDO log：<ul><li>失败-事务失败 系统失败</li><li>策略：<ul><li>shadow paging(COW)</li><li>Write-Ahead Logging 每个log entry:&lt;txn_id, obj_id, before_val, after_val&gt;<ul><li>周期性设置检查点将内存中内容flush到disk 作为redo undo操作新起点</li><li>physical logging 记录在数据库页的位置  logical logging 记录高层的操作如insert delete update和元数据</li></ul></li></ul></li></ul></li><li>容灾机制 ARIES: analyze WAL records + redo starting from a check point + undo uncommitted txns</li><li>索引管理</li><li>权限管理</li></ul><h2 id="workloads-oltp-olap"><a class="markdownIt-Anchor" href="#workloads-oltp-olap"></a> Workloads: OLTP OLAP</h2><ul><li>OLTP online transaction processing （最常见）例如亚马逊购物车界面  只以事务方式<strong>简单查询</strong>语句访问/更新数据库的一 <strong>小范围数据  较少读 较多写 简单查询</strong></li><li>OLAP analytical 已经通过oltp取得了数据 通过复杂查询语句在大范围内 进行数据分析 通常不涉及更新数据 kept query by oltp通常以只读方式提供        <strong>大范围数据 较多读 较少写 复杂查询</strong></li><li>HTAP hybrid transaction analytical  中间位置， 混合workload</li><li>oltp at frontend =&gt;  extract&amp;transform&amp;load =&gt;  olap at back end with datawarehouse</li><li>htap db: oltp and olap at same side complicated not easy to build</li></ul><h1 id="关系数据库设计理论"><a class="markdownIt-Anchor" href="#关系数据库设计理论"></a> 关系数据库设计理论</h1><h2 id="函数依赖异常范式"><a class="markdownIt-Anchor" href="#函数依赖异常范式"></a> 函数依赖,异常,范式</h2><ul><li><p>X函数依赖于Y 意味着Y独特的决定X Y是当前表的候选键</p></li><li><p>X完全函数依赖于Y意味着X不函数依赖于Y的任何子集</p></li><li><p>X部分函数依赖Y = Y的一部分可以决定X Y作为键存在冗余</p></li><li><p>X-&gt;Z，Z-&gt;Y，X-&gt;Y是传递函数依赖</p></li></ul><p>不符合范式的关系，会产生很多异常，范式可以解决异常：</p><ul><li>冗余数据栏目：例如某个信息在不同行出现了多次 该schema设计有问题</li><li>insert异常：因为冗余信息的存在 我们想插入一条记录 就要包括/编造这些无关冗余信息 这往往不现实</li><li>delete异常：删除一个含冗余信息的行，导致丢失同行其他关键信息。</li><li>update异常：只改了一条记录中的信息，其他记录中相同的信息忘了改。</li></ul><p>通过无损分解消除没必要的函数依赖 产生更合理的schema 高级别范式依赖于低级别范式</p><ul><li>1NF：原子属性不可分。</li><li>2NF：1NF+消除部分函数依赖 （每个非主属性完全函数依赖于主键）</li><li>3NF：2NF +消除传递函数依赖（非主属性不存在“<strong>传递函数依赖</strong>”）</li></ul><h1 id="数据库并发控制"><a class="markdownIt-Anchor" href="#数据库并发控制"></a> 数据库并发控制</h1><h2 id="事务管理中的acid原则"><a class="markdownIt-Anchor" href="#事务管理中的acid原则"></a> 事务管理中的ACID原则</h2><ul><li>Atomicity 原子性 “all or none”: 事务所做操作要么全部提交要么全部失败回滚<ul><li>实现： 日志undo log,   Shadow paging(COW)</li></ul></li><li>Consistency 一致性 “looks correct”<ul><li>数据库一致性 仍遵循完整性约束 未来事务能看到过去事务造成的后果</li><li>事务一致性  事务前后数据库内容一致 一致意味着多个事务访问相同数据得到相同结果</li></ul></li><li>Isolation 隔离性 “lives alone”: 事务所作修改commit前对其他事务不可见<ul><li>两种类别的并发控制协议来保证隔离性</li><li>悲观  从最初就避免问题的发生</li><li>乐观  设定某种事务执行顺序，假设冲突发生不常见，发生后再处理 lazy</li></ul></li><li>Durability 持久性 “survives failure”: 事务提交的修改应被持久化，即便系统崩溃也不受影响 redo log</li></ul><p>串行情况下 原子性=&gt;一致性   并行情况下  原子性+一致性=&gt;一致性</p><h2 id="一致性冲突"><a class="markdownIt-Anchor" href="#一致性冲突"></a> 一致性冲突</h2><ul><li>读写冲突：<ul><li>不可重复读 “non-repeatable read”   两个读的中间数据被另一个事务<strong>覆写并提交</strong> 导致第二次读的<strong>同一行值</strong>不同<ul><li>transaction reads committed <strong>UPDATES</strong> from another transaction. The same row now has different values than it did when your transaction began.</li><li>A non-repeatable read occurs, when during the course of a transaction, a row is retrieved twice and the <strong>values within the row differ</strong> between reads.</li></ul></li><li>幻读 “phantom read” 两个读的中间<strong>被另一个事务插入/删除行并提交</strong> 导致第二次读<strong>返回的行不同</strong><ul><li>Phantom reads are similar but when reading from committed <strong>INSERTS</strong> and/or <strong>DELETES</strong> from another transaction. There are new rows or rows that have disappeared since you began the transaction.</li><li>A phantom read occurs when, in the course of a transaction, two identical queries are executed, and the <strong>collection of rows</strong> returned by the second query is different from the first.</li></ul></li><li><strong>避免不可重复读锁行就足够，避免幻读需要锁表</strong></li></ul></li><li>写读冲突： 脏读 “dirty reads” Reading uncommitted data 读了另一个事务没有提交的数据</li><li>写写冲突：丢失修改 “lost updates” overwriting uncommitted data 一个事务覆盖另一个事务没有提交的数据</li></ul><h2 id="隔离级别"><a class="markdownIt-Anchor" href="#隔离级别"></a> 隔离级别</h2><p><img src="https://s2.ax1x.com/2020/02/02/1J7MlR.png" alt="isl"></p><ul><li>RU: 事务中的修改，即使没有提交，对其它事务也是可见的。</li><li>RC: 一个事务只能读取已经提交的事务所做的修改。</li><li>RR: 保证在同一个事务中多次读取同一数据的结果是一样的。</li><li>S: 强制事务串行执行，这样多个事务互不干扰，不会出现并发一致性问题。从MVCC并发控制退化为基于锁的并发控制。不区别快照读和当前读，所有的读操作都是当前读，读加读锁（S锁），写加写锁（X锁）。在该隔离级别下，读写冲突，因此并发性能急剧下降，在MySQL/InnoDB中不建议使用。</li><li>冲突可串行：一个调度是冲突可串行的意味着可以将其转换为串行调度<ul><li>依赖关系图一定无环</li><li>这就是SERIALIZABLE隔离级别：将事务完全调度为串行执行</li></ul></li></ul><h2 id="悲观并发控制"><a class="markdownIt-Anchor" href="#悲观并发控制"></a> 悲观并发控制</h2><h3 id="二段锁"><a class="markdownIt-Anchor" href="#二段锁"></a> 二段锁</h3><ul><li><p><strong>Pessmistic 悲观的</strong> 假设事物存在高度竞争 使用锁 因此安全程度高 但并发能力会有所限制 (not allow all serializable schedules)</p></li><li><p>写锁互斥 X 读锁共享</p></li><li><p>2PL 总是保证冲突可串行调度 <strong>always</strong> gurantee conflicts-serializable schedule = grantee serializable schedule</p></li><li><p>二个阶段      “/\”</p><ul><li>生长期 只允许拿锁</li><li>收缩期 一旦释放第一个锁 进入收缩期<ul><li>只允许放锁 或不放锁</li><li><strong>不允许拿锁</strong></li></ul></li></ul></li><li><p>问题: 脏读情况下<strong>cascading abort</strong>例如t1写 t2读 此时t1还没commit便abort 此时t2不得不abort…如果t2也写了还没来的及提交后面还有读的那这个反应会连锁下去</p><ul><li>解决: Strong Strict 2PL  (SS2PL) 一个事务提交/abort后才允许放锁 一次放完</li></ul></li><li><p>死锁处理:</p><ul><li>检测:<ul><li>后台周期性在waits-for graph中判环 / 超时检测</li><li>选择一个victim回滚打破环，选择标准和rollback程度取决于具体设计</li></ul></li><li>预防:<ul><li>通过时间戳赋予优先度 FCFS</li><li>一个人得到锁后其他所有人进入等待队列 直接严格避免死锁发生</li></ul></li></ul></li></ul><h3 id="锁粒度和层次"><a class="markdownIt-Anchor" href="#锁粒度和层次"></a> 锁粒度和层次</h3><p>MySQL 中提供了两种封锁粒度：行级锁以及表级锁。<br>应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。<br>但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。<br>在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。</p><ul><li>一个事务想要更新1billion tuples = ask for locks 1 billion times  VERY SLOW</li><li>我们需要锁的层次来展现 行级表级处分别发生了什么</li></ul><h4 id="如何更方便的进行多粒度封锁-意向锁"><a class="markdownIt-Anchor" href="#如何更方便的进行多粒度封锁-意向锁"></a> 如何更方便的进行多粒度封锁： 意向锁</h4><ul><li><p>意向锁Intention lock: 表示想要对表加锁，与&quot;锁提升机制&quot;结合，细粒度锁太多时动态的分配可用的粗粒度锁  大大减少lock manager需要处理的锁的请求数量</p></li><li><p>意向锁在高层如表级告诉我们下面有什么样的锁 通过兼容矩阵 可以从hierarchy高处快速判断能不能读/写下层具体行的数据</p></li><li><p>Intention-Shared (IS):下面某个地方有读锁</p><ul><li>Intention-Exclusive (IX):下面某个地方有写锁</li></ul></li><li><p>Shared+Intention-Exclusive (SIX):  整个子树可共享读，下面某个孩子有写锁</p></li><li><p>表级锁兼容矩阵：<br>|      | <code>X</code>  | <code>IX</code>   | <code>S</code>  | <code>IS</code>   |<br>| ---- | ---- | ------ | ---- | ------ |<br>| <code>X</code>  |      |        |      |        |<br>| <code>IX</code> |      | <strong>OK</strong> |      | <strong>OK</strong> |<br>| <code>S</code>  |      |        | OK   | OK     |<br>| <code>IS</code> |      | <strong>OK</strong> | OK   | <strong>OK</strong> |</p></li><li><p>表和表：任意 IS/IX 锁兼容:  != 真正加锁 | S 和 IS 兼容</p></li><li><p>表和行：表级 IX 和行级 X 兼容：两个事务先对同表加IX锁，然后可以对同表两个不同数据行加 X 锁</p></li></ul><h3 id="mysql事务四级封锁-强2pl读写锁"><a class="markdownIt-Anchor" href="#mysql事务四级封锁-强2pl读写锁"></a> Mysql事务四级封锁: 强2PL+读写锁</h3><p>Mysql InnoDB引擎采用强2PL，根据当前隔离级别自动加锁=<strong>隐式锁定</strong></p><ul><li><strong>一级</strong>  修改加写锁，事务结束放写锁  = Read Uncommited级别</li><li>防止<strong>写写冲突</strong>问题Lost updates</li><li><strong>二级</strong>  一级 + 读加读锁，读完放读锁 = Read Commited级别</li><li>防止<strong>脏读</strong>问题Dirty Reads</li><li><strong>三级</strong>  二级 + 读加读锁，事务结束放读锁 = Repeatable Reads级别</li><li>防止<strong>不可重复读</strong>问题unrepeatable reads</li><li><strong>四级</strong> 全表锁，事务结束放锁 = Serializable级别</li></ul><p><strong>显式锁定</strong>：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">获取读锁： <span class="keyword">SELECT</span> ... <span class="keyword">LOCK</span> <span class="keyword">In</span> <span class="keyword">SHARE</span> <span class="keyword">MODE</span>; </span><br><span class="line">获取写锁： <span class="keyword">SELECT</span> ... <span class="keyword">FOR</span> <span class="keyword">UPDATE</span>;</span><br></pre></td></tr></table></figure><h2 id="乐观并发控制"><a class="markdownIt-Anchor" href="#乐观并发控制"></a> 乐观并发控制</h2><ul><li>不使用锁：对common case的一种优化, 大部分情况下事务只需持续很短时间，冲突没有那么容易发生。所以我们可以使用比较懒的策略，假设冲突不会发生，检测到发生再进行补救 如选择abort</li></ul><p>根据ACID原则 并发情况下实现一致性需要原子性和隔离性, 原子性通过CAS等原子操作解决, 隔离性通过时间戳机制赋予事务执行顺序</p><p>目前有三种主流乐观并发控制策略</p><ul><li>基于时间戳的 事务用时间戳编号排序 最早OCC论文内容<ul><li>读写阶段：将更改存在私有空间</li><li>验证阶段：验证是否和其他事务冲突再提交</li><li>写阶段：验证成功 将私有空间更改同步至主空间  否则abort</li></ul></li><li>snapshot isolation: 朴素mvcc</li><li>CAS: 不仅是一种策略 也是一种实现<ul><li>满足期望值(没有被占用)则更新。返回旧值供外层循环检测</li><li>外层while CAS(flag, 0, 1) == 1: Old value is 1, lock held by someone else, spin and wait. Otherwise go ahead do modification</li><li>硬件支持：x86架构下指令为cmpxchgl</li></ul></li></ul><h2 id="mvcc多版本并发控制"><a class="markdownIt-Anchor" href="#mvcc多版本并发控制"></a> MVCC多版本并发控制</h2><ul><li><p>当前最常见的数据库并发控制方法. 非常适合读多写少的OLTP workload 朴素MVCC<strong>解决了在REPEATABLE READ和READ COMMITTED两个隔离级别下读同一行和写同一行的两个事务的并发问题。</strong></p></li><li><p>朴素的MVCC在数据库领域可以说是乐观的 是不用锁的 单纯使用快照方式实现读写分离 类似COW</p></li></ul><p>mysql默认隔离级别为RR， InnoDB的mvcc是mvcc的改进版 引入(next-key lock]解决了朴素mvcc的幻读问题 能够实现RC RR S三个隔离级别</p><ul><li><p>即便是改进版MVCC也只是处理读写或写读的冲突属于整个四种Isolation level处理的问题。写写冲突 lost updates 一般通过first commiter/first updater win 解决</p></li><li><p>读=不加锁的非阻塞读 读旧版本快照   |     写(插入删除更新)=加锁更新一个最新的版本快照</p></li><li><p>系统版本号SYS_ID：通过时间戳机制单调递增分配</p></li><li><p>事务版本号TRX_ID：事务开始时的系统版本号</p></li><li><p>每个事务都有这两个版本号并被记录在undo日志中</p></li><li><p>RC RR隔离级别下使用版本链 多个版本的快照存在undo日志中，日志通过回滚指针把一个数据行的所有快照连起来</p></li><li><p>MVCC 维护一个read view结构 当前未提交事务列表trx_min_id…trx_max_id  一个数据行快照的trx_ID &lt;min则可用 &gt;max则不可用 位于中间取决于当前隔离级别  若该快照不可用则要沿undo日志中版本链找前一个可用快照</p></li><li><p>快照读select…不需要锁，当前读（数据修改insert/update/delete）操作需要锁</p></li><li><p>innodb为了解决rr级别下当前读(数据修改)的幻读问题，使用了next-key lock</p><ul><li>本质上是gap lock+ record lock</li><li>record lock锁定记录上的索引相当于一个单点锁 (使用unique index访问的情况)</li><li>gap lock锁定record lock单点之前的开区间(使用non-unique index / no index访问的情况)</li><li><code>(10, 15]</code> 每一个next-key lock锁定一个左开右闭区间</li></ul></li></ul><h1 id="索引和储存"><a class="markdownIt-Anchor" href="#索引和储存"></a> 索引和储存</h1><h2 id="bbhashbit-map"><a class="markdownIt-Anchor" href="#bbhashbit-map"></a> B,B+,Hash,Bit Map</h2><ul><li><p>哈希索引高效等值查询 位图索引适合静态low cardinality数据</p></li><li><p>B树平衡多路查找树 m度=m指针 m-1个键值(实际数据记录)  叶子层并非包括全部数据记录 节点半满压缩高度 节点内有序 叶子结点位于同层</p></li><li><p>b+树 叶子层(节点内外均有序)fixed-size数组的链表保存全部数据记录+非叶子层有序索引只存搜索键值 (储存指针多一个)</p></li><li><p>b+树与b树区别：</p><ul><li>b+叶子层有序fixed-size数组链表同时支持高效等值查询和范围查询 （节点内有序可以2分搜索）和bulk-loading (每个固定gap选最小值作为搜索键值 从下到上建树)</li><li>单叶子储存节点更多 高度压缩更明显 IO次数更少</li><li>所有查询都要找到叶子结点 查询性能更稳定</li></ul></li><li><p>为什么适合储存：非平衡树可以直接排除-skew情况下退化为链表 红黑只有2叉不适合高度太高io次数太多文件系统 b+结合b树优点节点半满多路平衡查找树 高度低IO次数少 同时叶子层支持外排序后bulk-loading 更适合文件系统和数据储存 更好利用磁盘预读性质</p></li></ul><h2 id="索引"><a class="markdownIt-Anchor" href="#索引"></a> 索引</h2><p><strong>为什么要使用索引？避免全表扫描，使用更好的索引-减少数据访问量</strong></p><ul><li>索引键=索引项 搜索键：我们要查找的栏目名称</li><li><strong>clustered index / primary index / sparse index 主索引</strong>：记录顺序和索引键相同  整个文件要按索引键排序 indexed-sequential file 只能有1个主索引。例子：有序文件/hash表上的索引<ul><li>primary index指用含主键的集合作索引键的索引 一般情况下将primary index和clustered视为相同</li><li>无论索引键是否有重复 可以是dense(trivial)也可以sparse 因为完全有序 可以每个disk block建一个索引指向第一个anchor record即可 找到合适位置后顺序扫描 因此一般默认为<strong>sparse</strong><ul><li>有序= 高效的范围查找 IO次数少</li><li>因为有序 插入删除更新 维护成本高：有空间直接插入 否则维护overflow chain 时间长了性能下降严重 因此多数数据库会定期重新组织记录结构将overflow chain展开 但这也要开销</li></ul></li></ul></li><li><strong>non-clustered index / secondary index 辅助索引</strong>：索引键和记录顺序不同<ul><li><strong>must only be dense !</strong></li><li><strong>索引有序 按辅助索引键排序</strong> 不给记录排序 那是主索引的事！！！</li><li>可能涉及到不同磁盘区块 = 更多io + 寻道时间 更慢</li><li><strong>通常使用间接索引的方式避免重复key问题</strong> 这样最底层索引相同key有序排列 底层之上高层实现稀疏索引</li><li><s>sparse辅助索引没有意义 因为数据记录无序  什么都找不到 最后依赖全表扫描或主索引</s></li><li>例：mysql中当查询列上没有辅助索引 就走主索引</li></ul></li><li>dense index: 索引键出现在每个含搜索键值的记录上,<ul><li>有序情况下支持范围查询 二分查找</li><li>有序情况下非常高效：1 disk IO = load everything into memory until exceed range</li><li><s>无序情况：需要全表扫描 不适用 现在的索引尤其是b+tree都是有序索引</s></li></ul></li><li>sparse index: 索引键出现在部分含搜索键值的记录上  <strong>必须是主索引</strong> 记录要按索引键顺序排序<ul><li>1 key - ptr pair per disk block 1st record = anchor record</li><li>有序情况下 可用二分查找 <strong>MORE space-memory effcient</strong></li></ul></li><li>多列联合索引<ul><li>通常策略：按最左边建立b+树有序索引 索引按优先级左到右字典序排序</li></ul></li></ul><h2 id="mysql索引"><a class="markdownIt-Anchor" href="#mysql索引"></a> Mysql索引</h2><p>InnoDB支持 B+树 哈希 全文索引  MyISAM支持全文索引 空间数据索引</p><ul><li>DDL部分 声明的key会自动创建辅助索引 主键会创建主索引</li><li>联合索引匹配遵循<strong>最左匹配原则</strong> idx1(a,b,c,d)<ul><li>从左向右匹配直到遇到范围查询&lt;,&gt;,between,like e.g. a=3,b=4,c&gt;5,d=2   d会用不到索引</li><li>若查询均为等值查询 = , in 则可以乱序 如查询 a=1, c=3,b=2 (a,b,c) 甚至可以省略前面部分 直接查询c = 3 查询优化器会自动修改</li></ul></li><li>原因：B+树有序索引会建在a上 剩余内容b,c,d在前者基础上依次排序 叶子层记录以有序数组形式存在叶节点内 有序查询找到a后依次向后按序匹配<ul><li>b的有序是基于a的有序 因此等值查询不受影响</li><li>当a为范围查询时,e.g. a&gt;1 的结果是一个多条记录的范围  此时b相对于这个范围是无序的 无法使用索引</li></ul></li><li>索引是建立越多越好吗？<ul><li>数据量小的表不需要索引 增加额外开销</li><li>数据修改要维护索引 = 更多维护成本</li></ul></li></ul><h2 id="mysql引擎"><a class="markdownIt-Anchor" href="#mysql引擎"></a> Mysql引擎</h2><table><thead><tr><th>InnoDB  default</th><th>MyISAM</th><th></th></tr></thead><tbody><tr><td><strong>支持事务</strong>，适合OLTP  <strong>事务处理为主 小范围数据 简单查询 重复性高 增删查改写多于读</strong> 如购物车</td><td><strong>不支持事务</strong>，适合OLAP <strong>数据分析为主  大范围数据 复杂查询 重复性低 读多于写</strong> 如统计计算聚集函数。</td><td></td></tr><tr><td><strong>行锁设计</strong> MVCC+next-key lock提供四个级别安全和高并发性</td><td><strong>表锁设计</strong></td><td></td></tr><tr><td>支持外键</td><td>不支持外键</td><td></td></tr><tr><td>支持clustered index 全表按主键排序</td><td>不支持clustered index 索引文件单独储存：主键/其他方式所建索引的偏移量  数据库文件是无序的heapfile</td><td></td></tr><tr><td>提供了插入缓冲、二次写、自适应哈希索引、预读等高性能和高可用的功能。</td><td>它的缓冲池只缓冲<strong>索引文件</strong>，<strong>不缓冲数据文件</strong>。索引文件单独储存</td><td></td></tr></tbody></table><h2 id="sql调优"><a class="markdownIt-Anchor" href="#sql调优"></a> SQL调优</h2><p>索引调优基本heuristics</p><ul><li>修改sql尽量全走索引（<strong>覆盖索引</strong>）没索引的情况下考虑建合适的辅助索引<ul><li>innoDB辅助索引 不覆盖会 访问主索引</li><li>myisam只缓存索引 不覆盖会 额外读文件-全表扫描-系统调用 page replacement</li></ul></li><li>选择性强的索引放前面，索引全覆盖的情况下尽量将<strong>范围查询移到末尾</strong> <strong>遵循最左匹配原则</strong>的原理 避免查询不走索引</li><li><strong>不要把想走索引的搜索码放表达式里</strong> 如actor_id + 1 = 5; 是错误的 不会走索引</li><li>性能： <strong>1个多列索引&gt;多个单列索引</strong></li><li>较长类型如blob, text, varchar 应使用<strong>前缀索引</strong> 只索引前几个字符</li></ul><p>需要注意的</p><ul><li><p>mysql optimizer会消除没有必要的数据行访问 因此不一定会走主索引或副索引</p></li><li><p>找慢的query show variables找到系统变量long_query_time slow_query_log(默认off)</p><ul><li>long_query_time 超过则加入slow query log, set slow_query_log为on</li></ul></li><li><p>查看query plan, explain query显示栏目</p><ul><li>id=子查询执行顺序 type=找到数据行/join的方式:  all全表扫描 index扫了index树</li><li>extra里面有各种状态比如using index = 索引完全覆盖了查询 using index for group-by部分使用索引等  using file-sort用了外排序（比如order by） using temporary 用了临时表</li></ul></li><li><p>explain xxx force index(primary) / force index(xxx) 尝试使用别的索引</p></li><li><p>加索引 alter table xxx add index idxname(字段名); 或者在ddl里create index xxx</p></li></ul><p>查询优化</p><ul><li>切分大的事务(查询) 避免小的饥饿 或使用多粒度意向锁</li><li>大连接查询切分为 单表查询 + 关联  更好利用已有缓存 提高自身缓存可用性  减少锁竞争</li></ul><h1 id="分布式和系统设计"><a class="markdownIt-Anchor" href="#分布式和系统设计"></a> 分布式和系统设计</h1><h2 id="模型和概论"><a class="markdownIt-Anchor" href="#模型和概论"></a> 模型和概论</h2><ul><li>重要假设: 容错模型 <strong>假设我们可以相信节点(we write them)</strong>（若不相信需要使用拜占庭容错协议 blockchain）</li><li>基本架构<ul><li>shared everything: 单点</li><li>shared memory: <strong>no one does this</strong>, need OS support 多用于HPC超算中心</li><li>shared disk: common for cloud DBMS</li><li>shared nothing: most common. better performance, hard to manage ex. most nosql sys</li><li>同构vs异构：集群内节点可否执行相同任务</li></ul></li><li>两种设计monolith vs microservice 组件耦合程度<ul><li>monolith: 单机负责多种功能<ul><li>适合小团队</li><li>简单： 更少解耦，维护</li><li>快：少/无 RPC</li><li>部署复杂</li><li>单点故障波及范围大</li></ul></li><li>microservice：单机负责单一功能 + 小型分布式缓存数据库 适合大型系统<ul><li>easy to scale (easy for new team member)</li><li>decoupled : easy to reason about</li><li>hard to design: s1 only talks to s2 = they need to be merged</li></ul></li></ul></li><li>两种拓展模型</li></ul><table><thead><tr><th></th><th>水平扩展 更多机器</th><th>垂直拓展 更强机器</th></tr></thead><tbody><tr><td></td><td>需要负载均衡</td><td><strong>N/A</strong></td></tr><tr><td>容错</td><td>可靠</td><td>单点故障</td></tr><tr><td></td><td>RPC</td><td><strong>IPC</strong></td></tr><tr><td></td><td>易数据不一致</td><td><strong>通常一致</strong></td></tr><tr><td></td><td><strong>scales well as users increase</strong></td><td>硬件限制</td></tr></tbody></table><ul><li><p>优化方法</p><ul><li>优化单点能力：vertical scaling</li><li>解决单点故障  horizontal scaling - 备用服务器转换 / replication</li><li>多节点集群负载均衡 减少单点负荷: load balancer responsible</li><li>微服务架构提高可拓展性: 解耦系统组件, 各司其责</li><li>日志和评估系统</li></ul></li><li><p>事件驱动模型:  ex. git, game server csgo headshot</p><ul><li>publisher-subscriber: relies on message queues to pass events<ul><li>Good: decoupled, easy to identify failure ONLY SPOF, easy to add / remove</li><li>Bad: extra level of indirection = slow, <strong>does not gurantee strong consistency</strong>, cost for learning and maintaining message queues</li></ul></li></ul></li></ul><h2 id="原则和协议"><a class="markdownIt-Anchor" href="#原则和协议"></a> 原则和协议</h2><ul><li><p>CAP： 分布式系统不能同时满足一致性 可用性 分区容忍性</p><ul><li>Consistency一致性：保持数据一致和最新 Linearizability</li><li>Availability可用性：系统可用时间占总时间的比值 All up nodes can satisfy all requests</li><li>Partial tolerant分区容忍性：局部网络故障消息丢失时能否继续提供一致性和可用性服务 still operates despite message loss</li><li>分区容忍性一般必不可少 CAP实际上是在一致性和可用性CA间进行权衡<ul><li>不可以cp 因为存在k-safety限制 不得不放弃可用性</li></ul></li></ul></li><li><p>BASE理论 CAP的拓展 CA的协调结果 Basically avaiable, Soft State, Eventually Consistent</p><ul><li>ACID要求强一致性(数据更新后 用户能够读取到最新值) 用于单机传统数据库</li><li>BASE要求最终一致性 中间软状态可以看情况适当妥协 保证始终提供核心基础服务即可</li></ul></li><li><p><strong>分布式死锁检测</strong> 周期性union所有waits-for-graph</p></li><li><p>如何实现共识 agree on commit abort ? quorum (voting)</p></li><li><p>分布式事务协调  原子性提交相关协议2PC, Paxos, Raft, ZAB</p><ul><li>中心化:  global traffic cop as <strong>middleware / coordinator</strong> route query as needed to partitions<ul><li>2PC: 相当于paxos的弱化版<ul><li><p>prepare phase: 协调者询问参与者事务是否准备好提交 参与者投票Y/N 全票=提交</p></li><li><p>commit phase: 协调者决定结果 如果可以就都提交-否则回滚 参与者回复ack</p></li><li><p>可以和 2PL结合</p></li><li><p>问题</p><ul><li><strong>不能解决dead coordinator问题</strong>  paxos 可以解决</li><li>同步过程中阻塞问题 要等待其他参与者响应</li><li>网络问题导致只有部分参与者commit ？</li><li>一个节点失败=失败  容错率低</li></ul></li></ul></li></ul></li><li>去中心化: 节点自行组织产生分布式共识<ul><li>没有协调者</li><li>服务器和master node交流 如果是同构架构 所有节点都可以是master node</li><li>query request发送到master node / partition</li><li>提交时master node和其他节点交流safe to commit？ 投票选择<ul><li>paxos 分布式共识算法 无需全票 多数投票通过即通过 <strong>如果多数存活non-blocking 高容错 解决dead coordinator问题</strong><ul><li>proposer 提议提交 OK? 1个或多个proposer</li><li>acceptor reply  只需多数即可提交  see n+1 reject n</li><li>learner: 被告知投票的结果，不参与投票过程。</li><li><strong>持续处理新来的proposal</strong> 即便之前的已经同意 也当即拒绝之前的proposal和commit请求</li><li><strong>解决饥饿问题</strong>：multi-paxos 选择1个leader, 规定若如果只有一个proposer propose阶段可以跳过 周期性选举当前leader</li></ul></li></ul></li></ul></li></ul></li><li><p>raft 选举主节点</p></li></ul><h2 id="组件和机制"><a class="markdownIt-Anchor" href="#组件和机制"></a> 组件和机制</h2><ul><li><p>异步消息机制： message/task queue</p><ul><li>接受任务后分配给不同服务器，若花时间太长=dead，assign to next server to avoid duplication</li></ul></li><li><p>分布式缓存</p><ul><li>缓存：avoid network calls, repeated computation, db load<ul><li>置换策略不好或缓存太大都会导致缓存无用</li><li>thrashing: constantly input &amp; output withhout using the result = sequential flooding ?</li><li>server-side, client-side : fast but cache consistency?</li><li>全局缓存global cache (redis): 解耦！微服务！<ul><li>consistently accurate but slightly slower</li><li>can scale independently</li></ul></li><li>write through: …on hit, update cache &amp; database  <strong>keep db always consistent but slow</strong></li><li>write back: write to cache, mark dirty(inconsistent). lazily update db when dirty-cache entry is evicted <strong>db can be temporarily inconsistent but fast</strong></li><li>hybrid: 重要的更新write through, 批缓存不重要的更新到cache, 低峰时间一次性同步到db</li></ul></li></ul></li><li><p>分区 usually logical</p><ul><li>垂直切分/naive table partitioning ：如果查询分布不均匀集中到一个点 单点计算能力可能扛不住</li><li>水平切分/round-robin sharding / load balancing ：query fragment分布到集群不同节点上作相同处理最后合并 有效缓解单数据库压力 多采用哈希取模方式划分<ul><li><strong>可拓展 无重复的</strong> 一致性哈希：集群增删一个节点后如何避免rehash&amp;trash our caches？<ul><li>绕环线性探测到下一个节点</li><li>节点少数据倾斜？每台服务器做多个虚拟节点replication 实现相对均匀分布</li><li>哈希函数不好 服务器分布不均not uniformly distributed：<ul><li>完美哈希 使用哈希函数族（嵌套一致性哈希 + multilevel sharding ）</li></ul></li></ul></li></ul></li><li>数据库的分库分表：大连接慢 可与主从复制结合提高分片容错 可与和索引结合 consistency is hard 建议优先使用nosql等其他系统再考虑这种primritive<ul><li>表的垂直切分：一张表按列切分成多个表  分到不同库里</li><li>表的水平切分：同一个表中的记录拆分到多个结构相同的表中 可以分布到集群不同节点上 配合服务器的负载均衡 减少单库压力</li></ul></li></ul></li><li><p>复制 Replication</p><ul><li><p>创建冗余备用节点储存相同信息提高系统可用性</p></li><li><p>k-safety: 最少k可用复制品 #replicas &lt; k DBMS halts go offline</p></li><li><p>主从架构</p></li><li><p>更新集中到master</p></li><li><p>master更新内容到replica</p><ul><li>更新方式<ul><li>同步： 主等待从完成日志并回复ack 保证<strong>强一致性</strong>strong consistency 数据是即时的</li><li>异步：不等待 主直接返回ack给client 保证最终一致性eventual consistency 数据snapshot</li></ul></li><li>更新timing<ul><li>连续的：生成日志=》直接发送</li><li>提交时</li></ul></li><li>从者主动被动？<ul><li>主动：事务在从处自行执行 需要检测不同从的结果匹配</li><li>被动：事务在1处执行后传递给所有replicas</li></ul></li></ul></li><li><p>可允许只读事务访问replica</p><ul><li>可实现读写分离: 主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。从服务器可以分布到离用户较近的地方 降低延迟 提高用户体验</li><li>采用快照隔离能保证弱一致性, 增加冗余提高可用性</li></ul></li><li><p>master故障 选举新master</p></li><li><p>多主人</p><ul><li>replica和主人平级（没有主人=多主人）- 事务可在任何replica处更新 replica们<strong>自行使用原子性提交/分布式共识协议2PC/Paxos互相同步</strong></li></ul></li><li><p>网络故障包丢失 分区paxos选主后 <strong>split-brain</strong>双主如何在网络恢复后同步?</p><ul><li>传统/newsql dbms：多数节点连接完好<strong>才允许更新</strong> 不存在这个问题</li><li>nosql：需要某种形式上的中心化处理<ul><li>乐观：选择可用性，牺牲部分一致性，之后在合适的时间自动或人为处理 hazelcast</li><li>悲观：选择一致性，牺牲部分可用性，投票下线存在问题的网络分区 mongoDB</li></ul></li></ul></li></ul></li><li><p>总结：分区和复制通常一起使用：如水平切分的数据库分布到集群不同单点上 并作复制 复制品可以是slave(主从结构)也可以是master (distributed-consensus based).</p></li></ul><h1 id="no-sql-in-memory-db"><a class="markdownIt-Anchor" href="#no-sql-in-memory-db"></a> No-sql &amp; in-memory DB</h1><ul><li><p>NoSQL: not-only relation: <strong>k-v, document(json, csv), graph</strong> cassandra redis mongodb</p><ul><li>优点<ul><li>插入删除涉及所有相关数据 此时使用nosql开销较低</li><li>schema比较灵活 方便更改</li><li>内部支持水平切分 scales well</li><li>built for OLAP</li></ul></li><li>缺点<ul><li>no acid guarantee</li><li>not read optimized  join is hard 涉及大量扫描相关对象</li><li>no relation no constriants</li></ul></li></ul></li><li><p>In-memoryDB: very modern, lack durability support from ACID, store things in volatile meory. e.g. Oracle IMDB</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;网络模型&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#网络模型&quot;&gt;&lt;/a&gt; 网络模型&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;电路交换
&lt;ul&gt;
&lt;li&gt;不灵活 成本高 需要专有物理线路 需要建立专有连接 线路利用率低 没有转发机制&lt;/li&gt;
&lt;
      
    
    </summary>
    
    
      <category term="总结" scheme="http://th2zz.github.io/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>计网总结</title>
    <link href="http://th2zz.github.io/2019/12/02/computer_network/"/>
    <id>http://th2zz.github.io/2019/12/02/computer_network/</id>
    <published>2019-12-02T15:32:49.000Z</published>
    <updated>2020-02-08T16:54:39.768Z</updated>
    
    <content type="html"><![CDATA[<h1 id="包交换-vs-电路交换网络"><a class="markdownIt-Anchor" href="#包交换-vs-电路交换网络"></a> 包交换 vs 电路交换网络</h1><ul><li>电路交换<ul><li>需要建立连接 和 专用物理线路 线路利用率低 没有转发机制</li><li>容易受网络中断影响</li></ul></li><li>包交换<ul><li>更灵活  不需要专用线路 可以线路复用  线路利用率高</li><li>不容易受网络中断影响</li></ul></li></ul><h1 id="时延"><a class="markdownIt-Anchor" href="#时延"></a> 时延</h1><p>E2E总时延 = 排队时延 + 处理时延 + 传输时延 + 传播时延</p><p>P2P总时延 = 传输时延 + 传播时延</p><h1 id="传输过程和基本术语"><a class="markdownIt-Anchor" href="#传输过程和基本术语"></a> 传输过程和基本术语</h1><p><strong>Message “报文” - Segment “报文段” - Datagram / Packet “数据报 / 包” - Frame“帧” - bit</strong></p><p><img src="https://img-blog.csdnimg.cn/20181201104548931.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2EzMTkyMDQ4,size_16,color_FFFFFF,t_70" alt="img"></p><p><a href="https://blog.csdn.net/a3192048/article/details/84671340" target="_blank" rel="noopener">https://blog.csdn.net/a3192048/article/details/84671340</a></p><ul><li><p>Links: 链路 连接节点的物理介质</p></li><li><p>Service / Interface: between layering</p></li><li><p>Protocol: between peer</p></li><li><p>E2E Client to Server  P2P otherwise</p></li><li><p>根据信息在传输线上的传送方向，分为以下三种通信方式：</p><ul><li>单工通信Simplex：单向传输</li><li>半双工通信Half-duplex：双向交替传输</li><li>全双工通信Duplex：双向同时传输</li></ul></li><li><p>局域网：多种不同结构</p><ul><li>局域网是一种典型的广播信道，主要特点是网络为一个单位所拥有，且地理范围和站点数目均有限。有多种局域网技术，其中以太网占主导地位。可以按照网络拓扑结构对局域网进行分类：星 环 直线</li></ul></li><li><p>以太网：星形结构局域网 中间使用集线器或交换机连接</p></li><li><p>MAC地址 链路层地址 48位 设备网卡的唯一标识 有多少个适配器=多少个mac地址 os可更换</p></li><li><p>Switch交换机 Hub集线器 Router路由</p><ul><li>Hub 集线器 <strong>[layer1]</strong> enables mulitple hosts to create <strong>a broadcast Channel (only floods)</strong> 作用于物理层的 能使多个主机 创建一个广播频道的设备 具备多个网口，专门实现多台计算机的互联作用。</li><li>Switch 交换机 <strong>[layer 2]</strong> 收处理转发以太网帧到网络中的其他设备 会维护一个&lt;mac link/接口&gt; 表 “交换表” 表类似一个LRU缓存 因此能够实现mac地址识别=说它具有“学习能力”. Can have simultaneous p2p connectivity between different hosts</li><li>Router 路由 <strong>[layer 3]</strong> 根据routing table提供转发和路由两种功能 转发：将数据包移送到合适输出端 路由：决定数据包的路由路径。</li></ul></li><li><p>Bridge Repeater Gateway</p><ul><li>Repeater 中继器**[layer 1]** receive and repeat/regenerate signal</li><li>Bridge 网桥**[layer 2]** 连接两个局域网</li><li>Gateway 网关 <strong>[layer 3]</strong>  两个不同网络之间的关口设备</li></ul></li></ul><h1 id="ip-service-model-ip-best-effort-network-最大努力网络"><a class="markdownIt-Anchor" href="#ip-service-model-ip-best-effort-network-最大努力网络"></a> IP-service model / IP best-effort network /最大努力网络</h1><ul><li><p>packets may lose, duplicate, reorder</p></li><li><p>connectionelss best-effort destination based forwarding.</p></li></ul><h1 id="layering-architecture"><a class="markdownIt-Anchor" href="#layering-architecture"></a> Layering &amp; Architecture</h1><ul><li>OSI architecture 应用层传输层之间多了session(建立及管理会话) presentation(数据压缩、加密以及数据描述)</li><li>TCP/IP architecture 将物理层和数据链路层合并为“网络接口层”</li></ul><h2 id="application-layer"><a class="markdownIt-Anchor" href="#application-layer"></a> Application Layer</h2><p><strong>E2E</strong>用户服务  HTTP FTP DNS DHCP 远程登录 邮件</p><h2 id="transport-layer"><a class="markdownIt-Anchor" href="#transport-layer"></a> Transport Layer</h2><p><strong>E2E</strong> <strong>为应用进程提供端到端的通信服务 在应用层和网络层之间multiplexing和demultiplexing</strong> TCP UDP</p><p>Hide defects and limitations of the network</p><p>Fragmentation &amp; reassembly</p><p>resend defect packets</p><ul><li>TCP<ul><li>Connection oriented: need to set up connection (has overhead)</li><li>Reliable: it will make sure packets get through, if lost/corrupted resend packet</li><li>Flow control: “making sure receiver not overwhelmed”</li><li>Congestion control: “making network is not overloaded”</li></ul></li><li>UDP<ul><li>Connectionless: no need to set up connection, if need to send just send</li><li>Unreliable best-effort</li><li>No Flow control</li><li>No Congestion control</li></ul></li></ul><p>No timing / throughput / security gurantee</p><p>Why should we even bother using UDP ? you have a lot more control when having a tradeoff</p><h2 id="network-layer"><a class="markdownIt-Anchor" href="#network-layer"></a> Network Layer</h2><p>P2P Addressing, Routing, Congestion control <strong>点对点寻址，路由，拥塞控制</strong> Moving data between networks. 涉及协议： IP, ARP, ICMP and routing protocol</p><ul><li><p>Addressing</p><ul><li><p>IP: 沙漏结构的中点，将异构网络连接起来，使之看起来像个统一的网络</p><ul><li>IP is a <strong>unreliable</strong> protocol because it does not guarantee the delivery of a datagram to its destination. <strong>The reliability must be provided by the upper layer protocols like TCP.</strong> IP does not support flow control, retransmission, acknowledgement and error recovery.</li><li><strong>地址系统</strong><ul><li>Class-based addressing (过去版本):  lead to problem of large #networks in routing table</li><li>Subnetting and supernetting 子网与超网<ul><li>subnet ip = subnet mask &amp; host ip address</li><li>Supernetting: classless interdomain routing CIDR 无分类跨网地址系统<ul><li>ip地址=网络前缀+主机号 128.14.35.7/20 表示前 20 位为网络前缀。</li><li>意义：减少了路由表项   查找时采取最长前缀匹配原则选择哪一个</li></ul></li></ul></li></ul></li><li>Fragmentation/Reassembly <strong>报文的拆分重组</strong>: enabling heterogenous system to transmit their own “max pkt” 和tcp合作 tcp负责mtu discovery</li><li>Error reporting and control (ICMP) <strong>错误报告和控制</strong><ul><li><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/aa29cc88-7256-4399-8c7f-3cf4a6489559.png" alt="img" style="zoom:30%;"></li><li><strong>封装在 IP 数据报中</strong>，但是不属于高层协议。</li><li>ping 用来测试两台主机之间的连通性 通过icmp echo实现</li></ul></li><li>Traceroute 追踪一个数据包路径: 封装一个无法交付的udp包, 利用IP协议的“ttl”字段，尝试从每个网关到某个主机的路径引发ICMP 超时响应。</li><li>IP packet format</li></ul><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/85c05fb1-5546-4c50-9221-21f231cdc8c5.jpg" alt="img" style="zoom:40%;"></li></ul></li><li><p>Routing</p><ul><li><p><strong>How does router figure out MAC</strong></p><ul><li><p>ARP: routers and hosts maintain an dynammic &lt;IP, MAC&gt; cache, this table is called ARP table</p><p>If IP is not in ARP table, broadcast ARP request, hosts that have that IP address will responds</p></li></ul></li><li><p>Types &amp; protocols used</p><ul><li>Intra-domain<ul><li>RIP Routing Information Protocol:  rely on local computation in all nodes<ul><li>Distance Vector Protocol (based on Bellman-ford)</li></ul></li><li>OSPF Open Shortest Path First Protocol: no local computation  <strong>faster loop-free convergence</strong><ul><li>Link state Protocol (based on Dijkstra’s shortest path)</li></ul></li></ul></li><li>Inter-domain<ul><li>BGP Border Gateway Protocol</li></ul></li></ul></li></ul></li></ul><h2 id="link-layer"><a class="markdownIt-Anchor" href="#link-layer"></a> Link Layer</h2><p>P2P <strong>相邻网络节点/主机的数据传输和控制</strong> 局域网(LAN) 广域网(WAN)</p><ul><li><strong>Framing</strong> 把网络层传下来的包封装成帧 加个开始和结束</li><li>P2P点对点服务: Logical link control (LLC)<ul><li><strong>Error Detection</strong> CRC checksum</li><li><strong>Flow Control</strong> “making sure receiver not overwhelmed”</li></ul></li><li>Broadcast广播服务: Media access control (MAC)<ul><li><strong>Frames synchronization</strong> 帧的同步 clock based, character counting, byte stuffing.</li><li><strong>Channel sharing</strong> 信道共享- methods:<ul><li>信道复用：时分，频分，码分</li><li>交替：轮询，令牌传递</li><li>随机访问   主要例子：Aloha, Ethernet<ul><li>Ethernet MAC采用CSMA/CD协议 (Carrier Sense Multiple Access / Collision Detection) 载波监听多点接入/碰撞检测<ul><li>Only if line is idle, start to send immediately (Carrier Sense 载波监听)</li><li>if busy wait for “inter-frame gap” = 96 bit time</li><li>if collision detected, send jam signal, do binary exponential backoff “nth randomly choose k from {0,1,2,…,2^n-1}, then delay k*51.2 μs” 二进制指数后退   collision domain = 1 RTT</li></ul></li></ul></li></ul></li></ul></li></ul><h2 id="physical-layer"><a class="markdownIt-Anchor" href="#physical-layer"></a> Physical Layer</h2><p>P2P transmission of raw bits</p><h1 id="application-layer-2"><a class="markdownIt-Anchor" href="#application-layer-2"></a> Application Layer</h1><ul><li><p>2 different Architecture: Client Server / Peer to Peer</p></li><li><p>Socket = Door</p><ul><li>Transport Layer = hallway</li></ul></li><li><p>IP + port determines host &amp; process</p></li><li><p>Public Domain Protocols    Propertiary protocol Skype … etc.</p><ul><li>HTTP</li><li>FTP</li><li>SMTP</li><li>BitTorrent</li></ul></li><li><p>不同情况下应用有不同需求 data loss vs time-sensitive vs throughput</p></li></ul><h2 id="常用端口"><a class="markdownIt-Anchor" href="#常用端口"></a> 常用端口</h2><table><thead><tr><th>应用</th><th>应用层协议</th><th>端口号</th><th>传输层协议</th><th>备注</th></tr></thead><tbody><tr><td><strong>域名解析</strong></td><td><strong>DNS</strong></td><td><strong>53</strong></td><td><strong>UDP/TCP</strong></td><td><strong>长度超过 512 字节时使用 TCP</strong></td></tr><tr><td><strong>动态主机配置协议</strong></td><td><strong>DHCP</strong></td><td><strong>67/68</strong></td><td><strong>UDP</strong></td><td></td></tr><tr><td><strong>超文本传送协议</strong></td><td><strong>HTTP</strong></td><td><strong>80</strong></td><td><strong>TCP</strong></td><td></td></tr><tr><td><strong>文件传送协议</strong></td><td><strong>FTP</strong></td><td><strong>20/21</strong></td><td><strong>TCP</strong></td><td>数据连接 20，控制连接 21</td></tr><tr><td>远程终端协议</td><td>TELNET</td><td>23</td><td>TCP</td><td>ssh = 22</td></tr><tr><td>简单网络管理协议</td><td>SNMP</td><td>161/162</td><td>UDP</td><td></td></tr><tr><td>简单邮件传送协议</td><td>SMTP</td><td>25</td><td>TCP</td><td></td></tr><tr><td>邮件读取协议</td><td>POP3</td><td>110</td><td>TCP</td><td></td></tr><tr><td>网际报文存取协议</td><td>IMAP</td><td>143</td><td>TCP</td><td></td></tr></tbody></table><h2 id="web-and-http"><a class="markdownIt-Anchor" href="#web-and-http"></a> Web and HTTP</h2><h2 id="ftp"><a class="markdownIt-Anchor" href="#ftp"></a> FTP</h2><p>使用TCP进行连接, 使用2个连接来传输一个文件</p><ul><li>控制连接：服务器打开端口号 21 等待客户端的连接，客户端主动建立连接后，使用这个连接将客户端的命令传送给服务器，并传回服务器的应答。</li><li>数据连接：用来传送一个文件数据</li></ul><p>根据数据连接是否是服务器端主动建立，FTP 有主动和被动两种模式：</p><ul><li>主动模式：服务器端主动建立数据连接，服务器端端口号 20，客户端端口号1024 - 65535随机（因为 0~1023 是熟知端口号）。</li></ul><p><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/03f47940-3843-4b51-9e42-5dcaff44858b.jpg" alt="img"></p><ul><li>被动模式：服务器端被动，客户端主动建立数据连接，客户端端口号自己指定，服务器端的端口号随机。</li></ul><p><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/be5c2c61-86d2-4dba-a289-b48ea23219de.jpg" alt="img"></p><p>主动模式要求客户端开放端口号给服务器端，需要去配置客户端的防火墙。被动模式只需要服务器端开放端口号即可，无需客户端配置防火墙。但是被动模式会导致服务器端的安全性减弱，因为开放了过多的端口号。</p><h2 id="dns"><a class="markdownIt-Anchor" href="#dns"></a> DNS</h2><img src="https://s2.ax1x.com/2020/02/03/1NTl4S.png" alt="dns" style="zoom:50%;"><img src="https://s2.ax1x.com/2020/02/03/1NTMAf.png" alt="dns" style="zoom:50%;"><img src="https://s2.ax1x.com/2020/02/03/1NTuHP.png" alt="recdns" style="zoom:50%;"><p>DNS 可以使用 <strong>UDP 或者 TCP</strong> 进行传输，<strong>使用的端口号都为 53</strong>。大多数情况下 DNS 使用 <strong>UDP</strong> 进行传输，这就要求域名解析器和域名服务器都必须<strong>自己处理超时和重传</strong>从而保证可靠性。在两种<strong>特殊情况下会使用 TCP</strong> 进行传输：</p><ul><li>如果返回的响应超过 512 字节（UDP 最大只支持 512 字节的数据）。</li><li>DNS zone transfer</li></ul><h4 id="dns-负载均衡"><a class="markdownIt-Anchor" href="#dns-负载均衡"></a> DNS 负载均衡</h4><p>同一主机在dns服务器里配置多个主机记录=多个不同服务器ip，dns服务器解析域名时会轮询，这就完成了简单的负载均衡。</p><h2 id="dhcp"><a class="markdownIt-Anchor" href="#dhcp"></a> DHCP</h2><p>只适用于动态ip分配的情形，如进入一个新的移动网络。 主机不知道自己ip地址 ask dhcp server</p><p>DHCP (Dynamic Host Configuration Protocol) 是用于动态ip分配和配置的协议。</p><p>DHCP 配置的内容不仅是 IP 地址，还包括子网掩码、网关 IP 地址。</p><p>DHCP 工作过程如下：</p><ol><li>客户端发送 Discover 报文，该报文的目的地址为 255.255.255.255:67，源地址为 0.0.0.0:68，被放入 UDP 中，该报文被广播到同一个子网的所有主机上。如果客户端和 DHCP 服务器不在同一个子网，就需要使用中继代理。</li><li>DHCP 服务器收到 Discover 报文之后，发送 Offer 报文给客户端，该报文包含了客户端所需要的信息。因为客户端可能收到多个 DHCP 服务器提供的信息，因此客户端需要进行选择。</li><li>如果客户端选择了某个 DHCP 服务器提供的信息，那么就发送 Request 报文给该 DHCP 服务器。</li><li>DHCP 服务器发送 Ack 报文，表示客户端此时可以使用提供给它的信息。</li></ol><p><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/23219e4c-9fc0-4051-b33a-2bd95bf054ab.jpg" alt="img"></p><h2 id="远程登录协议"><a class="markdownIt-Anchor" href="#远程登录协议"></a> 远程登录协议</h2><p>SSH  TELNET</p><h2 id="电子邮件协议"><a class="markdownIt-Anchor" href="#电子邮件协议"></a> 电子邮件协议</h2><p>发送协议常用 SMTP，读取协议常用 POP3 和 IMAP。</p><h2 id="web页面请求过程"><a class="markdownIt-Anchor" href="#web页面请求过程"></a> Web页面请求过程</h2><h3 id="1-dhcp-配置主机信息"><a class="markdownIt-Anchor" href="#1-dhcp-配置主机信息"></a> 1. DHCP 配置主机信息</h3><ul><li>假设主机最开始没有 IP 地址以及其它信息，那么就需要先使用 DHCP 来获取。</li><li>主机生成一个 DHCP 请求报文，并将这个报文放入具有目的端口 67 和源端口 68 的 UDP 报文段中。</li><li>该报文段则被放入在一个具有广播 IP 目的地址(255.255.255.255) 和源 IP 地址（0.0.0.0）的 IP 数据报中。</li><li>该数据报则被放置在 MAC 帧中，该帧具有目的地址 FF:FF:FF:FF:FF:FF，将广播到与交换机连接的所有设备。</li><li>连接在交换机的 DHCP 服务器收到广播帧之后，不断地向上分解得到 IP 数据报、UDP 报文段、DHCP 请求报文，之后生成 DHCP ACK 报文，该报文包含以下信息：IP 地址、DNS 服务器的 IP 地址、默认网关路由器的 IP 地址和子网掩码。该报文被放入 UDP 报文段中，UDP 报文段有被放入 IP 数据报中，最后放入 MAC 帧中。</li><li>该帧的目的地址是请求主机的 MAC 地址，因为交换机具有自学习能力，之前主机发送了广播帧之后就记录了 MAC 地址到其转发接口的交换表项，因此现在交换机就可以直接知道应该向哪个接口发送该帧。</li><li>主机收到该帧后，不断分解得到 DHCP 报文。之后就配置它的 IP 地址、子网掩码和 DNS 服务器的 IP 地址，并在其 IP 转发表中安装默认网关。</li></ul><h3 id="2-arp-解析-mac-地址"><a class="markdownIt-Anchor" href="#2-arp-解析-mac-地址"></a> 2. ARP 解析 MAC 地址</h3><ul><li>主机通过浏览器生成一个 TCP 套接字，套接字向 HTTP 服务器发送 HTTP 请求。为了生成该套接字，主机需要知道网站的域名对应的 IP 地址。</li><li>主机生成一个 DNS 查询报文，该报文具有 53 号端口，因为 DNS 服务器的端口号是 53。</li><li>该 DNS 查询报文被放入目的地址为 DNS 服务器 IP 地址的 IP 数据报中。</li><li>该 IP 数据报被放入一个以太网帧中，该帧将发送到网关路由器。</li><li>DHCP 过程只知道网关路由器的 IP 地址，为了获取网关路由器的 MAC 地址，需要使用 ARP 协议。</li><li>主机生成一个包含目的地址为网关路由器 IP 地址的 ARP 查询报文，将该 ARP 查询报文放入一个具有广播目的地址（FF:FF:FF:FF:FF:FF）的以太网帧中，并向交换机发送该以太网帧，交换机将该帧转发给所有的连接设备，包括网关路由器。</li><li>网关路由器接收到该帧后，不断向上分解得到 ARP 报文，发现其中的 IP 地址与其接口的 IP 地址匹配，因此就发送一个 ARP 回答报文，包含了它的 MAC 地址，发回给主机。</li></ul><h3 id="3-dns-解析域名"><a class="markdownIt-Anchor" href="#3-dns-解析域名"></a> 3. DNS 解析域名</h3><ul><li>知道了网关路由器的 MAC 地址之后，就可以继续 DNS 的解析过程了。</li><li>网关路由器接收到包含 DNS 查询报文的以太网帧后，抽取出 IP 数据报，并根据转发表决定该 IP 数据报应该转发的路由器。</li><li>因为路由器具有内部网关协议（RIP、OSPF）和外部网关协议（BGP）这两种路由选择协议，因此路由表中已经配置了网关路由器到达 DNS 服务器的路由表项。</li><li>到达 DNS 服务器之后，DNS 服务器抽取出 DNS 查询报文，并在 DNS 数据库中查找待解析的域名。</li><li>找到 DNS 记录之后，发送 DNS 回答报文，将该回答报文放入 UDP 报文段中，然后放入 IP 数据报中，通过路由器反向转发回网关路由器，并经过以太网交换机到达主机。</li></ul><h3 id="4-http-请求页面"><a class="markdownIt-Anchor" href="#4-http-请求页面"></a> 4. HTTP 请求页面</h3><ul><li>有了 HTTP 服务器的 IP 地址之后，主机就能够生成 TCP 套接字，该套接字将用于向 Web 服务器发送 HTTP GET 报文。</li><li>在生成 TCP 套接字之前，必须先与 HTTP 服务器进行三次握手来建立连接。生成一个具有目的端口 80 的 TCP SYN 报文段，并向 HTTP 服务器发送该报文段。</li><li>HTTP 服务器收到该报文段之后，生成 TCP SYN ACK 报文段，发回给主机。</li><li>连接建立之后，浏览器生成 HTTP GET 报文，并交付给 HTTP 服务器。</li><li>HTTP 服务器从 TCP 套接字读取 HTTP GET 报文，生成一个 HTTP 响应报文，将 Web 页面内容放入报文主体中，发回给主机。</li><li>浏览器收到 HTTP 响应报文后，抽取出 Web 页面内容，之后进行渲染，显示 Web 页面。</li></ul><h1 id="tcpudp"><a class="markdownIt-Anchor" href="#tcpudp"></a> TCP/UDP</h1><ul><li><p>UDP header：src port, dest port, header length, checksum</p></li><li><p><strong>TCP header:</strong></p><ul><li>SRC，DST ports (16-bit each)</li><li><strong>Sequence #序号,     Ack #确认号</strong>(32-bit each) 序号：当前数据段第一个字节编号 确认号：期望下个数据段第一个字节编号</li><li>Header length(data offset), <strong>reserve flags(indicate pkt types)</strong> SYN FIN ACK</li><li><strong>Receive window</strong> (16-bits     that specify how big my receive buffer is) important for <strong>flow control</strong></li><li>Check sum, Urgent Ptr: can be     used by app to indicate a receiving host need to pay attention about     packets but most case is ignored.</li><li>Options</li></ul></li><li><p>TCP</p><ul><li>全双工：代表建立连接后可以双向传送接受数据</li><li>以连接为导向： 意味着需要主动建立连接</li><li>可以提供包级别的可靠传输 什么是包级别的可靠传输：udp只提供位级别的可靠传输 由checksum实现 只能进行简单的检测看看数据是否污染，包级别可靠传输 在网络层 也就是基本的的ip-service model=best-effort destination-based forwarding里是不能够被保证的，但是我们在很多实际应用中又需要这个保证，所以就在传输层由tcp来做：<strong>保证包级别可靠传输</strong>主要靠两个机制：<ul><li>接收方发送<strong>确认</strong>ack 就是要求接受者每次接收到数据都要回复发送方 说一声我收到了 只有这个确认机制只能保证我们可以收到包，还不够，有问题的包还需要进行恢复</li><li><strong>计时器/超时检测机制</strong> 解决了“<strong>什么时候重新发没收到的/有问题的包</strong>”  他的机制很简单：只要超时了 就要重发 超时标准要比RTT稍微多一点尽量接近RTT, RTO新= RTO旧*2  by karn’s algorithm</li></ul></li><li>提供流量控制：确保接收方的buffer不会overflow<ul><li>接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。</li></ul></li><li>提供拥塞控制：与整个网络有关, 网络比较拥挤的时候控制发送方的窗口。增加一个congestion window CWND<ul><li><strong>send window (#unacknowledge pkts in flight) = min(CWND, RWND</strong>) 当cwnd更小时，我们就进入了一个拥塞控制的模式<ul><li>慢开始与拥塞避免<ul><li>cwnd := 1, cwnd++ for each ack == cwnd*2 each RTT</li><li>cwnd &gt;= ssthresh do congestion avoidance: cwnd++ for each RTT;</li></ul></li><li>快重传和快恢复 on dupack fast retransmit the next sequence from receiver side.  Fast recover it by setting ssthresh = cwnd/2, cwnd = ssthresh, do congestion avoidance</li></ul></li></ul></li></ul></li></ul><h2 id="三次握手建立连接-四次挥手关闭连接"><a class="markdownIt-Anchor" href="#三次握手建立连接-四次挥手关闭连接"></a> 三次握手建立连接 四次挥手关闭连接</h2><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/e92d0ebc-7d46-413b-aec1-34a39602f787.png" alt="img" style="zoom:35%;"><ul><li><p><strong>为什么需要三次握手</strong>：TCP是一个<strong>全双工</strong>通信协议，也就是说它是<strong>双向收发</strong>的。<strong>初始序号是两边都要随机选择</strong>, 这个主要是因为安全问题要避免TCP sequence prediction attack的。<strong>然后，因为两方都要告诉对面自己的初始序号</strong> = 也就是<strong>通信双方数据原点的位置</strong>，<strong>所以至少要4次握手</strong>。SYN  ACK SYN ACK, <strong>然后因为tcp header里reserve flags部分SYN ACK是可以同时为1的 中间两个步骤可以合并</strong> 所以3次就够。</p></li><li><p>第三次握手过程中sender可以piggypack data而receiver只能在这次握手结束才可以。</p></li><li><p>在socket编程中，客户端执行connect()时，将触发三次握手。</p></li></ul><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/f87afe72-c2df-4c12-ac03-9b8d581a8af8.jpg" alt="img" style="zoom:50%;"><ul><li><p>四次挥手是因为tcp是双向的性质+tcp半关闭造成的。假如客户端主动关闭，那么直到客户端收到服务器的ack前，数据传输仍然可以从服务器到客户端进行，tcp是半关闭的client-server关了但server-client方向还没关，这也是为什么有close-wait状态的原因，服务器端要等待最后这一波数据传输的完成。所以这也解释了中间两次为什么不能像建立连接一样合并。当服务器没有数据要传时他就可以通过fin来释放自己方向的连接了。</p></li><li><p><strong>TIME_WAIT / 2MSL等待状态</strong>: 首先被动方如果接受了ack不需要等，因为他已经完成同步了可以释放资源了。然后主动方必须要等因为他不知道自己发的ack对面收没收到。这里需要假设没收到。那么它需要等待来自对面的超时重传消息，这最坏情况要1MSL。然后他等到了的话又要发ack回去。所以主动方要等最坏情况一个来回2MSL。</p></li><li><p>在socket编程中，任何一方执行close()操作即可产生挥手操作。</p></li></ul><h2 id="应用层面实现可靠传输-发收双方缓存工作原理滑动窗口"><a class="markdownIt-Anchor" href="#应用层面实现可靠传输-发收双方缓存工作原理滑动窗口"></a> 应用层面实现可靠传输-发收双方缓存工作原理：滑动窗口</h2><ul><li>Buffers on senders and receivers are operated as “sliding window”. Senders maintain buffers of sent but unacknowledged packets. Receivers maintains buffer to assure non-duplicate, in order delivery to applications.</li><li>发送方缓存：<strong>已发送和未确认的包</strong>   接收方缓存：<strong>不重复，按序到达的包</strong></li></ul><p>窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。</p><p><strong>发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收</strong>。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。</p><p>接收窗口<strong>只会对窗口内最后一个按序到达的字节进行确认</strong>。<strong>发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。就可以移动了</strong>。<strong>如果发送方窗口迟迟收不到来自接收方的确认，就会超时重传</strong></p><p><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/a3253deb-8d21-40a1-aae4-7d178e4aa319.jpg" alt="img"></p><h2 id="拥塞控制"><a class="markdownIt-Anchor" href="#拥塞控制"></a> 拥塞控制</h2><p>如果网络出现拥塞，分组将会丢失，此时发送方会继续重传，从而导致网络拥塞程度更高。因此当出现拥塞时，应当控制发送方的速率。这一点和流量控制很像，但是出发点不同。流量控制是为了让接收方能来得及接收，而拥塞控制是为了降低整个网络的拥塞程度。</p><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/51e2ed95-65b8-4ae9-8af3-65602d452a25.jpg" alt="img" style="zoom:30%;"><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/910f613f-514f-4534-87dd-9b4699d59d31.png" alt="img" style="zoom:30%;"><h2 id="1-慢开始与拥塞避免"><a class="markdownIt-Anchor" href="#1-慢开始与拥塞避免"></a> 1. 慢开始与拥塞避免</h2><ul><li><p>Slow start: 初始 cwnd = 1，每收到1个ack cwnd++，cwnd指数增长：2、4、8 …</p></li><li><p>为避免过快，设置一个慢开始门限 ssthresh，当 cwnd &gt;= ssthresh 时，进入拥塞避免，每个轮次cwnd++</p></li><li><p>超时: 令 ssthresh = cwnd / 2，重新执行慢开始。</p></li></ul><h2 id="2-快重传与快恢复"><a class="markdownIt-Anchor" href="#2-快重传与快恢复"></a> 2. 快重传与快恢复</h2><p>接收方只对最后一个收到的有序报文段进行确认。在发送方，如果收到<strong>三个重复确认</strong>，那么可以知道接收方下一个报文段丢失，此时执行快重传</p><p>只是丢失个别报文段，而不是网络拥塞，因此执行快恢复，令 ssthresh = cwnd / 2 ，cwnd = ssthresh，注意到此时直接进入拥塞避免。</p><img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/f61b5419-c94a-4df1-8d4d-aed9ae8cc6d5.png" alt="img" style="zoom:50%;"><h1 id="http"><a class="markdownIt-Anchor" href="#http"></a> HTTP</h1><ul><li>Stateless<ul><li>Every request is completely independent</li><li>Similar to transaction</li><li>programming, local storage, cookies, sessions are used to create enhanced user experience</li></ul></li><li>HTTPS<ul><li>data sent is encrpted</li><li>SSL / TLS</li><li>install a certificate on web host.</li></ul></li><li>HTTP Methods<ul><li>GET: fetch data from server</li><li>POST: submit data to server</li><li>PUT: update data already on the server</li><li>DELETE: deletes data from server</li></ul></li><li>Headers<ul><li>General: Request URL, Method, Status code, remote address, referer policy</li><li>Response: server, set-cookie, content-type, content-length, date</li><li>Request: cookies, accept-xxx, content-type, content-length, authorization, user-agent, referrer</li></ul></li></ul><h2 id="基本方法"><a class="markdownIt-Anchor" href="#基本方法"></a> 基本方法</h2><ul><li>Get 获取资源</li><li>Post 传输数据</li><li>Head 获取报文头部</li><li>Put/Delete 上传/删除文件 不安全没有验证机制</li><li>Patch 部分修改资源</li></ul><h2 id="状态码"><a class="markdownIt-Anchor" href="#状态码"></a> 状态码</h2><p>200 OK</p><p>3XX 重定向</p><p>4XX 客户端错误 如 404 NOT FOUND</p><p>5XX 服务端错误</p><h2 id="长连接短连接流水线"><a class="markdownIt-Anchor" href="#长连接短连接流水线"></a> 长连接短连接&amp;流水线</h2><ul><li><p>HTTP 1.1之后采用长连接persistent connection 只需要建立一次 TCP 连接就能进行多次 HTTP 通信。如果要断开连接，需要由客户端或者服务器端提出断开，使用 <code>Connection : close</code>；在 HTTP/1.1 之前默认是短连接的，如果需要使用长连接，则使用 <code>Connection : Keep-Alive</code>。</p></li><li><p>默认情况下，HTTP 请求是按顺序发出的，下一个请求只有在当前请求收到响应之后才会被发出。由于受到网络延迟可能需要等待很长时间。</p><p>流水线是在同一条长连接上连续发出请求，而不用等待响应返回，这样可以减少延迟。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;包交换-vs-电路交换网络&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#包交换-vs-电路交换网络&quot;&gt;&lt;/a&gt; 包交换 vs 电路交换网络&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;电路交换
&lt;ul&gt;
&lt;li&gt;需要建立连接 和 专用物理线路 线路利
      
    
    </summary>
    
    
      <category term="Computer Network" scheme="http://th2zz.github.io/tags/Computer-Network/"/>
    
  </entry>
  
  <entry>
    <title>Database Concurrency Summary</title>
    <link href="http://th2zz.github.io/2019/10/01/database_concurrency/"/>
    <id>http://th2zz.github.io/2019/10/01/database_concurrency/</id>
    <published>2019-10-01T08:35:04.000Z</published>
    <updated>2020-02-08T17:32:29.566Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据库并发控制"><a class="markdownIt-Anchor" href="#数据库并发控制"></a> 数据库并发控制</h1><h1 id="concurrency-control"><a class="markdownIt-Anchor" href="#concurrency-control"></a> Concurrency control</h1><h2 id="acid-principle-for-transaction-management"><a class="markdownIt-Anchor" href="#acid-principle-for-transaction-management"></a> ACID principle for transaction management</h2><h3 id="atomicity-原子性-all-or-none"><a class="markdownIt-Anchor" href="#atomicity-原子性-all-or-none"></a> Atomicity 原子性 “all or none”</h3><p>事务所做操作要么全部提交要么全部失败回滚</p><ul><li>实现： 日志,   Shadow paging</li></ul><h3 id="consistency-一致性-looks-correct"><a class="markdownIt-Anchor" href="#consistency-一致性-looks-correct"></a> Consistency 一致性 “looks correct”</h3><ul><li><p>数据库一致性 仍遵循完整性约束 未来事务能看到过去事务造成的后果</p></li><li><p>事务一致性  事务前后数据库内容一致 一致意味着多个事务访问相同数据得到相同结果</p></li></ul><h3 id="isolation-隔离性-lives-alone"><a class="markdownIt-Anchor" href="#isolation-隔离性-lives-alone"></a> Isolation 隔离性 “lives alone”</h3><p>事务所作修改提交前对其他事务不可见</p><ul><li>两种类别的并发控制协议来保证隔离性<ul><li>悲观  从最初就避免问题的发生</li><li>乐观  假设冲突发生不常见，发生后再处理</li></ul></li></ul><h3 id="durability-持久性-survives-failure"><a class="markdownIt-Anchor" href="#durability-持久性-survives-failure"></a> Durability 持久性 “survives failure”</h3><p>事务提交的修改应被持久化，即便系统崩溃也不受影响</p><h2 id="conflict-serializability-in-transaction-scheduling"><a class="markdownIt-Anchor" href="#conflict-serializability-in-transaction-scheduling"></a> Conflict Serializability in transaction scheduling</h2><ul><li><strong>Schedules are equivalent to some serial schedule.</strong></li><li>This is what (almost) every DBMS supports when you ask for the SERIALIZABLE isolation level.</li><li>Schedule S is <strong>conflict serializable</strong> if you are able to <strong>transform</strong> S into a <strong>serial schedule</strong> by <strong>swapping</strong> consecutive non-conflicting operations of different transactions.</li><li>Verify using either the swapping method or dependency graphs.</li><li>A schedule is <strong>conflict serializable</strong> if and only if its dependency graph is <strong>acyclic</strong>.</li></ul><h2 id="consistency-conflicts-in-transaction-management"><a class="markdownIt-Anchor" href="#consistency-conflicts-in-transaction-management"></a> Consistency Conflicts in transaction management</h2><ul><li>读写冲突：<ul><li>不可重复读 “non-repeatable read”   两个读的中间数据被另一个事务<strong>覆写并提交</strong> 导致第二次读的<strong>同一行值</strong>不同<ul><li>transaction reads committed <strong>UPDATES</strong> from another transaction. The same row now has different values than it did when your transaction began.</li><li>A non-repeatable read occurs, when during the course of a transaction, a row is retrieved twice and the <strong>values within the row differ</strong> between reads.</li></ul></li><li>幻读 “phantom read” 两个读的中间<strong>被另一个事务插入/删除行并提交</strong> 导致第二次读<strong>返回的行不同</strong><ul><li>Phantom reads are similar but when reading from committed <strong>INSERTS</strong> and/or <strong>DELETES</strong> from another transaction. There are new rows or rows that have disappeared since you began the transaction.</li><li>A phantom read occurs when, in the course of a transaction, two identical queries are executed, and the <strong>collection of rows</strong> returned by the second query is different from the first.</li></ul></li><li>避免不可重复读锁行就足够，避免幻影读则需要锁表</li></ul></li><li>写读冲突： 脏读 “dirty reads” Reading uncommitted data 读了另一个事务没有提交的数据</li><li>写写冲突：丢失修改 “lost updates” overwriting uncommitted data 一个事务覆盖另一个事务没有提交的数据</li></ul><h2 id="pessimistic-concurrency-control"><a class="markdownIt-Anchor" href="#pessimistic-concurrency-control"></a> Pessimistic Concurrency Control</h2><h3 id="two-phase-locking-cc-protocol"><a class="markdownIt-Anchor" href="#two-phase-locking-cc-protocol"></a> Two-Phase Locking CC protocol</h3><ul><li><p><strong>Pessmistic 悲观的</strong> assume there are a lot of contentions in transactions 因此安全程度高 但并发能力会有所限制 (not allow all serializable schedules)</p></li><li><p>Two basic types of locks &amp; compatibility matrix</p><ul><li>Write lock X (exclusive) Read lock S (shared)</li></ul></li><li><p>2PL <strong>always</strong> gurantee conflicts-serializable schedule = grantee serializable schedule</p></li><li><p>二个阶段      “/\”</p><ul><li>生长期 只允许拿锁</li><li>收缩期 一旦释放第一个锁 进入收缩期<ul><li>只允许释放锁 或不释放锁</li><li>不允许拿锁</li></ul></li></ul></li><li><p>Problem: can have <strong>cascading abort</strong> in case of <strong>dirty reads</strong> 例如t1写 t2读 此时t1还没commit便abort 此时t2不得不abort…如果t2也写了还没来的及提交后面还有读的那这个反应会连锁下去</p></li><li><p>Solution: Strong Strict 2PL  (SS2PL) 一个事务提交/abort后才允许放锁 一次放完</p></li><li><p>Deadlock handling:</p><ul><li>Detection:<ul><li>run backgroud task that periodically checks for cycles in waits-for graph / 超时检测</li><li>selects a victim to rollback and breaks the cycle 选择标准和rollback程度取决于具体设计</li></ul></li><li>Prevention:<ul><li>assign priority based on timestamp  older timestamp = higher priority</li><li>after comparison, one will get lock, the other waits, this essentially breaks deadlock.</li></ul></li></ul></li></ul><h3 id="locking-granularities-and-hierarchy"><a class="markdownIt-Anchor" href="#locking-granularities-and-hierarchy"></a> Locking Granularities and hierarchy</h3><p>MySQL 中提供了两种封锁粒度：行级锁以及表级锁。<br>应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。<br>但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。<br>在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。</p><ul><li>一个事务想要更新1billion tuples = ask for locks 1 billion times  VERY SLOW</li><li>WE NEED a lock hierarchy that reflects what is down there (行级) at high level (表级)</li></ul><h4 id="如何更方便的进行多粒度封锁-意向锁"><a class="markdownIt-Anchor" href="#如何更方便的进行多粒度封锁-意向锁"></a> 如何更方便的进行多粒度封锁： 意向锁</h4><ul><li><p>意向锁Intention lock: “lock escalation” 细粒度锁太多时动态的分配可用的粗粒度锁  大大减少lock manager需要处理的锁的请求数量</p><p>Intention locks <strong>allow a higher level node to be locked in shared or exclusive mode without having to check all descendant nodes.</strong> If a node is in an intention mode, then explicit locking is being done at a lower level in the tree. <strong>基本相当于告诉你下面有什么样的锁 通过兼容矩阵 可以从hierarchy高处如表级快速判断能不能读/写下层具体行的数据</strong></p></li><li><p>Intention-Shared (IS):下面某个地方有读锁</p><ul><li>Intention-Exclusive (IX):下面某个地方有写锁</li></ul></li><li><p>Shared+Intention-Exclusive (SIX):  整个子树可共享读，下面某个孩子有写锁</p></li><li><p>各种锁的兼容关系如下：</p><div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/image-20191207214442687.png"> </div><br>解释如下：<ul><li>任意 IS/IX 锁之间都是兼容的，因为它们只表示想要对表加锁，而不是真正加锁；</li><li>这里兼容关系针对的是表级锁，而表级的 IX 锁和行级的 X 锁兼容，两个事务可以对两个数据行加 X 锁。（事务 T<sub>1</sub> 想要对数据行 R<sub>1</sub> 加 X 锁，事务 T<sub>2</sub> 想要对同一个表的数据行 R<sub>2</sub> 加 X 锁，两个事务都需要对该表加 IX 锁，但是 IX 锁是兼容的，并且 IX 锁与行级的 X 锁也是兼容的，因此两个事务都能加锁成功，对同一个表中的两个数据行做修改。）</li></ul></li></ul><h3 id="三级封锁协议"><a class="markdownIt-Anchor" href="#三级封锁协议"></a> 三级封锁协议</h3><ul><li><strong>一级封锁协议</strong>  事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。可以解决丢失修改问题</li><li><strong>二级封锁协议</strong>  在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。可以解决读脏数据问题</li><li><strong>三级封锁协议</strong>  在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。可以解决不可重复读的问题</li></ul><h3 id="mysql-隐式与显示锁定"><a class="markdownIt-Anchor" href="#mysql-隐式与显示锁定"></a> MySQL 隐式与显示锁定</h3><p>MySQL 的 InnoDB 存储引擎采用两段锁协议，会<strong>根据隔离级别在需要的时候自动加锁，并且所有的锁都是在同一时刻被释放，这被称为隐式锁定</strong>。<br>InnoDB 也可以使用特定的语句进行显示锁定：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> ... <span class="keyword">LOCK</span> <span class="keyword">In</span> <span class="keyword">SHARE</span> <span class="keyword">MODE</span>;</span><br><span class="line"><span class="keyword">SELECT</span> ... <span class="keyword">FOR</span> <span class="keyword">UPDATE</span>;</span><br></pre></td></tr></table></figure><h2 id="optimistic-concurrency-control"><a class="markdownIt-Anchor" href="#optimistic-concurrency-control"></a> Optimistic Concurrency Control</h2><p>Ensure ordering using different methods. Assume they are good, handle problems later.</p><h3 id="basic-timestamp-ordering-to-cc-protocol"><a class="markdownIt-Anchor" href="#basic-timestamp-ordering-to-cc-protocol"></a> Basic Timestamp ordering (T/O) CC protocol</h3><ul><li><p>Basic idea: assign <strong>unique fixed monotonically increasing numeric</strong> value “timestamp” to determine <strong>commit order</strong>.</p><ul><li>different schemes for implementing timestamp: system clock, logical counter…</li></ul></li><li><p>Timestamp smaller TS(i) &lt; TS(j) = transaction i appears before j.</p></li><li><p>Method:</p><ul><li>Transaction r/w object without locks.</li><li>Every object X is tagged with timestamp of last txn that successfully did read / write. R-TS(X) / W-TS(X)</li><li>Reads<ul><li>Check timestamp for every operations, if txn k tries to access an object from the future, <strong>TS(k) &lt; W-TS(X)</strong>, (timestamp order of k violates writer of X), k aborts and restarts with <strong>newer</strong> TS.</li><li>Otherwise allow txn k to read X, update R-TS(X) = max(R-TS(X), TS(k)), make a local copy of X to ensure repeatable reads for k. (subsequent read occurs in local copy)</li></ul></li><li>Writes<ul><li>If TS(k) &lt; R-TS(X) or TS(k) &lt; W-TS(X) abort and restart k.<ul><li>opitimization: in case of write can simply <strong>ignore and continue</strong> “thomas write rule” this allow us to even commit it. Somewhat useful but will not give us a conflict serializable schedule.</li></ul></li><li>else allow k to write X and update W-TS(X), make a local copy of X to ensure repeatable reads for k. (subsequent read occurs in local copy)</li></ul></li></ul></li><li><p>Comments:</p><ul><li>Can gurantee to generate a conflict serializable schedule if do not use “Thomas write rule”</li><li>No deadlocks because no “waiting” at all.</li><li>Can have starvation for long tens if shorter one keep causeing conflicts.</li><li>permits schedules that are not recoverable 可恢复事务: 他读到的所有事务在他之前commit</li><li>high overhead of copying data to local workspace and updating timestamps.</li></ul></li></ul><h3 id="optimistic-cc-occ-protocol"><a class="markdownIt-Anchor" href="#optimistic-cc-occ-protocol"></a> Optimistic CC (OCC) protocol</h3><ul><li><p>Basic idea:  No locks at all.</p><ul><li>DBMS creates a private workspace for each transaction</li><li>any obj read is copied into thread local workspace for following r/w, perform modifications at local workspace</li><li>Validation: when commits, DBMS compares local workspace to see if it incurrs conflicts with other txns. Get a timestamp.</li><li>Atomic install to global database if no conflicts.</li></ul></li><li><p>3 Phases</p><ul><li><ol><li>Read: make w/r modifications at private thread local workspace</li><li>Validation: check if conflicts exist before commit, get a timestamp</li><li>Write: valid =&gt; apply local changes to global database, abort &amp; restart otherwise.</li></ol></li></ul></li><li><p>Serial Validation Explained</p><ul><li>Maintain a global view of all active txns.</li><li>record w/r set while txns running and write into private workspace</li><li>execute validation and write phase in a protected critical section</li><li>when txn invokes COMMIT, DBMS checks existence of conflicts through methods like the following, <strong>it checks if 双方write set intersects</strong>, if so, abort (myself) .<ul><li>Backward Validation: look at all older txns in the system</li><li>Forward Validation: look at all younger txns in the system.</li></ul></li></ul></li><li><p>Comments:</p><ul><li>OCC Works well when #conflicts is low, transactions read heavy, mostly accessing disjoint subsets of data.  In this case locking is wasteful.</li><li>High overhead of copying data to local space. Serial Validation/Write bottlenecks. Aborts more wasteful than 2PL because txns have already executed.   The validation step also need latches when comparing read write sets because maybe T2 is writing while T1 is reading. latch contention when a lot of concurrent txns ?</li></ul></li></ul><h3 id="partition-based-timestamp-ordering-protocol"><a class="markdownIt-Anchor" href="#partition-based-timestamp-ordering-protocol"></a> Partition-based Timestamp ordering protocol</h3><ul><li>Idea:<ul><li>partition db into disjoint subsets called partitions / <strong>shards</strong> so that we do not need locks.</li><li>Queued up &amp; assign timestamps upon arrival to order txns for serial execution at each partition. <strong>NO Concurrency  THIS IS SINGLE-THREADED</strong>.</li><li>Partitions are protected by a single lock. A txn acquires the partition’s lock if it has the lowest timestamp in queue, it starts when it has all the locks of partitions it needs (r/w).<ul><li>A txn can read anything in the partition it have locked</li><li>write occurs in place, maintains a in-mem buffer to undo changes if aborted.</li><li>abort &amp; restart if accessing a partition that it does not have the lock.</li></ul></li><li>Only check conflicts between txns within same partitions.</li><li>The finer-grained each partition is the more parallelism we get on disjoint sets of data</li></ul></li><li>Comments:<ul><li>Fast: when DBMS knows what partitions txn needs before it starts, most txns only need to access a single partition.</li><li>Mult-partition txns are slower, some partitions can be idle.</li></ul></li></ul><h3 id="phantom-problem"><a class="markdownIt-Anchor" href="#phantom-problem"></a> Phantom problem</h3><ul><li>The above discussed protocols only deal with read/update. But if we have insertions / updates / deletions, we can have the phantom problem.<ul><li>2PL cannot solve this because these new rows do not even have locks.</li><li>Predicate locking can solve it but too hard to implement.</li><li>Index locking can solves it</li></ul></li></ul><h2 id="isolation-level"><a class="markdownIt-Anchor" href="#isolation-level"></a> Isolation Level</h2><p>产生并发不一致性问题的主要原因是破坏了事务的隔离性，解决方法是通过并发控制来保证隔离性。并发控制可以通过封锁来实现，但是封锁操作需要用户自己控制，相当复杂。数据库管理系统提供了事务的隔离级别，让用户以一种更轻松的方式处理并发一致性问题。</p><p><img src="https://s2.ax1x.com/2020/02/02/1J7MlR.png" alt="isl"></p><ul><li>RU: 事务中的修改，即使没有提交，对其它事务也是可见的。</li><li>RC: 一个事务只能读取已经提交的事务所做的修改。</li><li>RR: 保证在同一个事务中多次读取同一数据的结果是一样的。</li><li>S: 强制事务串行执行，这样多个事务互不干扰，不会出现并发一致性问题。从MVCC并发控制退化为基于锁的并发控制。不区别快照读和当前读，所有的读操作都是当前读，读加读锁（S锁），写加写锁（X锁）。在该隔离级别下，读写冲突，因此并发性能急剧下降，在MySQL/InnoDB中不建议使用。</li></ul><h2 id="multi-version-concurrency-control"><a class="markdownIt-Anchor" href="#multi-version-concurrency-control"></a> Multi-version concurrency control</h2><ul><li><p>“Let writers make a “new” copy while readers use an appropriate “old” copy.”</p></li><li><p>最常见的并发控制方法 DBMS. 非常适合读多写少的OLTP workload 可以提供rr级别的隔离程度</p></li><li><p>读=读一个版本 写=创建一个新版本 版本号一般是通过时间戳机制分配</p></li><li><p>只有 写写冲突 通过first commiter/first updater win 解决</p></li><li><p>RC RR隔离级别下使用版本链 多个版本的快照存在undo日志中，日志通过回滚指针把一个数据行的所有快照连起来</p></li><li><p>MVCC 维护一个read view结构 读的时候判断数据行快照是否可以使用</p></li><li><p>mvcc下快照读select…不需要锁，当前读（涉及插入删除更新）仍需要锁</p></li><li><p>mysql为了解决rr级别下当前读的幻读问题，使用了next-key lock本质上是索引锁+间隙锁 = 不仅锁定了索引还锁定了索引之间的间隙 就相当于数学上一个大区间中间很多个小区间  我在小区间端点上加锁之外还要在间隙上加锁才能保证安全性</p></li></ul><h1 id="关系数据库设计理论"><a class="markdownIt-Anchor" href="#关系数据库设计理论"></a> 关系数据库设计理论</h1><h2 id="函数依赖"><a class="markdownIt-Anchor" href="#函数依赖"></a> 函数依赖</h2><p>记 A-&gt;B 表示 A uniquely determines B，也可以说 B functionaly dependent on A。</p><p><strong>Full Functional Dependency :</strong> X is functionally dependent on Y and is not functionally dependent on any proper subset of Y.</p><p>A <strong>Partial Functional Dependency</strong> is when you have a Composite Primary Key (a primary key that is made up of multiple columns), and one of the non-key columns is functionally dependent on a proper subset of the columns that make up the Composite Primary Key.</p><p>对于 A-&gt;B，B-&gt;C，则 A-&gt;C 是一个传递函数依赖。</p><p>For example : Let there be a relation R ( Course, Sid , Sname , fid, schedule ,  room , marks )</p><p>Full Functional Dependencies : {Course , Sid) -&gt; Sname , {Course , Sid} -&gt; Marks, etc.</p><p>Partial Functional Dependencies : Course -&gt; Schedule ,  Course -&gt; Room</p><h2 id="异常"><a class="markdownIt-Anchor" href="#异常"></a> 异常</h2><p>以下的学生课程关系的函数依赖为 {Sno, Cname} -&gt; {Sname, Sdept, Mname, Grade}，键码为 {Sno, Cname}。也就是说，确定学生和课程之后，就能确定其它信息。</p><table><thead><tr><th style="text-align:center">Sno</th><th style="text-align:center">Sname</th><th style="text-align:center">Sdept</th><th style="text-align:center">Mname</th><th style="text-align:center">Cname</th><th style="text-align:center">Grade</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">学生-1</td><td style="text-align:center">学院-1</td><td style="text-align:center">院长-1</td><td style="text-align:center">课程-1</td><td style="text-align:center">90</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">学生-2</td><td style="text-align:center">学院-2</td><td style="text-align:center">院长-2</td><td style="text-align:center">课程-2</td><td style="text-align:center">80</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">学生-2</td><td style="text-align:center">学院-2</td><td style="text-align:center">院长-2</td><td style="text-align:center">课程-1</td><td style="text-align:center">100</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">学生-3</td><td style="text-align:center">学院-2</td><td style="text-align:center">院长-2</td><td style="text-align:center">课程-2</td><td style="text-align:center">95</td></tr></tbody></table><p>不符合范式的关系，会产生很多异常，主要有以下四种异常：</p><ul><li>冗余数据：例如 <code>学生-2</code> 出现了两次。</li><li>修改异常：修改了一个记录中的信息，但是另一个记录中相同的信息却没有被修改。</li><li>删除异常：删除一个信息，那么也会丢失其它信息。例如删除了 <code>课程-1</code> 需要删除第一行和第三行，那么 <code>学生-1</code> 的信息就会丢失。</li><li>插入异常：例如想要插入一个学生的信息，如果这个学生还没选课，那么就无法插入。</li></ul><h2 id="范式"><a class="markdownIt-Anchor" href="#范式"></a> 范式</h2><p>范式理论是为了解决以上提到四种异常。</p><p>高级别范式的依赖于低级别的范式，1NF 是最低级别的范式。</p><h3 id="1-第一范式-1nf"><a class="markdownIt-Anchor" href="#1-第一范式-1nf"></a> 1. 第一范式 (1NF)</h3><p>原子属性不可分。</p><h3 id="2-第二范式-2nf"><a class="markdownIt-Anchor" href="#2-第二范式-2nf"></a> 2. 第二范式 (2NF)</h3><p>1NF+每个非主属性不存在<strong>部分函数依赖</strong>(完全函数依赖于主属性/主键)。</p><p>可以通过分解来满足。</p><table><thead><tr><th style="text-align:center">Sno</th><th style="text-align:center">Sname</th><th style="text-align:center">Sdept</th><th style="text-align:center">Mname</th><th style="text-align:center">Cname</th><th style="text-align:center">Grade</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">学生-1</td><td style="text-align:center">学院-1</td><td style="text-align:center">院长-1</td><td style="text-align:center">课程-1</td><td style="text-align:center">90</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">学生-2</td><td style="text-align:center">学院-2</td><td style="text-align:center">院长-2</td><td style="text-align:center">课程-2</td><td style="text-align:center">80</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">学生-2</td><td style="text-align:center">学院-2</td><td style="text-align:center">院长-2</td><td style="text-align:center">课程-1</td><td style="text-align:center">100</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">学生-3</td><td style="text-align:center">学院-2</td><td style="text-align:center">院长-2</td><td style="text-align:center">课程-2</td><td style="text-align:center">95</td></tr></tbody></table><p>以上学生课程关系中，{Sno, Cname} 为主键，有如下函数依赖：</p><ul><li>Sno -&gt; Sname, Sdept</li><li>Sdept -&gt; Mname</li><li>Sno, Cname-&gt; Grade</li></ul><p>Grade 完全函数依赖于主键，它没有任何冗余数据，每个学生的每门课都有特定的成绩。</p><p>Sname, Sdept 和 Mname 都部分依赖于主键，当一个学生选修了多门课时，这些数据就会出现多次，造成大量冗余数据。</p><p><font size="4">  <strong>分解后</strong>  </font><br></p><p>关系-1</p><table><thead><tr><th style="text-align:center">Sno</th><th style="text-align:center">Sname</th><th style="text-align:center">Sdept</th><th style="text-align:center">Mname</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">学生-1</td><td style="text-align:center">学院-1</td><td style="text-align:center">院长-1</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">学生-2</td><td style="text-align:center">学院-2</td><td style="text-align:center">院长-2</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">学生-3</td><td style="text-align:center">学院-2</td><td style="text-align:center">院长-2</td></tr></tbody></table><p>有以下函数依赖：</p><ul><li>Sno -&gt; Sname, Sdept</li><li>Sdept -&gt; Mname</li></ul><p>关系-2</p><table><thead><tr><th style="text-align:center">Sno</th><th style="text-align:center">Cname</th><th style="text-align:center">Grade</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">课程-1</td><td style="text-align:center">90</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">课程-2</td><td style="text-align:center">80</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">课程-1</td><td style="text-align:center">100</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">课程-2</td><td style="text-align:center">95</td></tr></tbody></table><p>有以下函数依赖：</p><ul><li>Sno, Cname -&gt;  Grade  完全函数依赖</li></ul><h3 id="3-第三范式-3nf"><a class="markdownIt-Anchor" href="#3-第三范式-3nf"></a> 3. 第三范式 (3NF)</h3><p>2NF + 非主属性不存在“<strong>传递函数依赖</strong>”。</p><p>关系-1 中存在以下传递函数依赖：</p><ul><li>Sno -&gt; Sdept -&gt; Mname</li></ul><p>可以把它分解成以下两个表：</p><table><thead><tr><th style="text-align:center">Sno</th><th style="text-align:center">Sname</th><th style="text-align:center">Sdept</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">学生-1</td><td style="text-align:center">学院-1</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">学生-2</td><td style="text-align:center">学院-2</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">学生-3</td><td style="text-align:center">学院-2</td></tr></tbody></table><table><thead><tr><th style="text-align:center">Sdept</th><th style="text-align:center">Mname</th></tr></thead><tbody><tr><td style="text-align:center">学院-1</td><td style="text-align:center">院长-1</td></tr><tr><td style="text-align:center">学院-2</td><td style="text-align:center">院长-2</td></tr></tbody></table><h1 id="er-图"><a class="markdownIt-Anchor" href="#er-图"></a> ER 图</h1><ul><li>一对多：带箭头的线</li><li>一对一：双向带箭头线</li><li>多对多：不带箭头的线</li></ul><p><img src="https://s2.ax1x.com/2020/02/02/1JfQVH.png" alt="erdiagram"></p><h2 id="表示出现多次的关系"><a class="markdownIt-Anchor" href="#表示出现多次的关系"></a> 表示出现多次的关系</h2><p>一个实体在联系出现几次，就要用几条线连接。</p><p>下图表示一个课程的先修关系，先修关系出现两个 Course 实体，第一个是先修课程，后一个是后修课程，因此需要用两条线来表示这种关系。</p><div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/ac929ea3-daca-40ec-9e95-4b2fa6678243.png" width="250px"> </div><br>## 表示子类<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/14389ea4-8d96-4e96-9f76-564ca3324c1e.png" width="450px"> </div><br># Indexing<ul><li><p>data can only have one actual order sorted by a order</p></li><li><p><a href="https://blog.csdn.net/jiadajing267/article/details/54581262" target="_blank" rel="noopener">https://blog.csdn.net/jiadajing267/article/details/54581262</a></p></li><li><p>Clustered : actually order data the same way as index key</p></li><li><p>non-clustered: only a list of reference</p></li><li><p>index-key  what the sort order is based on</p></li><li><p>b+树 叶子层有序数组链表+非叶子层平衡多叉树有序索引   同时支持高效等值查询和范围查询 （节点内有序可以2分搜索）</p></li><li><p>b+树与b树区别： b+树非叶节点 相当于多级索引，不含指向record的指针 （节省空间储存更多索引项）  叶子层是有序数组<strong>链表</strong></p></li><li><p>为什么适合储存：b+树节点要求半满 而且因为是多路查找树 节点内容多 相比红黑 高度压缩非常明显 树的访问查找效率和高度直接相关 b+树非常矮 大大减少IO次数 更适合文件系统和数据储存  支持bulk-loading 更适合文件系统和数据储存</p></li><li></li><li><p>InnoDB和MyISAM的区别</p><ol><li><p>InnoDB 支持事务，MyISAM 不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；</p></li><li><p>InnoDB 支持外键，而 MyISAM 不支持。对一个包含外键的 InnoDB 表转为 MYISAM 会失败；</p></li><li><p>InnoDB 是聚集索引，MyISAM 是非聚集索引。聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。</p></li><li><p>InnoDB 不保存表的具体行数，执行 select count(*) from table 时需要全表扫描。而MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快；</p></li><li><p>InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；</p></li></ol></li></ul><h1 id="nosql"><a class="markdownIt-Anchor" href="#nosql"></a> Nosql</h1><p>better suited for unstructured data</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;数据库并发控制&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#数据库并发控制&quot;&gt;&lt;/a&gt; 数据库并发控制&lt;/h1&gt;
&lt;h1 id=&quot;concurrency-control&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; hr
      
    
    </summary>
    
    
      <category term="Database" scheme="http://th2zz.github.io/tags/Database/"/>
    
  </entry>
  
  <entry>
    <title>JVM</title>
    <link href="http://th2zz.github.io/2019/10/01/java-jvm/"/>
    <id>http://th2zz.github.io/2019/10/01/java-jvm/</id>
    <published>2019-09-30T17:34:41.000Z</published>
    <updated>2020-02-08T16:17:54.966Z</updated>
    
    <content type="html"><![CDATA[<h1 id="jvm-architecture"><a class="markdownIt-Anchor" href="#jvm-architecture"></a> JVM architecture</h1><ul><li><p>Main function: load &amp; execute java application</p></li><li><p>Process: edit - javac myapp.java - java myapp (create a jvm instance)</p></li><li><img src="https://s2.ax1x.com/2020/02/08/1WkqSg.png" alt="1WkqSg.png" style="zoom:50%;"></li><li><img src="https://s2.ax1x.com/2020/02/08/1WAGnA.png" alt="1WAGnA.png" style="zoom:50%;"></li><li><p>components:</p><ul><li>class loader: input .class files output bytecode for execution engine</li><li>Runtime data areas</li><li>execution engine: executes byte code by talking to OS (may use native method calls that will be translated to machine language)</li></ul></li></ul><h3 id="1-class-loader-and-its-subsystem"><a class="markdownIt-Anchor" href="#1-class-loader-and-its-subsystem"></a> 1. Class Loader and its subsystem</h3><ul><li><img src="https://s2.ax1x.com/2020/02/08/1WA2NV.png" alt="1WA2NV.png" style="zoom:50%;"></li></ul><h4 id="load"><a class="markdownIt-Anchor" href="#load"></a> Load</h4><ul><li>Load: Load bytecode into memory<ul><li>can read from different sources: file system, socket</li><li>can have classNotFound</li><li>Three types of class loaders:<ul><li><strong>bootstrap</strong> rt.jar: <strong>load java internal classes</strong></li><li><strong>extension</strong> jre/lib/ext: <strong>load classes from additional application jar in jre/lib</strong></li><li><strong>application</strong> CLASSPATH, -cp: load classes from specified path</li></ul></li></ul></li></ul><h4 id="link"><a class="markdownIt-Anchor" href="#link"></a> Link</h4><ul><li>Link phase<ul><li><strong>verify</strong> bytecode compatibility with JVM</li><li><strong>Prepare</strong> allocate memory and init to default value for class (static) variables</li><li><strong>Resolve</strong> resolve symbolic references to other classes / constant pool to actual reference<ul><li>classDefNotFound</li></ul></li></ul></li></ul><h4 id="initialize"><a class="markdownIt-Anchor" href="#initialize"></a> Initialize</h4><ul><li>Initialize<ul><li>Execute static code block “static initializer”</li><li>actual initialization of static variables</li></ul></li></ul><h4 id="类初始化时机"><a class="markdownIt-Anchor" href="#类初始化时机"></a> 类初始化时机</h4><ol><li>主动引用<br>虚拟机规范中并没有强制约束何时进行加载，但是规范严格规定了有且只有下列五种情况必须对类进行初始化（加载、验证、准备都会随之发生）：</li></ol><ul><li>遇到 new、getstatic、putstatic、invokestatic 这四条字节码指令时，如果类没有进行过初始化，则必须先触发其初始化。最常见的生成这 4 条指令的场景是：使用 new 关键字实例化对象的时候；读取或设置一个类的静态字段（被 final 修饰、已在编译期把结果放入常量池的静态字段除外）的时候；以及调用一个类的静态方法的时候。</li><li>使用 java.lang.reflect 包的方法对类进行反射调用的时候，如果类没有进行初始化，则需要先触发其初始化。</li><li>当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。</li><li>当虚拟机启动时，用户需要指定一个要执行的主类（包含 main() 方法的那个类），虚拟机会先初始化这个主类；</li><li>当使用 JDK 1.7 的动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果为 REF_getStatic, REF_putStatic, REF_invokeStatic 的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化；</li></ul><ol start="2"><li>被动引用<br>以上 5 种场景中的行为称为对一个类进行主动引用。除此之外，所有引用类的方式都不会触发初始化，称为被动引用。被动引用的常见例子包括：</li></ol><ul><li>通过子类引用父类的静态字段，不会导致子类初始化。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">System.out.println(SubClass.value);  <span class="comment">// value 字段在 SuperClass 中定义Copy to clipboardErrorCopied</span></span><br></pre></td></tr></table></figure><ul><li>通过数组定义来引用类，不会触发此类的初始化。该过程会对数组类进行初始化，数组类是一个由虚拟机自动生成的、直接继承自 Object 的子类，其中包含了数组的属性和方法。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SuperClass[] sca = <span class="keyword">new</span> SuperClass[<span class="number">10</span>];Copy to clipboardErrorCopied</span><br></pre></td></tr></table></figure><ul><li>常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">System.out.println(ConstClass.HELLOWORLD);</span><br></pre></td></tr></table></figure><h3 id="2-runtime-data-areas"><a class="markdownIt-Anchor" href="#2-runtime-data-areas"></a> 2. Runtime data areas</h3><ul><li><strong>per thread means operations in thread local storage are generally safe.</strong></li><li><strong>per JVM means operations in shared data areas such as meatspace, Heap are not thread-safe.</strong></li></ul><h4 id="per-thread"><a class="markdownIt-Anchor" href="#per-thread"></a> Per-thread</h4><img src="https://s2.ax1x.com/2020/02/08/1WmTkn.png" alt="1WmTkn.png" style="zoom:50%;"><h5 id="pc-register"><a class="markdownIt-Anchor" href="#pc-register"></a> PC Register</h5><ul><li><strong>PC Register</strong>:  program counter register<ul><li>pointer to next instruction <strong>per thread</strong></li></ul></li></ul><h5 id="java-stacks"><a class="markdownIt-Anchor" href="#java-stacks"></a> Java Stacks</h5><ul><li><strong>Java Stacks</strong>: stack frames “chains of stack frames” corresponded to current methods execution <strong>per thread</strong><ul><li>use -Xss to mention size of stacks we want to maintain</li><li>when run out of memory, can have StackOverflowError</li></ul></li></ul><h5 id="native-method-stacks"><a class="markdownIt-Anchor" href="#native-method-stacks"></a> Native method Stacks</h5><ul><li><strong>Native method stacks</strong>: native method stacks if needed / used <strong>per thread</strong>.<ul><li>a thread with its method may call a native method such as loading a dll and run something, then the native method stack will be created, and you will get a pointer</li></ul></li></ul><h4 id="per-jvm"><a class="markdownIt-Anchor" href="#per-jvm"></a> Per-JVM</h4><img src="https://s2.ax1x.com/2020/02/08/1WZNA1.md.png" alt="1WZNA1.md.png" style="zoom:80%;"><h5 id="metaspace-method-area"><a class="markdownIt-Anchor" href="#metaspace-method-area"></a> Metaspace / Method Area</h5><ul><li><p><strong>Method Area</strong> “PermGen space 64MB”: metadata for class, available for reflection <strong>per JVM</strong>.</p><ul><li>use -XX:MaxPermSize to adjust size if we need to store a lot more classes</li><li><strong>Removed since Java 8</strong></li><li>Now is called: <strong>Metaspace</strong><ul><li>a seperate memory portion in native operating system</li><li>no limit now, can grow infinitely, but can have a limit if tuned.</li></ul></li></ul></li></ul><h5 id="heap"><a class="markdownIt-Anchor" href="#heap"></a> Heap</h5><ul><li><p><strong>Heap</strong>: stores Object data such as arrays, objects… <strong>per JVM</strong>.</p><ul><li>now has runtime constant pool and string pool</li><li>use -Xms for min size, -Xms for max size if need to tune.</li></ul></li></ul><h5 id="direct-memory"><a class="markdownIt-Anchor" href="#direct-memory"></a> Direct Memory</h5><ul><li>直接内存: 在 JDK 1.4 中新引入了 NIO 类，它可以使用 Native 函数库直接分配堆外内存，然后通过 Java 堆里的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在堆内存和堆外内存来回拷贝数据。</li></ul><h3 id="3-execution-engine"><a class="markdownIt-Anchor" href="#3-execution-engine"></a> 3. Execution Engine</h3><img src="https://s2.ax1x.com/2020/02/08/1WQdZF.png" alt="1WQdZF.png" style="zoom:50%;"><ul><li><strong>Interperter</strong>: interpret &amp; execute bytecode related native operations<ul><li>done by interacting with Java Native Method Interface (JNI)<ul><li><strong>Platform independent (native) libraries</strong>: ex. in windows JRE /bin you will see .dll files   .so on unix platform</li></ul></li></ul></li><li><strong>JIT Compiler</strong> (Just-in-time): do not interpret instructions that will be executed again and agin, compile it on the fly and keep the bytecode to avoid wasteful interpretations.</li><li><strong>Hotspot profiler</strong>: make statistics on hotspot to help JIT compiler.</li><li><strong>Garbage Collector (GC)</strong>: cleans up unused classes / objects in memory areas.</li></ul><h1 id="jvm-gc"><a class="markdownIt-Anchor" href="#jvm-gc"></a> JVM GC</h1><ul><li>Intro<ul><li>Memory leak: 内存管理不当导致的“不需要的内存没有被释放” <strong>can have Memory leak in Java</strong></li><li>In C++/C, programmers responsible for manage memory, can easily lead to memory leaks if not handled properly<ul><li>malloc() realloc() calloc() free() new and destructors</li></ul></li></ul></li><li>Basics<ul><li>Live object = reachable (referenced by someone else)</li><li>dead object = unreachable (not referenced anywhere)</li><li><strong>root node = main thread</strong></li><li>Objects e.g. (new xxx) are allocated in the heap, static members, class definitions (metadata) are stored in Permgen / Metaspace</li><li>GC is carried out by a <strong>daemon thread &quot;Garbage collector&quot;</strong></li><li><strong>we cannot force gc to happen</strong> (System.gc()😉</li><li>failed new allocations in heap  = java.lang.OutOfMemoryError</li><li>GC只处理java new出来的对象，但无法关闭其他资源，也无法处理java调用C或其他语言分配出的内存。</li><li>垃圾回收分多级，0级为全部(Full)的垃圾回收，会回收OLD段中的垃圾；1级或以上为部分垃圾回收，只会回收Young中的垃圾。</li><li>System.gc并不保证GC执行，只是向JVM发送建议，并不是命令。</li><li>finalize被调用时代表gc准备回收该对象内存</li></ul></li></ul><h3 id="directed-graph-reachability"><a class="markdownIt-Anchor" href="#directed-graph-reachability"></a> Directed Graph &amp; Reachability</h3><ul><li>.NET的垃圾回收采用引用计数，java的垃圾回收机制采取的是有向图的方式来实现，具体的说，java程序中的每个线程对象就可以看作是一个有向图的起点，有向边从栈中的引用者指向堆中的引用对象。在这个有向图中，如果一个对象和根节点之间是可达的，那么这个对象就是有效的，反之，这个对象就是可以被回收的。采取这样一种机制的优点是可以有效的避免循环引用。</li></ul><h2 id="general-gc-steps-mark-sweep-compact"><a class="markdownIt-Anchor" href="#general-gc-steps-mark-sweep-compact"></a> General GC steps: Mark Sweep Compact</h2><ul><li><strong>Mark</strong><ul><li>Starts from root node (main) walks the object graph, <strong>marks reachable object</strong> as live.</li></ul></li><li><strong>Sweep</strong>/Delete<ul><li><strong>clean unreachable objects</strong> and <strong>reclaim memory</strong></li></ul></li><li><strong>Compacting</strong><ul><li>arrange things in order: move objects around to <strong>avoid fragmentation</strong> = make memory contiguous.</li></ul></li></ul><h2 id="java-gc-generational-collectors"><a class="markdownIt-Anchor" href="#java-gc-generational-collectors"></a> Java GC: <strong>Generational collectors</strong></h2><h3 id="heap-division"><a class="markdownIt-Anchor" href="#heap-division"></a> Heap division</h3><ul><li><img src="https://s2.ax1x.com/2020/02/08/1WtC4S.png" alt="1WtC4S.png" style="zoom:80%;"></li><li>Young Generation<ul><li><strong>Eden space</strong>: new object();</li><li><strong>Survivor space 1 / 2</strong>: used to <strong>move back and force</strong> survivors that survive minor GC each turn<ul><li>can <strong>help avoid compacting step</strong></li></ul></li></ul></li><li>Old Generation<ul><li>objects that survived at least “threshold” rounds of GC</li><li>if full, iincur Major GC</li></ul></li></ul><h3 id="minor-vs-major-gc"><a class="markdownIt-Anchor" href="#minor-vs-major-gc"></a> Minor vs Major GC</h3><ul><li>Minor:<ul><li>only Young Generation</li><li>Responsive</li></ul></li><li>Major:<ul><li>run through entire heap</li><li>Long pause / latency</li><li>High throughput</li><li>Good for batch processing, jobs in database that that care about throughput &gt; latency</li></ul></li></ul><h3 id="entire-process"><a class="markdownIt-Anchor" href="#entire-process"></a> Entire process</h3><ol><li>new obj allocated in Eden</li><li>Eden full = allocation fail for new obj<ol><li>Minor GC run, mark reachable objs</li><li>move reachable obj to survivor 1</li><li>Sweep unreachables</li><li>survivors counters =  “1” means 1 rounds</li></ol></li><li>Now Eden clear, allocate new objs… some in survivor 1 became unreachable… when Eden full,<ol><li>minor GC mark and move reachables to survivor 2 <strong>the empty one</strong></li><li>move reachables in S1 to S2, <strong>increment</strong> S1 <strong>survivor counter.</strong>  By moving around this way we <strong>avoids compacting steps.</strong></li></ol></li><li><strong>Repeat</strong>: allocate in Eden, Eden full, mark and move all reachable (Eden or Sx) to the empty S, increment counters, sweep unreachables</li><li>If counter <strong>hit threshold, promote them to Old Generation</strong>.</li><li>If Old Generation is near full, Major GC runs across the entire heap MSC. very time consuming, can lead to pause.</li></ol><h2 id="gc-types-usages"><a class="markdownIt-Anchor" href="#gc-types-usages"></a> GC types &amp; Usages</h2><h3 id="basic-serial-collector"><a class="markdownIt-Anchor" href="#basic-serial-collector"></a> Basic Serial Collector</h3><ul><li>runs in single thread, used for basic applications</li></ul><h3 id="concurrent-collector-cmsc"><a class="markdownIt-Anchor" href="#concurrent-collector-cmsc"></a> Concurrent collector (CMSC)</h3><ul><li>A thread that performs GC concurrently for the app.</li><li>No waiting for the old generation.</li><li><strong>small pause only when mark / remark</strong>. Otherwise no pause “concurrent”.</li><li>use when<ul><li>more available memory</li><li>high number of CPUs</li><li>needs responsiveness</li></ul></li></ul><h3 id="parallel-collector-pmsc"><a class="markdownIt-Anchor" href="#parallel-collector-pmsc"></a> Parallel collector (PMSC)</h3><ul><li>use multiple CPU and multiple threads to do MSC (mark sweep compact).</li><li>only runs when heap is full / near full.</li><li><strong>long pause when it runs</strong>.</li><li>use when<ul><li>less available memory</li><li>less number of CPUs</li><li>needs high throughput &amp; can withstand pauses</li></ul></li></ul><h3 id="g1-collector-garbage-first-17"><a class="markdownIt-Anchor" href="#g1-collector-garbage-first-17"></a> G1 collector (Garbage - first) 1.7+</h3><ul><li>Divide heap into small regions, each of them can be eden / survivor / old</li><li><strong>Dynamically chose regions with most garbage to GC</strong><ul><li>More predictable GC pauses</li><li>Low pauses and fragmentation</li><li>Parallelism &amp; concurrency together</li><li>Better heap utilization</li></ul></li></ul><h3 id="usage"><a class="markdownIt-Anchor" href="#usage"></a> Usage</h3><p><img src="https://s2.ax1x.com/2020/02/08/1WBMZj.png" alt="1WBMZj.png"></p><ul><li>notice CMS is only in old generation.</li></ul><h2 id="memory-leaks"><a class="markdownIt-Anchor" href="#memory-leaks"></a> Memory Leaks</h2><ul><li><p>内存溢出通常发生于OLD段或Perm段垃圾回收后，仍然无内存空间容纳新的Java对象的情况。</p></li><li><p>建议将不用的对象引用设为null来避免临时的内存泄漏： 将他们标记为可清理对象。</p></li><li><p>常发生于</p><ol><li>使用生命周期较长的单位：单例模式类对象， 静态集合类形成的对象引用   <strong>暂时内存泄漏：只有相应对象/类被释放时才会gc</strong></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Static Vector v = new Vector(); </span><br><span class="line">for (int i = 1; i&lt;100; i++) </span><br><span class="line">&#123; </span><br><span class="line">    Object o = new Object(); </span><br><span class="line">    v.add(o); </span><br><span class="line">    o = null; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="2"><li><p><strong>使用了各种资源连接忘了关</strong>：数据库连接，网络连接，IO连接等，显式调用close<strong>关闭后才能被GC回收</strong></p></li><li><p>**改变哈希值，**当一个对象被存储进HashSet集合中以后，就不能修改这个对象中的那些参与计算哈希值的字段了，否则，对象修改后的哈希值与最初存储进HashSet集合中时的哈希值就不同了，在这种情况下，即使在contains方法使用该对象的当前引用作为的参数去HashSet集合中检索对象，也将返回找不到对象的结果，这也会导致无法从HashSet集合中单独删除当前对象，造成内存泄露</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">  Set&lt;Person&gt; set = <span class="keyword">new</span> HashSet&lt;Person&gt;();</span><br><span class="line">  Person p1 = <span class="keyword">new</span> Person(<span class="string">"唐僧"</span>,<span class="string">"pwd1"</span>,<span class="number">25</span>);</span><br><span class="line">  Person p2 = <span class="keyword">new</span> Person(<span class="string">"孙悟空"</span>,<span class="string">"pwd2"</span>,<span class="number">26</span>);</span><br><span class="line">  Person p3 = <span class="keyword">new</span> Person(<span class="string">"猪八戒"</span>,<span class="string">"pwd3"</span>,<span class="number">27</span>);</span><br><span class="line">  set.add(p1);</span><br><span class="line">  set.add(p2);</span><br><span class="line">  set.add(p3);</span><br><span class="line">  System.out.println(<span class="string">"总共有:"</span>+set.size()+<span class="string">" 个元素!"</span>); <span class="comment">//结果：总共有:3 个元素!</span></span><br><span class="line">  p3.setAge(<span class="number">2</span>); <span class="comment">//修改p3的年龄,此时p3元素对应的hashcode值发生改变</span></span><br><span class="line">  set.remove(p3); <span class="comment">//此时remove不掉，造成内存泄漏</span></span><br><span class="line">  set.add(p3); <span class="comment">//重新添加，居然添加成功</span></span><br><span class="line">  System.out.println(<span class="string">"总共有:"</span>+set.size()+<span class="string">" 个元素!"</span>); <span class="comment">//结果：总共有:4 个元素!</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol></li></ul><h2 id="java对象引用类别强引用软引用弱引用虚引用"><a class="markdownIt-Anchor" href="#java对象引用类别强引用软引用弱引用虚引用"></a> Java对象引用类别：强引用，软引用，弱引用，虚引用</h2><ul><li><p><strong>强引用</strong>就是平时最常用的引用，当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。</p></li><li><p>如果一个对象只具有<strong>软引用</strong>，则内存空间足够，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。</p></li><li><p>只具有<strong>弱引用</strong>的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，<strong>不管当前内存空间足够与否，都会回收它的内存</strong>。</p></li><li><p>虚引用，这种引用不常用，主要用途是关联对象，实现对对象引用关系追踪。虚引用并不会决定对象的生命周期。也无法通过虚引用得到一个对象。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。</p></li><li><p>几种引用分别位于java.lang.ref.SoftReference; java.lang.ref.WeakReference; 和 java.lang.ref.PhantomReference;</p></li></ul><h2 id="finalize"><a class="markdownIt-Anchor" href="#finalize"></a> finalize( )</h2><ul><li><p>do not use finalizer manually: finalize()</p><ul><li><p>guranteed to be called <strong>only ONCE</strong> at the end of execution when GC is done</p></li><li><p>no gurantee of gc happens</p></li><li><p>do not use finalizer on anything important</p></li><li><p>suppose we try to resurect obj by recreating an object in finalize( ), this = new xxx( );</p><ul><li>obj is recreated in memory at the end of gc = <strong>memory leak</strong></li></ul></li></ul></li><li><p>finalize被调用时代表gc准备回收该对象内存</p><ul><li>对象不可达，但是调用<strong>finalize之后</strong>又变得可达的情况存在，在finalize函数中通过this指针让其他句柄执行本身即可，但是再下次回收时不会再调用finalize，因为只能调用一次。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">protected void finalize()</span><br><span class="line">&#123;</span><br><span class="line">     main.ref=this;  // 恢复本对象，让本对象可达</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>垃圾回收器不能对用Java以外的代码编写的Class(比如JNI，C<ins>的new方法分配的内存)进行正确的回收，这时就需要覆盖默认finalize的方法来实现对这部分内存的正确释放和回收(比如C</ins>需要delete)。</li><li>finalize不能等同于C<ins>对象的destructor析构函数，C</ins>析构函数在在对象生命周期结束时会确定执行，而finalize函数的调用具有很大的不确定性。</li></ul><blockquote><p><strong>1、调用时间不确定——有资源浪费的风险</strong></p><p>如果把某些稀缺资源放到finalize()中释放，可能会导致该稀缺资源等上很久很久以后才被释放。造成资源的浪费！另外，某些类对象所携带的资源（比如某些JDBC的类）可能本身就很耗费内存，这些资源的延迟释放会造成很大的性能问题。</p><p><strong>2、可能不被调用——有资源泄漏的风险</strong></p><p>在某些情况下，finalize()压根儿不被调用。比如在JVM退出的当口，内存中那些对象的finalize函数可能就不会被调用了。</p><p>因此一些清理工作如文件的关闭，连接的关闭等不要放到finalize函数中，要在程序中单独进行管理，一般finalize只做C/C++内存的回收。<br><strong>3、对象可能在finalize函数调用时复活——有诈尸的风险</strong>　　<br>诈尸的情况比较少见，不过俺还是稍微提一下。<br>　　本来，只有当某个对象已经失效（没有引用），垃圾回收器才会调用该对象的finalize函数。但是，万一碰上某个变态的程序员，在finalize()函数内部再把对象自身的引用（也就是this）重新保存在某处，也就相当于把自己复活了（因为这个对象重新有了引用，不再处于失效状态）。这种做法是不是够变态啊</p><p>为了防止发生这种诡异的事情，垃圾回收器只能在每次调用完finalize()之后再次去检查该对象是否还处于失效状态。这无形中又增加了JVM的开销。<br>　　随便提一下。由于JDK的文档中规定了（具体见“这里”），JVM对于每一个类对象实例最多只会调用一次finalize()。所以，对于那些诈尸的实例，当它们真正死亡时，finalize()反而不会被调用了。这看起来是不是很奇怪？<br><strong>4、要记得自己做异常捕获</strong><br>　　刚才在介绍finalize()调用机制时提到，一旦有异常抛出到finalize函数外面，会被垃圾回收线程捕获并丢弃。也就是说，异常被忽略掉了（异常被忽略的危害，“这里”有提到）。为了防止这种事儿，凡是finalize()中有可能抛出异常的代码，你都得写上try catch语句，自己进行捕获。 　<br><strong>5、要小心线程安全</strong><br>　　由于调用finalize()的是垃圾回收线程，和你自己代码的线程不是同一个线程；甚至不同对象的finalize()可能会被不同的垃圾回收线程调用（比如使用“并行收集器”的时候）。所以，当你在finalize()里面访问某些数据的时候，还得时刻留心线程安全的问题。</p></blockquote></li></ul><h2 id="常量池总结"><a class="markdownIt-Anchor" href="#常量池总结"></a> 常量池总结</h2><ul><li><p>**class文件常量池 / constant pool：存静态常量,符号引用和字面量 ** 存在于.class文件中</p></li><li><p><strong>运行时常量池</strong>：类加载后，常量池中的数据会在<strong>运行时常量池</strong>中存放！这里所说的常量包括：基本类型包装类**（包装类<strong>不管理浮点型</strong>，整形只会管理-128到127）和<strong>String</strong>（也可以通过String.intern()方法可以强制将String放入常量池）**</p></li><li><p><strong>字符串常量池</strong>： HotSpot VM里，记录interned string的一个全局表叫做StringTable，它本质上就是个HashSet<string>。注意它只存储对java.lang.String实例的引用，而不存储String对象的内容</string></p></li><li><p>运行时常量池和字符串常量池都在堆中。</p></li></ul><h2 id="other-notes"><a class="markdownIt-Anchor" href="#other-notes"></a> Other Notes</h2><ol><li>Tune the heaps</li></ol><img src="https://s2.ax1x.com/2020/02/08/1WspsU.png" alt="1WspsU.png" style="zoom:80%;"><ol start="2"><li>GC logging with graphical tool if we suspect gc is the problem for performance issues.</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-verbose:gc</span><br><span class="line"></span><br><span class="line">-XX:+PrintGCDetails</span><br><span class="line"></span><br><span class="line">-Xloggc:gc.log</span><br></pre></td></tr></table></figure><ol start="3"><li>jvisualvm: visual gc plugin</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;jvm-architecture&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#jvm-architecture&quot;&gt;&lt;/a&gt; JVM architecture&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Main function: load 
      
    
    </summary>
    
    
      <category term="Java" scheme="http://th2zz.github.io/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Design Pattern</title>
    <link href="http://th2zz.github.io/2019/05/03/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    <id>http://th2zz.github.io/2019/05/03/设计模式/</id>
    <published>2019-05-03T15:34:41.000Z</published>
    <updated>2020-02-09T10:21:02.104Z</updated>
    
    <content type="html"><![CDATA[<h1 id="solid"><a class="markdownIt-Anchor" href="#solid"></a> SOLID</h1><ol><li>Single Responsiblity</li><li>Open Closed</li><li>Liskov Substitution</li><li>Inteface Segregation 专门的接口比总的接口好  更细化接口的继承！</li><li>Dependency Inversion  高层模块不应依赖底层模块 “依赖倒置” 大家都应该依赖于抽象</li></ol><h1 id="agile"><a class="markdownIt-Anchor" href="#agile"></a> Agile</h1><p>最初先做个基本的prototype，然后迭代改进 每个版本新增一个完整的功能。</p><h1 id="design-pattern"><a class="markdownIt-Anchor" href="#design-pattern"></a> Design Pattern</h1><p>设计模式的作用：</p><ol><li>设计模式以一种标准的方式供广大开发人员使用，为开发者的沟通提供了一套机制，帮助开发者更好地明白和更清晰地描述一段被给出的代码。</li><li>设计模式可以使人们更加方便简单复用成功的设计模式和结构。</li><li>设计模式可以使人们深入理解面向对象的设计思想，提高软件的开发效率，节约设计成本。</li></ol><h2 id="重点"><a class="markdownIt-Anchor" href="#重点"></a> 重点</h2><h3 id="单例模式"><a class="markdownIt-Anchor" href="#单例模式"></a> 单例模式</h3><p>Lazy initialization vs Eager initialization</p><p>违反单例模式的情况</p><ul><li><p>序列化 + 反序列化后 产生不同的对象</p><ul><li>通过重写readResolve改变反序列化行为</li></ul></li><li><p>clone 类似第二个情况</p><ul><li>建议直接抛出异常：不支持克隆</li><li>或者重写clone 返回唯一的实例</li></ul></li><li><p>反射修改constructor权限构建新实例</p></li><li><p>multiple threads access + <strong>lazy init</strong></p><ul><li><p><strong>双重检验锁</strong> + <strong>volatile</strong> 解决缓存不一致问题 + “happens-before rule”: a change to a volatile variable happens before read</p></li><li><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">volatile</span> Singleton soleInstance = <span class="keyword">null</span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">//double checked locking</span></span><br><span class="line">  <span class="keyword">if</span>(soleInstance == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">synchronized</span>(Singleton.class) &#123;</span><br><span class="line">      soleInstance = <span class="keyword">new</span> Singleton();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> soleInstance;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>只使用双重检验锁不够， 因为可能出现线程1new Singleton( )过程中 “只初始化了一半” 被中断切换到线程2 线程2会返回一个没初始化完的单例</p></li><li><p><strong>静态内部类holder</strong></p></li><li><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> Holder.INSTANCE;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Holder</span> </span>&#123;</span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">final</span> Singleton INSTANCE = <span class="keyword">new</span> Singleton();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p><strong>最高安全级别：使用枚举类</strong> addresses all the concerns above</p></li><li><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> Singleton &#123;</span><br><span class="line">  INSTANCE;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">getConfiguration</span><span class="params">()</span></span>&#123;<span class="keyword">return</span> <span class="string">"xxx"</span>;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>multiple class loaders  + eager init:</p><ul><li>no exact solution, can add check.</li></ul></li></ul><h3 id="工厂模式"><a class="markdownIt-Anchor" href="#工厂模式"></a> 工厂模式</h3><h4 id="简单工厂"><a class="markdownIt-Anchor" href="#简单工厂"></a> 简单工厂</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SimpleFactory</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Product <span class="title">createProduct</span><span class="params">(<span class="keyword">int</span> type)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (type == <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> ConcreteProduct1();</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (type == <span class="number">2</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> ConcreteProduct2();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ConcreteProduct();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="工厂方法模式"><a class="markdownIt-Anchor" href="#工厂方法模式"></a> 工厂方法模式</h4><img src="https://s2.ax1x.com/2020/02/09/1hpKqx.png" alt="1hpKqx.png" style="zoom:50%;"><p>父类决定实例生成方式，但不决定要生成的具体类，具体处理全部交给子类负责</p><p>用模版方法模式来构成生成实例的工厂</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Factory</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">abstract</span> <span class="keyword">public</span> Product <span class="title">factoryMethod</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConcreteFactory1</span> <span class="keyword">extends</span> <span class="title">Factory</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Product <span class="title">factoryMethod</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ConcreteProduct1();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConcreteFactory2</span> <span class="keyword">extends</span> <span class="title">Factory</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Product <span class="title">factoryMethod</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ConcreteProduct2();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="抽象工厂"><a class="markdownIt-Anchor" href="#抽象工厂"></a> 抽象工厂</h4><p>定义模版方法将抽象零件组装成抽象产品 = 抽象工厂</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractProductA</span> </span>&#123;&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProductA1</span> <span class="keyword">extends</span> <span class="title">AbstractProductA</span> </span>&#123;&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractFactory</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">abstract</span> AbstractProductA <span class="title">createProductA</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">abstract</span> AbstractProductB <span class="title">createProductB</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConcreteFactory1</span> <span class="keyword">extends</span> <span class="title">AbstractFactory</span> </span>&#123;</span><br><span class="line">    <span class="function">AbstractProductA <span class="title">createProductA</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="keyword">new</span> ProductA1(); &#125;</span><br><span class="line">    <span class="function">AbstractProductB <span class="title">createProductB</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="keyword">new</span> ProductB1(); &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="代理模式"><a class="markdownIt-Anchor" href="#代理模式"></a> 代理模式</h3><p>使用一个中间代理去控制对其他对象的访问 Remote Method Invocation (<em>RMI</em>) 两个JVM之间</p><h2 id="其他"><a class="markdownIt-Anchor" href="#其他"></a> 其他</h2><h4 id="模版方法模式"><a class="markdownIt-Anchor" href="#模版方法模式"></a> 模版方法模式</h4><p>将具体处理交给子类：抽象类 抽象方法 去定义“模版” 子类要实现的东西</p><h4 id="builder模式"><a class="markdownIt-Anchor" href="#builder模式"></a> Builder模式</h4><p>封装一个对象的构造过程，并允许按步骤构造。 StringBuilder</p><h4 id="prototype模式"><a class="markdownIt-Anchor" href="#prototype模式"></a> Prototype模式</h4><p>通过复制一个原型实例来创建新对象。 Object.clone( )</p><h4 id="迭代器模式"><a class="markdownIt-Anchor" href="#迭代器模式"></a> 迭代器模式</h4><p>提供一个遍历集合的东西 但不暴露集合内容</p><h4 id="适配器模式"><a class="markdownIt-Anchor" href="#适配器模式"></a> 适配器模式</h4><p>加个适配器类以便于复用现有类  Arrays.asList</p><h4 id="decorator模式"><a class="markdownIt-Anchor" href="#decorator模式"></a> Decorator模式</h4><p>添加功能与对象本体功能分离：为对象动态添加功能。 类似继承。<br>FileInputStream - BufferedInputStream<br>没有缓存区，read一次 = 发送一次IO操作；<br>有缓存区，第一次read时，会一下读取x个字节放入缓存区，然后后续的read都会从缓存中读取, 当read到缓存区末尾时，会再次读取x个字节放入缓存区</p><h1 id="mvc"><a class="markdownIt-Anchor" href="#mvc"></a> MVC</h1><p>A very popular architecture for web application.</p><p><img src="https://s2.ax1x.com/2020/02/06/16uykV.png" alt="mvc"></p><h2 id="model"><a class="markdownIt-Anchor" href="#model"></a> Model</h2><ul><li>data related logic</li><li>interact with database sql / nosql</li><li>communicates with controller</li><li>can sometimes update the view (depends on framework)</li></ul><h2 id="view"><a class="markdownIt-Anchor" href="#view"></a> View</h2><ul><li>What the end user sees (UI)</li><li>HTML/CSS</li><li>communicates with controller</li><li>can be passed dynamic values from the controller</li><li>template engines</li></ul><h2 id="controller"><a class="markdownIt-Anchor" href="#controller"></a> Controller</h2><ul><li>receives input (from browser / view, url)</li><li>processes requests (GET POST PUT DELETE)</li><li>get data from model</li><li>passes data to the view</li></ul><h1 id="aop-aspect-oriented-programming"><a class="markdownIt-Anchor" href="#aop-aspect-oriented-programming"></a> AOP Aspect Oriented Programming</h1><ul><li>Cross cutting concerns<ul><li>having a common functionality such as logging, transaction, security</li><li>do we create a new class ?</li><li>No, we create an agent</li><li>define a aspect configuration: which aspect applies to which classes - dependency injection in spring</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;solid&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#solid&quot;&gt;&lt;/a&gt; SOLID&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;Single Responsiblity&lt;/li&gt;
&lt;li&gt;Open Closed&lt;/li&gt;
&lt;li&gt;Liskov
      
    
    </summary>
    
    
      <category term="Software Engineering" scheme="http://th2zz.github.io/tags/Software-Engineering/"/>
    
  </entry>
  
  <entry>
    <title>Database Management System - Indexing</title>
    <link href="http://th2zz.github.io/2019/04/22/Database%20Management%20System%20-%20Indexing/"/>
    <id>http://th2zz.github.io/2019/04/22/Database Management System - Indexing/</id>
    <published>2019-04-21T23:49:41.000Z</published>
    <updated>2019-04-21T23:50:22.999Z</updated>
    
    <content type="html"><![CDATA[<h1 id="indexing"><a class="markdownIt-Anchor" href="#indexing"></a> Indexing</h1><h2 id="基本概念"><a class="markdownIt-Anchor" href="#基本概念"></a> 基本概念</h2><ul><li><strong>search key/搜索码/搜索键</strong>  注意这里的码的定义与主码、候 选码以及超码中的码定义不同。这里是泛指。例如如果一个文件上有多个索引，那么它就有多个搜索码。 一个文件可以有多个索引，分别基于不同的搜索码。</li><li><strong>基本的索引类型</strong>:<ul><li>顺序索引。基于值的顺序排序。</li><li>散列索引。基于将值平均分布到若干散列桶中。一个值所属的散列桶是由散列函数觉定。</li></ul></li><li><strong>顺序索引与散列索引评价metric</strong>。<ul><li>访问类型: 范围查询？等值查询？</li><li>访问时间:在查询中使用该技术找到一个特定数据项或数据项集所需的时间</li><li>插入时间: 插入一个新数据项所需的时间。该值包括找到插入这个新数据项的正确位置所需的时间，以及更新索引结构所需的时间。</li><li>删除时间:删除一个数据项所需的时间。该值包括找到待删除项所需的时间，以 及更新索引结构所需的时间。</li><li>空间开销:索引结构所占用的额外存储空间。倘若存储索引结构的额外空间大小适度，通常牺牲一定的空间代价来换取性能的提高是值得的。 通常需要在一个文件上建立多个索引。</li></ul></li></ul><h2 id="顺序索引"><a class="markdownIt-Anchor" href="#顺序索引"></a> 顺序索引</h2><ul><li><p><strong>主索引/聚集索引  primary index / clustered/clustering index</strong>：</p><ul><li>不一定是建立在主码，可以是任何码之上。</li><li>包含记录的文件与搜索码指定的顺序相同！</li></ul></li><li><p><strong>辅助索引/次级索引/非聚集索引 secondary index non-clustering index non-clustered index</strong></p><ul><li>包含记录的文件与搜索码指定的顺序不同！</li></ul></li><li><p><strong>稠密萦引 (dense index)</strong> :</p><ul><li>稠密聚集索引：文件中的每个搜索码值都有一个索引项。索引项包括搜索码值以及指向具有该搜索码值的第一条数据记录的指针。具有相同搜 索码值的其余记录顺序地存储在第一条数据记录之后，记录根据 相同的搜索码值排序。</li><li>稠密非聚集索引中，索引必须存储指向所有具有相同搜索码值的记录的指针列表。</li><li>相比稀疏索引 定位record更快</li></ul></li><li><p><strong>稀疏索引 (sparse index) : 在稀疏索引中，只为搜索码的某些值建立索引项</strong>。</p><ul><li>只有索引是聚集索引时才能使用稀疏索引。</li><li>和稠密索引一样，每个索引项也包括一个搜索码值和指向具有该搜索码值的第一条数据记录的 指针。为了定位一条记录，我们找到其最大搜索码值小于或等于所查找记录的搜索码值的索引</li><li>require less space and impose less maintainance overhead for insertions/deletions项。然后从该索引项指向的记录开始，沿着文件中的指针查找，直到找到所需记录为止。<br><img src="https://i.imgur.com/HVaboXj.png" alt=""></li></ul></li><li><p><strong>选择那种索引？</strong><br>使用稀疏还是稠密索引是一个access time and space overhead tradeoff.<br>A good compromise is to have a sparse index with one index entry per block.<br>Because the dominant cost in processing a database request is the time that it takes to bring a block from disk into main memory. Once we have brought in the block, the time to scan the entire block is negligible. we minimize block accesses while keeping the size of the index (and thus our space overhead) as small as possible.</p></li></ul><h2 id="多级索引"><a class="markdownIt-Anchor" href="#多级索引"></a> 多级索引</h2><ul><li>If the relation instead had 100,000,000 tuples, the index would instead occupy 1,000,000 blocks, or 4 gigabytes of space. Such large indices are stored as sequential files on disk.</li><li>If an index is small enough to be kept entirely in main memory, the search time to find an entry is low. However, if the index is so large that not all of it can be kept in memory, index blocks must be fetched from disk when required.<br>The search for an entry in the index then requires several disk-block reads.</li><li>The process of searching a large index may be costly.</li></ul><img src="https://i.imgur.com/56ApMIy.png" width="250"><ul><li>To locate a record, we first use binary search on the outer index to find the record for the largest search-key value less than or equal to the one that we desire. The pointer points to a block of the inner index. We scan this block until we find the record that has the largest search-key value less than or equal to the one that we desire. The pointer in this record points to the block of the file that contains the record for which we are looking.</li><li>In our example, an inner index with 10,000 blocks would require 10,000 entries in the outer index, which would occupy just 100 blocks. If we assume that the outer index is already in main memory, we would read only one index block for a search using a multilevel index, rather than the 14 blocks we read with binary search. As a result, we can perform 14 times as many index searches per second.</li><li>Indeed, we can repeat this process as many times as necessary. Indices with two or more levels are called multilevel indices. <strong>Searching for records with a multilevel index requires significantly fewer I/O operations than does searching for records by binary search</strong>.</li></ul><h2 id="索引更新"><a class="markdownIt-Anchor" href="#索引更新"></a> 索引更新</h2><p>Regardless of what form of index is used, every index must be updated whenever a record is either inserted into or deleted from the file. Further, in case a record in the file is updated, any index whose search-key attribute is affected by the update must also be updated;<br>As a result we only need to consider insertion and deletion on an index, and do not need to consider updates explicitly.</p><ul><li><p><strong>Insertion</strong>: First, the system performs a lookup using the search-key value that appears in the record to be inserted. The actions the system takes next depend on whether the index is dense or sparse:</p><ul><li>Dense indices:</li></ul><ol><li>If the search-key value does not appear in the index, the system inserts an index entry with the search-key value in the index at the appropriate position.</li><li>Otherwise the following actions are taken:<ul><li>a. If the index entry stores pointers to all records with the same search- key value, the system adds a pointer to the new record in the index entry.</li><li>b. Otherwise, the index entry stores a pointer to only the first record with the search-key value. The system then places the record being inserted after the other records with the same search-key values.</li></ul></li></ol><ul><li>Sparse indices: We assume that the index stores an entry for each block. If the system creates a new block, it inserts the first search-key value (in search-key order) appearing in the new block into the index. On the other hand, if the new record has the least search-key value in its block, the system updates the index entry pointing to the block; if not, the system makes no change to the index.</li></ul></li><li><p><strong>Deletion</strong>: To delete a record,the system first looks up the record to be deleted. The actions the system takes next depend on whether the index is dense or sparse:</p><ul><li>Dense indices:</li></ul><ol><li>If the deleted record was the only record with its particular search-key value, then the system deletes the corresponding index entry from the index.</li><li>Otherwise the following actions are taken:<ul><li>a. If the index entry stores pointers to all records with the same search- key value, the system deletes the pointer to the deleted record from the index entry.</li><li>b. Otherwise, the index entry stores a pointer to only the first record with the search-key value. In this case, if the deleted record was the first record with the search-key value, the system updates the index entry to point to the next record.</li></ul></li></ol><ul><li>Sparse indices:</li></ul><ol><li>If the index does not contain an index entry with the search-key value of the deleted record, nothing needs to be done to the index.</li><li>Otherwise the system takes the following actions:<ul><li>a. If the deleted record was the only record with its search key, the system replaces the corresponding index record with an index rec- ord for the next search-key value (in search-key order). If the next search-key value already has an index entry, the entry is deleted instead of being replaced.</li><li>b. Otherwise, if the index entry for the search-key value points to the record being deleted, the system updates the index entry to point to the next record with the same search-key value.</li></ul></li></ol></li></ul><p>Insertion and deletion algorithms for multilevel indices are a simple extension of the scheme just described. On deletion or insertion, the system updates the lowest-level index as described. As far as the second level is concerned, the lowest-level index is merely a file containing records—thus, if there is any change in the lowest-level index, the system updates the second-level index as described. The same technique applies to further levels of the index, if there are any.</p><h2 id="辅助索引"><a class="markdownIt-Anchor" href="#辅助索引"></a> 辅助索引</h2><p>A clustering/primary index may be sparse    中间空过的搜索键值可以通过顺序扫描的方式获取<br>Secondary/nonclustered indices must be dense  辅助索引若是稀疏的，就不能保证sequential order, 中间相隔的搜索键值没有办法获取<br>基于候选键的辅助索引就像稠密聚集索引，除了：索引所指的连续的记录值实际上不是顺序储存的<br>通常情况下辅助索引可以有与聚集索引不同的结构：若聚集索引的搜索键不是候选键，索引只需指向有search key value的第一个记录即可，后续记录可以顺序scan。 但对于搜索键不是候选键的非聚集索引，索引只指向第一个record with each search-key value是不够的, 剩余的相同search key value的记录可以存在于文件任何地方，因为文件是以聚集索引的搜索键排序的<br>所以，辅助索引必须包含所有记录的指针<br>我们可以使用额外一层间接的方式来实现基于非候选键的辅助索引： 辅助索引里的指针指向bucket， bucket指针（们）指向文件记录<br><img src="https://i.imgur.com/8ZYKi8C.png" alt=""></p><ul><li>索引的自动创建：<ul><li>大多数据库都会自动为主键创建索引（从而用于检测primary key constraint on new tuple insertion） 若无主键索引，当插入元组时整个relation都要读一下来确保不违反primary-key constraint.<br>我们无法储存既被聚集索引搜索键排序的又被辅助索引搜索键排序的文件！<br>因为辅助索引键的顺序和物理键的顺序不同，如果我们按辅助索引键的顺序扫描那么读取一个记录就可能需要从磁盘读一个新的block  这非常慢！</li></ul></li></ul><p>上述索引更新方法 插入删除也适用于次级索引。the actions taken are those described for dense indices storing a pointer to every record in the file. 如果一个文件有多个索引，每当文件被修改，所有索引都要更新</p><p>辅助索引可以提高 基于非主索引key的query的查询效率，但对于数据库改动会造成很大的额外开支。数据库设计者需根据估计的各种queries频率和改动来决定是否使用一些辅助索引。<br>所以除非根据估计辅助索引可以带来性能提升，不要使用辅助索引：因为辅助索引是nonclustered index whose key order is different from physical-key order in file. 不同的index所指record可能会在不同的磁盘区块上，会导致额外磁盘IO访问！ 使用不当会效果很糟糕！</p><h2 id="btree索引与哈希索引"><a class="markdownIt-Anchor" href="#btree索引与哈希索引"></a> B+tree索引与哈希索引</h2><p>index以block为单位进行index  within block用offset</p><h3 id="索引类型与基本特点"><a class="markdownIt-Anchor" href="#索引类型与基本特点"></a> <strong>索引类型与基本特点</strong></h3><ul><li>hash index  通过哈希函数生成hash address to a bucket with possible overflow chain for managing collision cheaper than B+tree if no overflow occurs Access: O(1+#overflow buckets)所以hash索引的最大的特点就是等值查询快，不能进行范围索引。</li><li>位图索引适合静态low-cardinality重复数据（属性），can be used as a compressed storage mechanism at the leaf nodes of B±trees for those values that occur very frequently.</li><li>B+tree 索引</li></ul><h3 id="motivation"><a class="markdownIt-Anchor" href="#motivation"></a> Motivation</h3><ul><li>The primary disadvantage of the index-sequential file organization is that performance degrades as the file grows. To overcome this deficiency, we can use a B±tree index.</li></ul><h3 id="btree索引特点"><a class="markdownIt-Anchor" href="#btree索引特点"></a> <strong>B+tree索引特点</strong></h3><p>普通balanced binary tree tall and thin, b tree fat and short because of the node size! b树索引同时支持范围及等值查询 log (N/2) N path length上届disk block access远远优于log2N普通平衡树 for N records in file 可以大量减少磁盘io次数</p><ul><li><strong>B tree</strong>: m-way(order m, m fanout, m-1info fields) search tree with additional constraints:  叶子层高度相同 root 2 key  其他节点至少半满ceiling(order/2)来尽量减少高度  B-tree indices are similar to B±tree indices. The primary distinction between the two approaches is that a B-tree eliminates the redundant storage of search-key values:<strong>A B-tree allows search-key values to appear only once.</strong></li><li><strong>B+ tree</strong> 更贴近多级索引，是在b树基础上, nonleaf node sparse index 减少disk page access  支持equality search 在叶子层将nonleaf节点key按中序遍历顺序拷贝下来 叶子层包含record ptrs 保持中序遍历顺序建立链表 形成dense &amp; clustered index 密集聚集索引 从而支持range search范围搜索<br>order=#ptr fields = p    /node<br>#k,v fields = p-1          /node<br>(p-1)(key_ptr_size + record_ptr_size) + p(block_ptr_size) &lt;= blocksize=512</li><li>若想要插入的位置已满  recursively按中序遍历顺序将中点上移 同时将前驱后继节点分开 始终保持节点半满的要求   删除： 左合并 右合并 来满足半满的限制  split if necessary can propagate to root.     重点：split colasce redistribution merge</li><li>bottom-up construction for empty B+tree index: 每一层每个节点使用最小值&amp;最小值指针创建下一层entry until root is created</li><li>sort and then bulk-loading(insertion)</li></ul><h3 id="btree索引的缺点"><a class="markdownIt-Anchor" href="#btree索引的缺点"></a> <strong>B+tree索引的缺点</strong></h3><ul><li><strong>long term performance degradation:</strong> b+tree索引或file organization的一个缺点是：相邻叶子节点可能存在于磁盘不同区域，最优情况是节点内指针遵循磁盘内容连续的分布，这样顺序扫描叶子结点基本等价于顺序扫描磁盘. 但随着越来越多的插入删除更新操作, sequentiality is increasingly lost, has to wait for disk seeks increasingly often. 这时候需要重建索引restore sequentiality</li><li>次级索引的更新问题: 拆分节点可能需要更新建立的次级索引，一个叶节点可能有成百上千条record 每一条都可能在不同地方 Thus a leaf-node split may require tens or even hundreds of I/O operations to update all affected secondary indices, making it a very expensive operation。解决方法： In secondary indices, in place of pointers to the indexed records, we store the values of the primary- index search-key attributes. For example, suppose we have a primary index on theattribute ID of relation instructor; then a secondary index on dept with each department name a list of instructor’s ID values of the corresponding records, instead of storing pointers to the records. locating a record using the sec- ondary index now requires two steps: First we use the secondary index to find the primary-index search-key values, and then we use the primary index to find the corresponding records. The above approach thus greatly reduces the cost of index update due to file reorganization, although it increases the cost of accessing data using a secondary index.</li></ul><h3 id="btree-file-organization"><a class="markdownIt-Anchor" href="#btree-file-organization"></a> <strong>b+tree file organization</strong></h3><p>使用b+tree的思想可以创建b+tree file organization  因为不再储存ptr而是file record leaf node size更大 需要更好的space utilization， 可以通过提高节点容量下限来解决 例如2n/3<br>B±tree file organizations可以用于储存大的对象如 SQL clobs and blobs, 这些东西通常比disk block大甚至好几个gb. 可以通过拆分成很多个小的record序列的方式使用b+tree file organization储存. The records can be sequentially numbered, or numbered by the byte offset of the record within the large object, and the record number can be used as the search key.</p><h3 id="hash-index"><a class="markdownIt-Anchor" href="#hash-index"></a> <strong>Hash Index</strong></h3><ul><li><p>can be used for (strictly speaking) <strong>secondary indices/file organization</strong>,因为</p><ul><li>A hash index is never needed as a clustering index structure, since, if a file itself is organized by hashing, there is no need for a separate hash index structure on it.</li><li>hash file organization provides the same direct access to records that indexing provides, we pretend that a file organized by hashing also has a clustering hash index on it.</li></ul></li><li><p><strong>open hashing with overflow chain for buckets</strong>: add chained bucket when need(conflict) usually used in database</p></li><li><p><strong>closed hashing</strong>: the set of buckets is fixed. Deletion is troublesome: usually used in compiler and assembler because there is only lookup and insert.</p><ul><li>choose other bucket when a bucket is full: Linear probing, quadratic probing</li><li>hash function must be choosed wisely otherwise performance degrades.</li></ul></li><li><p><strong>static hashing</strong>: linear congruential hash function with fixed #hash buckets  use overflow chain to manage contention</p><ul><li>problem: performance degrades as database grows in size if no reorganziation of hash structure is done (remap everything &amp; reconstruct corresponding buckets, time-comsuming &amp; massive)</li></ul></li><li><p><strong>extendible/dynammic hashing</strong>:</p><ul><li>copes with changes in database size by splitting and coalescing buckets as the database grows and shrinks. Does so by using extra level of directory that double its size when local depth = global depth during insertion to buckets &amp; bucket overflow (bits are not enough to distinguish the search values of the overflown bucket.). use directory of size <strong>2^k</strong> to store ptrs to hash buckets. 扩容numbering使用gray code. <strong>Directory numbering last k bits 0 - 2^k</strong></li><li>hash function: check out last k bits / mod 2^k</li><li>global depth = k: Max # of bits needed to tell which bucket an entry belongs to in the directory</li><li>local depth: # of bits used in <strong>directory numbering</strong> to determine if an entry belongs to this bucket or not</li><li>If a bucket overflow happens, the bucket is split into two. The directory may or may not double, depending on whether the local depth of the overflown bucket was equal to the global depth before split.</li><li>After resize, we do not necessarily have new buckets, match existing directory to current buckets. Meaning usually a bucket is pointed by 2 entries or more. A bucket is only pointed by 1 when bucket overflow due to insertion and this situation is after spliting.</li><li><a href="https://www.youtube.com/watch?v=TtkN2xRAgv4&amp;list=PLkZdHIQy-AeJjLbvcLO-rp1-eImyJvO2l" target="_blank" rel="noopener">https://www.youtube.com/watch?v=TtkN2xRAgv4&amp;list=PLkZdHIQy-AeJjLbvcLO-rp1-eImyJvO2l</a></li><li><a href="http://delab.csd.auth.gr/papers/ExtendibleHashing2017.pdf" target="_blank" rel="noopener">http://delab.csd.auth.gr/papers/ExtendibleHashing2017.pdf</a></li><li><a href="http://www.cs.sfu.ca/CourseCentral/354/lxwu/notes/chapter11.pdf" target="_blank" rel="noopener">http://www.cs.sfu.ca/CourseCentral/354/lxwu/notes/chapter11.pdf</a></li></ul></li></ul><h2 id="multiple-key-indices"><a class="markdownIt-Anchor" href="#multiple-key-indices"></a> Multiple key indices</h2><ul><li>in general a search key can have more than one attribute. A search key containing more than one attribute is referred to as a composite search key. The structure of the index is the same as that of any other index, the only difference being that the search key is not a single attribute, but rather is a list of attributes. The search key can be represented as a tuple of values, of the form (a1, . . . , an), where the indexed attributes are A1, . . . , An. The ordering of search-key values is the lexicographic ordering.</li><li>As an example. Consider an index on takes relation on composite search key(courseid,semester,year). This index is useful in finding all students who have registered for a particular course in a particular semester/year. An ordered index on multiple-key can be also used to answer some other queries efficiently.</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;indexing&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#indexing&quot;&gt;&lt;/a&gt; Indexing&lt;/h1&gt;
&lt;h2 id=&quot;基本概念&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#基本概念&quot;&gt;&lt;
      
    
    </summary>
    
    
      <category term="Database" scheme="http://th2zz.github.io/tags/Database/"/>
    
  </entry>
  
  <entry>
    <title>Operating System - Persistence</title>
    <link href="http://th2zz.github.io/2019/04/11/Operating%20System%20-%20Persistence/"/>
    <id>http://th2zz.github.io/2019/04/11/Operating System - Persistence/</id>
    <published>2019-04-11T01:51:23.000Z</published>
    <updated>2019-04-11T02:12:45.982Z</updated>
    
    <content type="html"><![CDATA[<h1 id="cs537-operating-system-summary-part-2-persistence"><a class="markdownIt-Anchor" href="#cs537-operating-system-summary-part-2-persistence"></a> <strong>CS537 - Operating System Summary Part 2 Persistence</strong></h1><h1 id="persistence"><a class="markdownIt-Anchor" href="#persistence"></a> Persistence</h1><h2 id="io-device-and-communication-protocol"><a class="markdownIt-Anchor" href="#io-device-and-communication-protocol"></a> IO Device and Communication Protocol</h2><h3 id="motivation"><a class="markdownIt-Anchor" href="#motivation"></a> Motivation</h3><ul><li>we want <strong>hardware</strong> that will let us plug in different devices</li><li>we want <strong>OS</strong> that can interact with different combinations of HW</li></ul><h3 id="hardware-support-for-io-device-in-system-architecture"><a class="markdownIt-Anchor" href="#hardware-support-for-io-device-in-system-architecture"></a> Hardware support for IO device in system architecture</h3><ul><li>different buses have different speed, costs, size/volume of devices that need to be connected with</li><li>high speed buses are very expensive to manufacture</li><li>Hierarchical buses are a good solution<br><img src="https://i.imgur.com/8mMkV75.png" alt=""></li><li>proprietary bus: <strong>60GB/s</strong> on a 4-core system</li><li>General I/O bus: PCI…etc. <strong>1-4GB/s</strong></li><li>Peripheral I/O bus: disk devices, SCSI, SATA, USB, <strong>100MB/s</strong></li><li>Modern system hierarcical uses more specialized chipset and p2p interconnects for better performance. Example Z270 Chipset:<br><img src="https://i.imgur.com/eXgCTWC.png" alt=""></li><li>Dedicated Graphics bus: facilitate graphics intensive applications such as gaming, interactive web browser, and photo manipulations.</li><li>Higher performance devices connected via PCIe, NVMe persistent storage.</li><li>lower performance devices connected via USB, eSATA: modern sata standard, SSD: higher speed storage</li></ul><h3 id="oss-view-to-device-a-canonical-device"><a class="markdownIt-Anchor" href="#oss-view-to-device-a-canonical-device"></a> OS’s view to Device &amp; a canonical device</h3><p><img src="https://i.imgur.com/DtbaXIO.png" alt=""></p><ul><li>Interface: where OS reads/writes to, allow system to control its operations</li><li>Internal Structure (Varies depends on different devices &amp; manufacture): microcontroller, extra memory, special-purpose chips…connection to cache/disk drives, graphics cards…</li></ul><h3 id="a-canonical-protocol-os-writing-to-device"><a class="markdownIt-Anchor" href="#a-canonical-protocol-os-writing-to-device"></a> A canonical protocol OS writing to device</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (STATUS == BUSY)</span><br><span class="line">    ; <span class="comment">// spin</span></span><br><span class="line">Write data to DATA <span class="keyword">register</span></span><br><span class="line">Write command to COMMAND <span class="keyword">register</span></span><br><span class="line"><span class="keyword">while</span> (STATUS == BUSY)</span><br><span class="line">    ; <span class="comment">// spin</span></span><br></pre></td></tr></table></figure><ul><li>Simple polling protocol works but is inefficient sometimes:</li></ul><table><thead><tr><th>CPU</th><th>sys_write A</th><th>waits</th><th>copy Data &amp; Command to A</th><th>wait(for command to be executed)</th><th>B</th></tr></thead><tbody><tr><td>DISK</td><td>busy</td><td>busy</td><td></td><td>busy</td><td></td></tr></tbody></table><ul><li>The policy of polling itself reduces CPU utilization when job processing time can be long</li><li>Using interrupt instead<br><img src="https://i.imgur.com/lgYgLBu.png" alt=""></li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (STATUS == BUSY) <span class="comment">// 1</span></span><br><span class="line">    wait <span class="keyword">for</span> interrupt;</span><br><span class="line">Write data to DATA <span class="keyword">register</span> <span class="comment">// 2</span></span><br><span class="line">Write command to COMMAND <span class="keyword">register</span> <span class="comment">// 3</span></span><br><span class="line"><span class="keyword">while</span> (STATUS == BUSY) <span class="comment">// 4</span></span><br><span class="line">    wait <span class="keyword">for</span> interrupt;</span><br></pre></td></tr></table></figure><ul><li>Interrupt improves CPU utilization in this case.</li><li>Summary: Polling/Interrupt is a tradeoff.<ul><li>Faster devices:<ul><li>better to spin(poll) and keep waiting than taking interrupt overhead</li></ul></li><li>Unknown device speed:<ul><li>Hybrid approach (spin then use interrupts)</li></ul></li><li>Better not to use interrupts when Floods of interrupts arrive:<ul><li>Example: floods of requests to the NIC device of a webserver</li><li>can lead to livelock (always handling interrupts rather than doing actual works - user level processes to service some requests)</li><li>Better to ignore interrupts and use some polling to make some progress handling them and control what is happening in the system</li></ul></li><li>Other improvement<ul><li>Interrupt coalescing (batch together several interrupts into a single one): This reduces overhead of interrupts processing</li></ul></li></ul></li></ul><h3 id="data-transfer-costs-more-efficient-data-movement-with-dma"><a class="markdownIt-Anchor" href="#data-transfer-costs-more-efficient-data-movement-with-dma"></a> Data Transfer Costs &amp; More efficient data movement with DMA</h3><ul><li>Programmed I/O:<ul><li>Programmed IO(PIO) is a method of transferring data between the CPU and a peripheral, such as a network adapter or an ATA storage device. Each data item transfer is initiated by an instruction in the program, involving the CPU for every transaction.</li><li>when using PIO to transfer a large chunk of data to a device. CPU is overburdened with trivial tasks of copying data from memory to device explicitly one word at a time. Poor CPU utilization!<br><img src="https://i.imgur.com/NxnvlJU.png" alt=""></li><li><strong>Solution</strong>: Direct Memory Access (DMA)<ul><li>CPU let a <strong>special purpose device “DMA engine”</strong> to copy data on behalf of it.</li><li>OS would program the DMA engine by telling it where the data lives inmemory, how much data to copy, and which device to send it to</li><li>CPU is thus free and OS can do something else: this improves both CPU and disk utilization, and improves the time of copying data into the <strong>data register</strong> in a device. (not command register because commands are usually very small in size).<br><img src="https://i.imgur.com/by6oZkv.png" alt=""><br><img src="https://i.imgur.com/XuKa5ys.png" alt=""></li></ul></li></ul></li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (STATUS == BUSY) <span class="comment">// 1</span></span><br><span class="line">    ;</span><br><span class="line">Write command to COMMAND <span class="keyword">register</span> <span class="comment">// no step 2 anymore, 3</span></span><br><span class="line"><span class="keyword">while</span> (STATUS == BUSY) <span class="comment">// 4</span></span><br><span class="line">    ;</span><br></pre></td></tr></table></figure><h3 id="methods-of-device-interactions"><a class="markdownIt-Anchor" href="#methods-of-device-interactions"></a> Methods of Device interactions</h3><ul><li>How OS communicates with Device? (Doesn’t matter much, both are used)<ul><li>Special instructions<ul><li>each device has a port</li><li>in/out instructions (x86) communicate with device</li></ul></li><li>Memory-Mapped I/O<ul><li>H/W maps registers into address space<ul><li>example: eax ebx cpu register</li></ul></li><li>loads/stores of mapped register sent to device<ul><li>load/store eax/ebx</li></ul></li></ul></li></ul></li></ul><h3 id="device-drivers"><a class="markdownIt-Anchor" href="#device-drivers"></a> Device Drivers</h3><p><img src="https://i.imgur.com/tYLHgXh.png" alt=""></p><ul><li>Motivation: we want to keep device general and neutral as much as possible and hide the details of device interactions with OS subsystems.</li><li>Device driver: At the lowest level, a piece of software in the OS must know in detail how a device works. Any specifics of device interaction are encapsulated within.</li><li>Significance: Writing device driver for each device helps us abstract hardware and avoid writing different OS for different H/W combinations.</li><li>Example: we want a file system that works with SSD, USB, SATA</li><li>Problem: Many devices in a system! Each has its own protocol!<ul><li>Drivers are 70% of Linux Source code and major causes of OS crashes.</li></ul></li></ul><h2 id="hard-disks"><a class="markdownIt-Anchor" href="#hard-disks"></a> Hard Disks</h2><h3 id="hard-disk-interface-and-its-view-to-osuser"><a class="markdownIt-Anchor" href="#hard-disk-interface-and-its-view-to-osuser"></a> Hard Disk Interface and its view to OS/User</h3><ul><li>The abstraction to OS/User</li></ul><table><thead><tr><th>sector 0</th></tr></thead><tbody><tr><td>sector 1</td></tr><tr><td>sector 2</td></tr><tr><td>…</td></tr></tbody></table><ul><li>Disk has a sector-addressable address space</li><li>Appears as an array of sectors</li><li>Similar to Paging, sectors are typically 512 bytes/sector</li><li>Main operations: <strong>atomic</strong> read/write to a particular sector. When power failure, can have guranntee that r/w to a sector is done or not.</li><li>Mechanical and slow</li></ul><h3 id="internals-performance-measure"><a class="markdownIt-Anchor" href="#internals-performance-measure"></a> Internals &amp; Performance Measure</h3><img src="https://i.imgur.com/eMcYqyA.png" width="250"><img src="https://i.imgur.com/zwN9ySC.png" width="250"><ul><li>Platter: a circular/disk shape entity with magnetic foam on both sides</li><li>Spindle: connected with motor to make platter spin.</li><li>RPM(Rotations Per Minutes): tells the rate of platter spinning. 10000RMP = 1 rotation/6ms<br><img src="https://i.imgur.com/b8jsBT7.png" alt=""></li><li>Surface: one side of a platter. <strong>Both sides</strong> can be written/read.</li><li>tracks: a ring of certain inner &amp; outer radius, surface is divided into different tracks. Tracks are divided into numbered sectors. Each track in above graph has 8 sectors.</li><li>cylinder: stack of tracks across platters. This idea is useful when we want to do uniform operations on the same track of each surfaces.</li><li>Arm seeks over desired tracks, platter rotates! <strong>A head per surface for R/W!</strong></li><li>Reading/Writing data from disks<br><img src="https://i.imgur.com/gP9kn0E.png" width="250"><ul><li>Rotation Delay: the waiting time for the platter to rotate till the head is positioned at right sector on the single track. On average R/2.<br><img src="https://i.imgur.com/uYVVvU7.png" width="250"></li><li>Seek Time: the waiting time for disk arm to be positioned on the right track.</li><li>Transfer Time: actual time data is either read from or written to the surface.</li><li>Overall Time to Read/write<ul><li><strong>Time_IO = seek + rotation + transfer</strong></li><li>IO rate (mainly used for comparing drives performance):<ul><li><strong>IO_rate = size to transfer / Time_IO</strong></li></ul></li></ul></li><li>Summary<ul><li>Seek cost (major): Function of cylinder distance. Not purely linear cost. Must accelerate, coast, decelerate, settle. Settling alone can take 0.5 - 2 ms. Entire seeks often takes 4 - 10 ms. <strong>Average seek = 1/3 of max seek</strong>.</li><li>Rotate cost (major): Depends on rotations per minute (RPM). 7200 RPM is common, 15000 RPM is high end. <strong>Average rotation = 1/2 of rotation delay</strong></li><li>Transfer time: pretty fast. depends on RPM and sector density. 100+ MB/s is typical for maximum transfer rate.</li></ul></li></ul></li><li>IO time calculation Example<ul><li><img src="https://i.imgur.com/Xf8oBgw.png" alt=""> Find  the time for 4KB random read for Cheetah (on average).</li><li>Solution:<ul><li>Tseek = 4ms</li><li>Trotate = 15000R/60s = 15000R/60000ms = 0.25R/ms = 4 R/ms = 2R/ms on average</li><li>Ttransfer = 4KB/(125MB/s) = 4/125 ms</li></ul></li></ul></li></ul><h3 id="workload-performance"><a class="markdownIt-Anchor" href="#workload-performance"></a> Workload Performance</h3><ul><li>Question: How does two kinds of workload affect performance?<ul><li>Sequential: reads a large number of sectors consecutively from the disk, without jumping around.</li><li>Random: issues small (e.g., 4KB) reads to random locations on the disk.</li><li>Example:<br><img src="https://i.imgur.com/WdGY378.png" alt=""><ul><li>What is throughput (IO rate) for sequential workload and random workload for Cheetah?<ul><li>Sequential: 4ms seek + 2ms rotate + 1s transfer = 1.006s This means effective throughput is almost equal to 125MB/s</li><li>Random: IO time = 6ms, 4KB/6ms &lt;&lt;&lt; 125MB/s <strong>much lower throughput than sequential access</strong>.</li></ul></li><li>Conclusion: When at all possible, transfer data to and from disks in a sequential manner. If sequential is not possible, at least think about transferring data in large chunks: the bigger, the better. If I/O is done in little random pieces, I/O performance will suffer dramatically.</li></ul></li></ul></li></ul><h3 id="some-techniques-manufacturers-use-to-improve-performance-of-disks"><a class="markdownIt-Anchor" href="#some-techniques-manufacturers-use-to-improve-performance-of-disks"></a> Some techniques manufacturers use to improve performance of disks</h3><h4 id="track-skew-skewed-layout"><a class="markdownIt-Anchor" href="#track-skew-skewed-layout"></a> Track Skew (skewed layout):</h4><ul><li>How should sector number be laid out so that we can continue reading sequentially?</li><li><img src="https://i.imgur.com/1aGAVKw.png" width="250"></li><li>Goal: We want low overhead and seamless transformation from 15 to 16 when we want to read 16 after 15.</li><li>Solution with track skew method:<ul><li>idea: <strong>overlapping seek and rotation</strong></li><li><img src="https://i.imgur.com/ravLbuh.png" width="250"></li><li>By the time the platter rotate, the head already place at position of 16.</li></ul></li></ul><h4 id="zones"><a class="markdownIt-Anchor" href="#zones"></a> Zones</h4><ul><li>Idea: outer tracks have more area available than inner tracks and thus can store more data. But we fixed sector size. So we can have <strong>non-uniform division</strong>: more sectors on outer tracks to utilize that space.</li><li><img src="https://i.imgur.com/bULnWS6.png" width="250"></li><li>Zone bit recording: call collection of sectors as zone.</li></ul><h4 id="cache-inside-drive"><a class="markdownIt-Anchor" href="#cache-inside-drive"></a> Cache inside drive</h4><ul><li>Idea: Drives may cache both reads and writes. (In addition to OS cache). Cache is not big (2MB-16MB)</li><li>Advantages of caching in drive for read:<ul><li>Store recently read sectors. Fetch it from cache.</li><li>Read-ahead: read contents of entire track into cache. predictively facilitates sequential workload.</li></ul></li><li>Advantages &amp; Disadvantages of caching in drive for write:<ul><li>Immediate reporting: CPU doesn’t need to wait for write to finish. Can acknowledge a write even before the write actually makes it to the magnetic medieum.</li><li>Danger: cached data can be lost on power failure.</li></ul></li><li>Other advantages: multiple outstanding requests<ul><li>Tagged command queuing: Disk can reorder/schedule requests for better performance.</li></ul></li></ul><h2 id="io-scheduler-scheduling-policies-and-tradeoff"><a class="markdownIt-Anchor" href="#io-scheduler-scheduling-policies-and-tradeoff"></a> IO scheduler, scheduling policies and tradeoff</h2><h3 id="motivation-2"><a class="markdownIt-Anchor" href="#motivation-2"></a> Motivation</h3><p>Given a stream of I/O requests, in what <strong>order</strong> should they be served?</p><ul><li>Example timeline: P1Read___P2Read___P3write__</li></ul><h3 id="goal"><a class="markdownIt-Anchor" href="#goal"></a> Goal</h3><ul><li>OS should dispatch requests in certain order to the shared storage device disk.</li></ul><h3 id="key-problem"><a class="markdownIt-Anchor" href="#key-problem"></a> Key Problem</h3><ul><li>Much different than CPU scheduling, Position of disk head relative to request position matters more than length of job</li><li>Example:<ul><li>FCFS/FIFO: Assume seek+rotate = 10 ms for random request, How long (roughly) does the below workload take? Requests are given in sector numbers:<ul><li>300001, 700001, 300002, 700002, 300003, 700003  = 60ms because each time we need to seek and rotate</li><li>300001, 300002, 300003, 700001, 700002, 700003  = 20ms 2 sequential pattern<br>-This shows why IO scheduling is important.</li></ul></li></ul></li></ul><h3 id="crux"><a class="markdownIt-Anchor" href="#crux"></a> Crux</h3><ul><li>we want to implement an algorithm that <strong>more closely approximates SJF by taking both seek and rotation into account</strong>.</li></ul><h3 id="sstf-shortest-seek-time-first"><a class="markdownIt-Anchor" href="#sstf-shortest-seek-time-first"></a> SSTF (Shortest SEEK Time First)</h3><ul><li>Strategy always choose request that requires <strong>least seek time</strong> (time for seeking and rotating)</li><li>Greedy algorithm (looks for local optimal)</li><li>Implementation in OS: use sector number as a substitite, order by nearest sector number first, try to issue requests that are closely together.</li><li>Disadvantages: starvation!<ul><li>ex. 30001,30002,…,70001(starved)</li><li>avoid starvation:<ul><li>Scan/Elevator Algorithm: Sweep back and forth, from one end of disk other, serving requests as pass that cylinder; Sorts by cylinder number(order of tracks); ignores rotation delays;<ul><li><img src="https://i.imgur.com/ZnJPy5F.png" width="150/"></li><li><p>Example: input 101 201 102 301 203; output_order 101 201 301 203 102 (first bit track#)</p></li><li><p>This ensure for example the request at outermost track does not starve!</p></li><li><p>This is a “Best effort” work done on OS side -&gt; logically like sorting</p></li></ul></li><li>C-SCAN(Circular Scan Algorithm): Only sweep in one direction. 1-&gt;2-&gt;3 reset 1-&gt;2-&gt;3<ul><li>This is more fair than SCAN because in pure backand-forth SCAN middle one 2 is treated more times on average than peripheral 1 and 3.</li></ul></li></ul></li></ul></li><li>Problem: SCAN and SSTF  do not actually adhere as closely to the principle of SJF as they could. In particular, they ignore rotation.</li></ul><h3 id="sptfshortest-positioning-time-first"><a class="markdownIt-Anchor" href="#sptfshortest-positioning-time-first"></a> SPTF(Shortest Positioning Time First)</h3><img src="https://i.imgur.com/gAfQtUL.png" width="200"><ul><li><p>Example: we get 2 requests one to 16, one to 8. 16 gets shorter seek but longer rotate, 8 has shorter rotation delay and longer seek. If seek time is higher than rotational delay in the disk in this example, then SSTF related policies are fine = we want to minimize seek time. So go to 16. Otherwise 8 is a better choice because we need to minimize rotation delay to have better performance.</p></li><li><p>This algorithm is complex, for simplicity, many OS only implements shortest seek time first</p></li></ul><h3 id="where-should-io-scheduler-go-os-vs-disk"><a class="markdownIt-Anchor" href="#where-should-io-scheduler-go-os-vs-disk"></a> Where should IO scheduler go? OS vs Disk.</h3><ul><li>Disk: it knows disk geometry much better but fixed by hardware, can be hard to update firmware or the scheduler.</li><li>OS: knows processes that are requesting, so we can do some weighted or fair sharing across processes. Easy to update scheduler software. Can have multiple disks scheudler and change scheduler based on workload pattern.</li><li>Typical state of the art approach: has a simple scheduler in OS side that sorts the requests based on sector locations, then has one more complex scheduler on disk side to take account of seek time and rotation time in order to minimize things further. But typically OS sends multiple requests to disk, so disk scheduelr can do some reordering between them.</li></ul><h3 id="how-busy-should-we-keep-the-disk"><a class="markdownIt-Anchor" href="#how-busy-should-we-keep-the-disk"></a> How busy should we keep the disk?</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//This is a procedure that reads from a file </span></span><br><span class="line"><span class="comment">//descriptor 1KB at a time and process that.</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reader</span><span class="params">(<span class="keyword">int</span> fd)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">char</span> buf[<span class="number">1024</span>];</span><br><span class="line">    <span class="keyword">int</span>rv;</span><br><span class="line">    <span class="keyword">while</span>((rv = read(buf,fd)) != <span class="number">0</span>) &#123;</span><br><span class="line">     assert(rv);</span><br><span class="line">     <span class="comment">// takes short time, e.g., 1ms</span></span><br><span class="line">     process(buf, rv);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><img src="https://i.imgur.com/ThnSHG3.png" width="150"><br><ul><li><p>assume 2 processes calling read() with C-SCAN,consider workload pattern: 100 101 200 201 102 103 202. This pattern is possible because there is maybe 1 ms gap between 101 and 102 so that other threads(processes) can interrupt. This is very inefficient. Should the OS always submit requests waiting present on the queue or should wait to see if other requests arrive (BE work-conserving and let disk be idle at some point so that we can make more efficient progress in the future)?</p></li><li><p>Work conservation (a trick used by linux scheduler)</p><ul><li>not work conserving/violating work-conservation: might wait for a while to merge or get a better sequence of requests</li><li>Work conserving schedulers always try to do work if there’s work to be done <strong>(always run a request if resource is free)</strong><ul><li>Sometimes, it’s better to wait instead if system anticipates another request will arrive.</li><li>example: I/O Merging. OS coalesces several IO requests into ONE. Less IO overhead.</li></ul></li></ul></li></ul><h2 id="raid"><a class="markdownIt-Anchor" href="#raid"></a> RAID</h2><h3 id="motivation-3"><a class="markdownIt-Anchor" href="#motivation-3"></a> Motivation</h3><ul><li>Typical scenario</li></ul><table><thead><tr><th>APP</th></tr></thead><tbody><tr><td>OS FS</td></tr><tr><td>Storage Devices:most file systems work with one disk</td></tr></tbody></table><ul><li><p>sometimes we need many disks for reasons:</p><ul><li>Capacity</li><li>Performance</li><li>Reliability</li></ul></li><li><p>Solution1 JBOD - Just a bunch of disks<br><img src="https://i.imgur.com/0XJooqP.png" alt=""></p><ul><li>Applications store data on different FS, ex. critical data that app decides to replicate</li><li>Downsides: need to know multiple devices, need to be rewritten, not deployable</li></ul></li><li><p>Solution2 RAID - Redundant Array of Inexpensive (Independent) Disks<br><img src="https://i.imgur.com/A4kPGQM.png" alt=""></p><ul><li>abstract multiple physical disks into one logical disk to OS</li><li>Advantages: transparent to apps, deployable Improved capacity, performance, and reliability!</li></ul></li></ul><h3 id="fault-model-of-raid"><a class="markdownIt-Anchor" href="#fault-model-of-raid"></a> Fault Model of RAID</h3><ul><li>Simple: Fail-stop model</li><li>Either works correctly or fails entirely</li><li>System can easily detect which part is not working</li><li>No silent failures, No corruptions, …etc…</li></ul><h3 id="general-strategy-of-raid-mapping"><a class="markdownIt-Anchor" href="#general-strategy-of-raid-mapping"></a> General strategy of RAID - Mapping</h3><p><img src="https://i.imgur.com/djO9nvL.png" alt=""></p><ul><li>Mapping blocks: build fast, large disk from smaller ones</li><li>Very similar to VM: go from virtual space to physical space by looking up TLB and pagetable</li><li>VM mapping is dynamic - mapping can change for example, when memory is free and is reallocated.</li><li>RAID mapping is static - translation is simple static calculation: no lookup</li></ul><h3 id="general-strategy-of-raid-redundancy"><a class="markdownIt-Anchor" href="#general-strategy-of-raid-redundancy"></a> General strategy of RAID - Redundancy</h3><p><img src="https://i.imgur.com/hrQi5Rw.png" alt=""></p><ul><li>Add even more disks for reliability</li><li>More redundancy == More fault tolerance</li><li>This is a tradeoff<ul><li>Redundancy improves reliability (and maybe performance)</li><li>Deduplication improves space efficiency</li></ul></li></ul><h3 id="raid-analysis"><a class="markdownIt-Anchor" href="#raid-analysis"></a> RAID analysis</h3><ul><li>RAID level: different levels</li><li>Workload: types of reads/writes issued by app</li><li>Metric: capacity, reliability, performance</li><li>Analysis mode: given Workload, Raid level, determine/calculate Metric</li></ul><h3 id="raid-levels"><a class="markdownIt-Anchor" href="#raid-levels"></a> RAID levels</h3><ol start="0"><li>Stripping</li><li>Mirroring</li><li>Parity</li><li>Rotated parity<br>We will not discuss 2, 3, 6 in this class.</li></ol><h3 id="workload"><a class="markdownIt-Anchor" href="#workload"></a> Workload</h3><p><img src="https://i.imgur.com/x9e3J0f.png" alt=""></p><h3 id="metrics"><a class="markdownIt-Anchor" href="#metrics"></a> Metrics</h3><p><img src="https://i.imgur.com/hfU880R.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;cs537-operating-system-summary-part-2-persistence&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#cs537-operating-system-summary-part-2-persist
      
    
    </summary>
    
    
      <category term="OS" scheme="http://th2zz.github.io/tags/OS/"/>
    
  </entry>
  
  <entry>
    <title>Computer Networking</title>
    <link href="http://th2zz.github.io/2019/04/09/Computer%20Networking/"/>
    <id>http://th2zz.github.io/2019/04/09/Computer Networking/</id>
    <published>2019-04-09T14:52:41.000Z</published>
    <updated>2019-04-09T14:52:56.760Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/network/1.png" alt=""><br><img src="/network/2.png" alt=""><br><img src="/network/3.png" alt=""><br><img src="/network/4.png" alt=""><br><img src="/network/5.png" alt=""><br><img src="/network/6.png" alt=""><br><img src="/network/7.png" alt=""><br><img src="/network/8.png" alt=""><br><img src="/network/9.png" alt=""><br><img src="/network/10.png" alt=""><br><img src="/network/11.png" alt=""><br><img src="/network/12.png" alt=""><br><img src="/network/13.png" alt=""><br><img src="/network/14.png" alt=""><br><img src="/network/15.png" alt=""><br><img src="/network/16.png" alt=""><br><img src="/network/17.png" alt=""><br><img src="/network/18.png" alt=""><br><img src="/network/19.png" alt=""><br><img src="/network/20.png" alt=""><br><img src="/network/21.png" alt=""><br><img src="/network/22.png" alt=""><br><img src="/network/23.png" alt=""><br><img src="/network/24.png" alt=""><br><img src="/network/25.png" alt=""><br><img src="/network/26.png" alt=""><br><img src="/network/27.png" alt=""><br><img src="/network/28.png" alt=""><br><img src="/network/29.png" alt=""><br><img src="/network/30.png" alt=""><br><img src="/network/31.png" alt=""><br><img src="/network/32.png" alt=""><br><img src="/network/33.png" alt=""><br><img src="/network/34.png" alt=""><br><img src="/network/35.png" alt=""><br><img src="/network/36.png" alt=""><br><img src="/network/37.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/network/1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;
&lt;img src=&quot;/network/2.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;
&lt;img src=&quot;/network/3.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;
&lt;img src=&quot;/network/4.pn
      
    
    </summary>
    
    
      <category term="Computer Network" scheme="http://th2zz.github.io/tags/Computer-Network/"/>
    
  </entry>
  
  <entry>
    <title>Operating System - Concurrency</title>
    <link href="http://th2zz.github.io/2019/04/03/Operating%20System%20-%20Concurrency/"/>
    <id>http://th2zz.github.io/2019/04/03/Operating System - Concurrency/</id>
    <published>2019-04-03T01:06:41.000Z</published>
    <updated>2019-04-11T02:01:38.530Z</updated>
    
    <content type="html"><![CDATA[<h1 id="cs537-operating-system-summary-part-2-concurrency"><a class="markdownIt-Anchor" href="#cs537-operating-system-summary-part-2-concurrency"></a> <strong>CS537 - Operating System Summary Part 2 Concurrency</strong></h1><h1 id="concurrency"><a class="markdownIt-Anchor" href="#concurrency"></a> Concurrency</h1><h2 id="thread"><a class="markdownIt-Anchor" href="#thread"></a> Thread</h2><h3 id="processes-vs-thread"><a class="markdownIt-Anchor" href="#processes-vs-thread"></a> Processes vs Thread</h3><ul><li><p>Process</p><ul><li>Example: Chrome (process per tab)</li><li>Communicate via pipe() or similar</li><li>Pros: Don’t need new abstractions; good for security</li><li>Cons:<ul><li>Cumbersome programming</li><li>High communication overheads</li><li>Expensive context switching</li></ul></li></ul></li><li><p>Thread</p><ul><li>Multiple threads of same process share an address space</li><li>Divide large task across several cooperative threads</li><li>Communicate through shared address space</li><li>Shared: page directories, page tables, code segment</li><li>Not Shared: instruction pointer, stack</li></ul></li><li><p>Multiple threads within a single process share:</p><ul><li>Process ID (PID)</li><li>Address space: Code (instructions), Most data (heap)</li><li>Open file descriptors</li><li>Current working directory</li><li>User and group id</li></ul></li><li><p>Each thread has its own</p><ul><li>Thread ID (TID)</li><li>Set of registers, including Program counter and Stack pointer</li><li>Stack for local variables and return addresses (in same address space)</li></ul></li></ul><p><img src="https://i.imgur.com/3DmuMbX.png" alt=""></p><h3 id="common-programming-models"><a class="markdownIt-Anchor" href="#common-programming-models"></a> Common Programming Models</h3><ul><li><p>Producer/consumer</p><ul><li>Multiple producer threads create data (or work) that is handled by one of the multiple consumer threads</li></ul></li><li><p>Pipeline</p><ul><li>Task is divided into series of subtasks, each of which is handled in series by a different thread</li></ul></li><li><p>Defer work with background thread</p><ul><li>One thread performs non-critical work in the background (when CPU idle)</li></ul></li></ul><h3 id="user-level-threads-many-to-one"><a class="markdownIt-Anchor" href="#user-level-threads-many-to-one"></a> User-level threads: Many-to-one</h3><ul><li><p>Idea</p><ul><li>Implemented by user-level runtime libraries</li><li>Create, schedule, synchronize threads at user-level</li><li>OS is not aware of user-level threads</li><li>OS thinks each process contains only a single thread of control</li></ul></li><li><p>Advantages</p><ul><li>Does not require OS support; Portable</li><li>Can tune scheduling policy to meet application demands</li><li>Lower overhead thread operations since no system call</li></ul></li><li><p>Disadvantages</p><ul><li>Cannot leverage multiprocessors</li><li>Entire process blocks when one thread blocks</li></ul></li></ul><img src="https://i.imgur.com/usa8UOF.png" width="50%" style="margin:auto; display: block;"><h3 id="kernel-level-threads-one-to-one"><a class="markdownIt-Anchor" href="#kernel-level-threads-one-to-one"></a> Kernel-level threads: One-to-one</h3><ul><li><p>Idea</p><ul><li>OS provides each user-level thread with a kernel thread</li><li>Each kernel thread scheduled independently</li><li>Thread operations (creation, scheduling, synchronization) performed by OS</li></ul></li><li><p>Advantages</p><ul><li>Each kernel-level thread can run in parallel on a multiprocessor</li><li>When one thread blocks, other threads from process can be scheduled</li></ul></li><li><p>Disadvantages</p><ul><li>Higher overhead for thread operations</li><li>OS must scale well with increasing number of threads</li></ul></li></ul> <img src="https://i.imgur.com/NVLmaXh.png" width="50%" style="margin:auto; display: block;"><h3 id="thread-schedule-examples"><a class="markdownIt-Anchor" href="#thread-schedule-examples"></a> Thread Schedule Examples</h3><ul><li><p>Assume <code>M[0x123]</code> = 100 initially, and we want to increment it by 1 twice</p></li><li><p>Example 1</p><table><thead><tr><th>Thread 1</th><th>Thread 2</th></tr></thead><tbody><tr><td><code>mov 0x123, %eax</code> =&gt; <code>%eax</code> = 100<br> <code>add $0x1, %eax</code> =&gt; <code>%eax</code> = 101<br> <code>mov %eax, 0x123</code> =&gt;<code>M[0x123]</code> = 101<br><br><br><br></td><td><br><br><br><code>mov 0x123, %eax</code> =&gt; <code>%eax</code> = 101<br> <code>add $0x1, %eax</code> =&gt; <code>%eax</code> = 102<br> <code>mov %eax, 0x123</code> =&gt;<code>M[0x123]</code> = 102</td></tr></tbody></table></li><li><p>Example 2</p><table><thead><tr><th>Thread 1</th><th>Thread 2</th></tr></thead><tbody><tr><td><code>mov 0x123, %eax</code> =&gt; <code>%eax</code> = 100<br><br><br><br> <code>add $0x1, %eax</code> =&gt; <code>%eax</code> = 101<br> <code>mov %eax, 0x123</code> =&gt;<code>M[0x123]</code> = 101<br></td><td><br><code>mov 0x123, %eax</code> =&gt; <code>%eax</code> = 100<br> <code>add $0x1, %eax</code> =&gt; <code>%eax</code> = 101<br> <code>mov %eax, 0x123</code> =&gt;<code>M[0x123]</code> = 101<br><br><br></td></tr></tbody></table></li></ul><h3 id="non-determinism"><a class="markdownIt-Anchor" href="#non-determinism"></a> Non-Determinism</h3><ul><li><p>Concurrency leads to non-deterministic results</p><ul><li>Different results even with same inputs</li><li>race conditions</li></ul></li><li><p>Whether bug manifests depends on CPU schedule!</p></li><li><p>How to program: imagine scheduler is malicious?!</p></li></ul><h3 id="what-do-we-want"><a class="markdownIt-Anchor" href="#what-do-we-want"></a> What do we want?</h3><ul><li><p>Want 3 instructions to execute as an uninterruptable group</p></li><li><p>That is, we want them to be atomic</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mov 0x123, %eax </span><br><span class="line">add $0x1, %eax  </span><br><span class="line">mov %eax, 0x123</span><br></pre></td></tr></table></figure></li><li><p>More general: Need mutual exclusion for critical sections</p><ul><li>if thread A is in critical section C, thread B isn’t</li><li>(okay if other threads do unrelated work)</li></ul></li></ul><h3 id="synchronization"><a class="markdownIt-Anchor" href="#synchronization"></a> Synchronization</h3><ul><li>Build higher-level synchronization primitives in OS</li><li>Operations that ensure correct ordering of instructions across threads</li><li>Use help from hardware</li></ul><h3 id="concurrency-objective"><a class="markdownIt-Anchor" href="#concurrency-objective"></a> Concurrency Objective</h3><ul><li><p>Mutual exclusion (e.g., A and B don’t run at same time)</p><ul><li>solved with locks</li></ul></li><li><p>Ordering (e.g., B runs after A does something)</p><ul><li>solved with condition variables and semaphores</li></ul></li></ul><h3 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h3><ul><li>Concurrency is needed for high performance when using multiple cores</li><li>Threads are multiple execution streams within a single process or address space (share PID and address space, own registers and stack)</li><li>Context switches within a critical section can lead to non-deterministic bugs</li></ul><h2 id="locks"><a class="markdownIt-Anchor" href="#locks"></a> Locks</h2><h3 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h3><ul><li><p>Goal: Provide mutual exclusion (mutex)</p></li><li><p>Atomic operation: No other instructions can be interleaved</p></li></ul><ol><li><p>Allocate and Initialize</p><ul><li><figure class="highlight plain"><figcaption><span>mylock </span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">    </span><br><span class="line">2. Acquire</span><br><span class="line">    - Acquire exclusion access to lock;</span><br><span class="line">    - Wait if lock is not available (some other process in critical section)</span><br><span class="line">    - Spin or block (relinquish CPU) while waiting</span><br><span class="line">    - ```Pthread_mutex_lock(&amp;mylock);</span><br></pre></td></tr></table></figure></li></ul></li><li><p>Release</p><ul><li>Release exclusive access to lock; let another process enter critical section</li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### Implementation Goals</span><br><span class="line">- Correctness</span><br><span class="line">    - Mutual exclusion</span><br><span class="line">        - Only one thread in critical section at a time</span><br><span class="line">    - Progress (deadlock-free) </span><br><span class="line">        - If several simultaneous requests, must allow one to proceed</span><br><span class="line">        - Deadlock happens when all threads are waiting for lock</span><br><span class="line"></span><br><span class="line">    - Bounded (starvation-free)</span><br><span class="line">        - Must eventually allow each waiting thread to enter</span><br><span class="line">        - The waiting time for lock is bounded</span><br><span class="line"></span><br><span class="line">- Fairness: Each thread waits for same amount of time</span><br><span class="line">- Performance: CPU is not used unnecessarily</span><br><span class="line"></span><br><span class="line">### Spin Lock with Interrupts</span><br><span class="line">- Idea</span><br><span class="line">    - Turn off interrupts for critical sections</span><br><span class="line">    - Prevent dispatcher from running another thread</span><br><span class="line">    - Code between interrupts executes atomically</span><br><span class="line"></span><br><span class="line">- Implementation code</span><br><span class="line">    ```c=</span><br><span class="line">    void acquire(lockT *l) &#123;</span><br><span class="line">        disableInterrupts();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    void release(lockT *l)  &#123; </span><br><span class="line">        enableInterrupts(); </span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></li></ul></li></ol><ul><li>Disadvantages<ul><li>Only works on uniprocessors</li><li>Process can keep control of CPU for arbitrary length</li><li>Cannot perform other necessary work</li></ul></li></ul><h3 id="spin-lock-with-load-store"><a class="markdownIt-Anchor" href="#spin-lock-with-load-store"></a> Spin Lock with Load + Store</h3><ul><li><p>Idea: uses a single <strong>shared</strong> lock variable</p></li><li><p>Implementation code</p></li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// shared variable </span></span><br><span class="line">boolean lock = <span class="literal">false</span>; </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">acquire</span><span class="params">(Boolean *lock)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">while</span> (*lock) <span class="comment">/* wait */</span> ; </span><br><span class="line">    *lock = <span class="literal">true</span>; </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">release</span><span class="params">(Boolean *lock)</span> </span>&#123; </span><br><span class="line">    *lock = <span class="literal">false</span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>Race condition</p><table><thead><tr><th>Thread 1</th><th>Thread 2</th></tr></thead><tbody><tr><td><code>while (*lock)</code><br><br><br> <code>lock = true;</code></td><td><br><code>while (*lock)</code> <br> <code>*lock = true;</code><br><br></td></tr></tbody></table><ul><li>Both threads grab lock!</li><li>Problem: Testing lock and setting lock are not atomic</li></ul></li></ul><h3 id="spin-lock-with-xchg"><a class="markdownIt-Anchor" href="#spin-lock-with-xchg"></a> Spin Lock with xchg</h3><ul><li><p>xchg: Atomic exchange or test-and-set</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// return what was pointed to by addr</span></span><br><span class="line"><span class="comment">// at the same time, store newval into addr</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">xchg</span><span class="params">(<span class="keyword">int</span> *addr, <span class="keyword">int</span> newval)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> old = *addr;</span><br><span class="line">    *addr = newval;</span><br><span class="line">    <span class="keyword">return</span> old;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Implementation code</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> flag;</span><br><span class="line">&#125; <span class="keyword">lock_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    lock-&gt;flag = <span class="number">0</span>; <span class="comment">// 0 =&gt; unlocked; 1 =&gt; locked</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">acquire</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (xchg(&amp;lock-&gt;flag, <span class="number">1</span>) == <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="comment">// spin-wait (do nothing)</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// exit loop when flag changed from 0 (unlocked) to 1 (locked)</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">release</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    lock-&gt;flag = <span class="number">0</span>; <span class="comment">// set the flag to 0 (unlocked)</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="spin-lock-with-cas"><a class="markdownIt-Anchor" href="#spin-lock-with-cas"></a> Spin Lock with CAS</h3><ul><li><p>CAS: Compare and Swap</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Atomic instruction</span></span><br><span class="line"><span class="comment">// set newval to *addr when *addr == expected</span></span><br><span class="line"><span class="comment">// return what was pointed to by addr</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">CompareAndSwap</span><span class="params">(<span class="keyword">int</span> *addr, <span class="keyword">int</span> expected, <span class="keyword">int</span> newval)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">int</span> actual = *addr; </span><br><span class="line">    <span class="keyword">if</span> (actual == expected)  </span><br><span class="line">        *addr = newval; </span><br><span class="line">    <span class="keyword">return</span> actual; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Implementation code</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">acquire</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123;  </span><br><span class="line">    <span class="keyword">while</span>(CompareAndSwap(&amp;lock-&gt;flag, <span class="number">0</span>, <span class="number">1</span>) == <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="comment">// spin-wait (do nothing)  </span></span><br><span class="line">    &#125;</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">release</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    lock-&gt;flag = <span class="number">0</span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Exercise with xchg and CAS</p><ul><li><p>Code</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> a = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span> b = xchg(&amp;a, <span class="number">2</span>);</span><br><span class="line"><span class="keyword">int</span> c = CompareAndSwap(&amp;b, <span class="number">2</span>, <span class="number">3</span>);</span><br><span class="line"><span class="keyword">int</span> d = CompareAndSwap(&amp;b, <span class="number">1</span>, <span class="number">3</span>) ;</span><br></pre></td></tr></table></figure></li><li><p>Result:</p><table><thead><tr><th>a</th><th>b</th><th>c</th><th>d</th></tr></thead><tbody><tr><td>1</td><td></td><td></td><td></td></tr><tr><td>2</td><td>1</td><td></td><td></td></tr><tr><td>2</td><td>1</td><td>1</td><td></td></tr><tr><td>2</td><td>3</td><td>1</td><td>1</td></tr></tbody></table></li></ul></li></ul><h3 id="ticket-locks"><a class="markdownIt-Anchor" href="#ticket-locks"></a> Ticket Locks</h3><ul><li><p>Basic spinlocks are unfair</p><p><img src="https://i.imgur.com/l2lu5Vn.png" alt=""></p><ul><li>Scheduler is unaware of locks/unlocks!</li></ul></li><li><p>Introduction to Ticket Locks</p><ul><li><p>Idea: reserve each thread’s turn to use a lock.</p></li><li><p>Each thread spins until their turn.</p></li><li><p>Use new atomic primitive, fetch-and-add</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">FetchAndAdd</span><span class="params">(<span class="keyword">int</span> *ptr)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">int</span> old = *ptr; </span><br><span class="line">    *ptr = old + <span class="number">1</span>; </span><br><span class="line">    <span class="keyword">return</span> old; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Acquire: Grab ticket; Spin while not thread’s ticket != turn</p></li><li><p>Release: Advance to next turn</p></li></ul></li><li><p>Example</p><table><thead><tr><th>Time</th><th>Event</th><th>ticket</th><th>Turn</th><th>Result</th></tr></thead><tbody><tr><td>1</td><td>A <code>lock()</code></td><td>0</td><td>0</td><td>A runs</td></tr><tr><td>2</td><td>B <code>lock()</code></td><td>1</td><td></td><td>B spins until turn = 1</td></tr><tr><td>3</td><td>C <code>lock()</code></td><td>2</td><td></td><td>C spins until turn = 2</td></tr><tr><td>4</td><td>A <code>unlock()</code></td><td></td><td>1</td><td>B runs</td></tr><tr><td>5</td><td>A <code>lock()</code></td><td>3</td><td></td><td>A spins until turn = 3</td></tr><tr><td>6</td><td>B <code>unlock()</code></td><td></td><td>2</td><td>C runs</td></tr><tr><td>7</td><td>C <code>unlock()</code></td><td></td><td>3</td><td>A runs</td></tr><tr><td>8</td><td>A <code>unlock()</code></td><td></td><td>4</td><td></td></tr></tbody></table></li><li><p>Ticket Lock Implementation</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span> </span><br><span class="line">    <span class="keyword">int</span> ticket; </span><br><span class="line">    <span class="keyword">int</span> turn; </span><br><span class="line">&#125; <span class="keyword">lock_t</span>; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">lock_init</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123; </span><br><span class="line">    lock-&gt;ticket = <span class="number">0</span>; </span><br><span class="line">    lock-&gt;turn = <span class="number">0</span>; </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">acquire</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> myturn = FetchAndAdd(&amp;lock-&gt;ticket);</span><br><span class="line">    <span class="keyword">while</span> (lock-&gt;turn != myturn); <span class="comment">// spin</span></span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">release</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123; </span><br><span class="line">    FetchAndAdd(&amp;lock-&gt;turn); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="ticket-lock-with-yield"><a class="markdownIt-Anchor" href="#ticket-lock-with-yield"></a> Ticket Lock with Yield</h3><ul><li><p>Spinlock Performance</p><ul><li><p>Fast when…</p><ul><li>many CPUs</li><li>locks held a short time</li><li>advantage: avoid context switch</li></ul></li><li><p>Slow when…</p><ul><li>one CPU</li><li>locks held a long time</li><li>disadvantage: spinning is wasteful</li></ul></li></ul></li><li><p>CPU Scheduler is Ignorant</p><ul><li>CPU scheduler may run B, C, D instead of A even though B, C, D are waiting for A</li></ul></li></ul><p><img src="https://i.imgur.com/Avi05dZ.png" alt=""></p><ul><li><p>Ticket Locks with Yield</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span> </span><br><span class="line">    <span class="keyword">int</span> ticket; </span><br><span class="line">    <span class="keyword">int</span> turn; </span><br><span class="line">&#125; <span class="keyword">lock_t</span>; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">lock_init</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123; </span><br><span class="line">    lock-&gt;ticket = <span class="number">0</span>; </span><br><span class="line">    lock-&gt;turn = <span class="number">0</span>; </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">acquire</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> myturn = FetchAndAdd(&amp;lock-&gt;ticket);</span><br><span class="line">    <span class="keyword">while</span> (lock-&gt;turn != myturn) &#123;</span><br><span class="line">        yield(); <span class="comment">// yield instead of spin</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">release</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123; </span><br><span class="line">    FetchAndAdd(&amp;lock-&gt;turn); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Yield instead of Spin</p></li></ul><p><img src="https://i.imgur.com/cXfmvjp.png" alt=""></p><ul><li>Time Comparison: Yield vs Spin<ul><li><p>Assumption</p><ul><li>Round robin scheduling, 10ms time slice</li><li>Process A, B, C, D, E, F, G, H, I, J in the system</li></ul></li><li><p>Timeline</p><ul><li>A: lock() … compute … unlock()</li><li>B: lock() … compute … unlock()</li><li>…</li><li>J: lock() … compute … unlock()</li><li>A: lock() … compute … unlock()</li><li>…</li></ul></li><li><p>If A’s compute is 20ms long, starting at t = 0, when does B get lock with spin ?</p><ul><li><p>110 ms</p><table><thead><tr><th>A…J</th><th>A</th><th>B</th></tr></thead><tbody><tr><td>100</td><td>10</td><td></td></tr></tbody></table></li></ul></li><li><p>If B’s compute is 30ms long, when does C get lock with spin ?</p><ul><li><p>320 ms</p><table><thead><tr><th>A…J</th><th>A…J</th><th>A…J</th><th>A</th><th>B</th><th>C</th></tr></thead><tbody><tr><td>100</td><td>100</td><td>100</td><td>10</td><td>10</td><td></td></tr></tbody></table></li></ul></li><li><p>If context switch time = 1ms, when does B get lock with yield ?</p><ul><li>29 ms</li><li><table><thead><tr><th>A</th><th>B…J</th><th>A</th><th>B</th></tr></thead><tbody><tr><td>10</td><td>9</td><td>10</td><td></td></tr></tbody></table></li></ul></li></ul></li></ul><h3 id="queue-lock"><a class="markdownIt-Anchor" href="#queue-lock"></a> Queue Lock</h3><ul><li><p>Motivation</p><ul><li><p>Time complexity of spinlock</p><ul><li>Without yield: O(threads * time_slice)</li><li>With yield: O(threads * context_switch)</li></ul></li><li><p>Even with yield, spinning is slow with high thread contention</p></li></ul></li><li><p>Idea</p><ul><li>Block and put thread on waiting queue instead of spinning</li><li>Remove waiting threads from scheduler ready queue</li><li>(e.g., <code>park()</code> and <code>unpark(threadID)</code>)</li><li>Scheduler runs any thread that is ready</li></ul></li><li><p>Example</p><ul><li><p>Assumption</p><ul><li>A &amp; C has 60ms of work</li><li>A, B, D contend for lock</li><li>C not contending</li><li>Context switch + yield takes 5ms</li></ul></li><li><p>Timeline</p><table><thead><tr><th>Time</th><th>Event</th><th>Running</th><th>Runnable</th><th>Waiting</th></tr></thead><tbody><tr><td>Initial</td><td></td><td></td><td>A, B, C, D</td><td></td></tr><tr><td>0-20</td><td>A scheduled</td><td>A</td><td>B, C, D</td><td></td></tr><tr><td>20-25</td><td>B scheduled &amp; blocked</td><td></td><td>C, D, A</td><td>B</td></tr><tr><td>25-45</td><td>C scheduled</td><td>C</td><td>D, A</td><td>B</td></tr><tr><td>45-50</td><td>D scheduled &amp; blocked</td><td></td><td>A, C</td><td>B, D</td></tr><tr><td>50-70</td><td>A scheduled</td><td>A</td><td>C</td><td>B, D</td></tr><tr><td>70-90</td><td>C scheduled</td><td>C</td><td>A</td><td>B, D</td></tr><tr><td>90-110</td><td>A scheduled &amp; finished</td><td>A</td><td>C</td><td>B, D</td></tr><tr><td>110-130</td><td>C scheduled &amp; finished</td><td>C</td><td>B</td><td>D</td></tr><tr><td>130-150</td><td>B scheduled &amp; finished</td><td>B</td><td>D</td><td></td></tr><tr><td>150-170</td><td>D scheduled &amp; finished</td><td>D</td><td></td><td></td></tr></tbody></table></li></ul></li><li><p>Incorrect Implementation</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="keyword">bool</span> lock = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">bool</span> guard = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">queue_t</span> q;</span><br><span class="line">&#125; LockT;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. Grab guard</span></span><br><span class="line"><span class="comment">// 2. If lock is held, add to queue and park</span></span><br><span class="line"><span class="comment">// 3. If lock is not held, grab the lock</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">acquire</span><span class="params">(LockT *l)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">while</span> (XCHG(&amp;l-&gt;guard, <span class="literal">true</span>)); </span><br><span class="line">    <span class="keyword">if</span> (l-&gt;lock) &#123; </span><br><span class="line">        qadd(l-&gt;q, tid); </span><br><span class="line">        l-&gt;guard = <span class="literal">false</span>; </span><br><span class="line">        park();     <span class="comment">// blocked  </span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">        l-&gt;lock = <span class="literal">true</span>; </span><br><span class="line">        l-&gt;guard = <span class="literal">false</span>; </span><br><span class="line">    &#125; </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. Grab guard</span></span><br><span class="line"><span class="comment">// 2. If queue is empty, release hte lock</span></span><br><span class="line"><span class="comment">// 3. If the queue is not empty, unpark head of queue</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">release</span><span class="params">(LockT *l)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">while</span> (XCHG(&amp;l-&gt;guard, <span class="literal">true</span>)); </span><br><span class="line">    <span class="keyword">if</span> (qempty(l-&gt;q))</span><br><span class="line">        l-&gt;lock=<span class="literal">false</span>; </span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        unpark(qremove(l-&gt;q));  </span><br><span class="line">    l-&gt;guard = <span class="literal">false</span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Questions and Answers</p><ul><li><p>Why is guard used?<br>To ensure queue operations is thread safe</p></li><li><p>Why OK to spin on guard?<br>Very shhort critical section</p></li><li><p>In release(), why not set <code>lock = false</code> when unpark?<br><code>lock == true</code> is passed from one thread to the next</p></li></ul></li><li><p>Race Condition for Previous Implementation</p><table><thead><tr><th>Thread 1 (in lock)</th><th>Thread 2 (in unlock)</th></tr></thead><tbody><tr><td>if (l-&gt;lock) {<br> qadd(l-&gt;q, tid); <br> l-&gt;guard = false; <br> <br> <br> <br><br>  park()</td><td><br> <br> <br> while (TAS(&amp;l-&gt;guard, true)); <br> if (qempty(l-&gt;q)) // false!!  <br> else unpark(qremove(l-&gt;q)); <br> l-&gt;guard = false;   <br> <br></td></tr></tbody></table></li><li><p>Correct Implementation</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    <span class="keyword">bool</span> lock = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">bool</span> guard = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">queue_t</span> q;</span><br><span class="line">&#125; LockT;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">acquire</span><span class="params">(LockT *l)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">while</span> (XCHG(&amp;l-&gt;guard, <span class="literal">true</span>)); </span><br><span class="line">    <span class="keyword">if</span> (l-&gt;lock) &#123; </span><br><span class="line">        qadd(l-&gt;q, tid); </span><br><span class="line">        setpark(pid); <span class="comment">// notify of plan</span></span><br><span class="line">        l-&gt;guard = <span class="literal">false</span>; </span><br><span class="line">        park();     <span class="comment">// blocked  </span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">        l-&gt;lock = <span class="literal">true</span>; </span><br><span class="line">        l-&gt;guard = <span class="literal">false</span>; </span><br><span class="line">    &#125; </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">release</span><span class="params">(LockT *l)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">while</span> (XCHG(&amp;l-&gt;guard, <span class="literal">true</span>)); </span><br><span class="line">    <span class="keyword">if</span> (qempty(l-&gt;q))</span><br><span class="line">        l-&gt;lock=<span class="literal">false</span>; </span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        unpark(qremove(l-&gt;q));  </span><br><span class="line">    l-&gt;guard = <span class="literal">false</span>; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Time Comparison: Yield vs Blocking</p><ul><li><p>Assumption</p><ul><li>Round robin scheduling, 10ms time slice</li><li>Process A, B, C, D, E, F, G, H, I, J in the system</li><li>Context switch takes 1ms</li></ul></li><li><p>Timeline</p><ul><li>A: lock() … compute … unlock()</li><li>B: lock() … compute … unlock()</li><li>…</li><li>J: lock() … compute … unlock()</li><li>A: lock() … compute … unlock()</li><li>…</li></ul></li><li><p>If A’s compute is 30ms long, starting at t = 0, when does B get lock with yield?</p><ul><li><p>48 ms</p><table><thead><tr><th>A</th><th>B…J</th><th>A</th><th>B…J</th><th>A</th><th>B</th></tr></thead><tbody><tr><td>10</td><td>9</td><td>10</td><td>9</td><td>10</td><td></td></tr></tbody></table></li></ul></li><li><p>If A’s compute is 30ms long, starting at t = 0, when does B get lock with blocking?</p><ul><li><p>39 ms</p><table><thead><tr><th>A</th><th>B…J</th><th>A</th><th>A</th><th>B</th></tr></thead><tbody><tr><td>10</td><td>9</td><td>10</td><td>10</td><td></td></tr></tbody></table></li></ul></li></ul></li></ul><h3 id="queue-lock-vs-spin-lock"><a class="markdownIt-Anchor" href="#queue-lock-vs-spin-lock"></a> Queue Lock vs Spin Lock</h3><ul><li><p>Each approach is better under different circumstances</p></li><li><p>Uniprocessor</p><ul><li>Waiting process is scheduled à Process holding lock isn’t</li><li>Waiting process should always relinquish processor</li><li>Associate queue of waiters with each lock (as in previous implementation)</li></ul></li><li><p>Multiprocessor</p><ul><li>Waiting process is scheduled -&gt; Process holding lock might be</li><li>Spin or block depends on how long, t, before lock is released<ul><li>Lock released quickly -&gt; Spin-wait</li><li>Lock released slowly -&gt; Block</li><li>Quick and slow are relative to context-switch cost, C</li></ul></li></ul></li></ul><h2 id="condition-variables"><a class="markdownIt-Anchor" href="#condition-variables"></a> Condition Variables</h2><h3 id="ordering"><a class="markdownIt-Anchor" href="#ordering"></a> Ordering</h3><ul><li><p>Idea: Thread A runs after Thread B does something</p></li><li><p>Example: Join</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pthread_t</span> p1, p2; </span><br><span class="line">Pthread_create(&amp;p1, <span class="literal">NULL</span>, mythread, <span class="string">"A"</span>); </span><br><span class="line">Pthread_create(&amp;p2, <span class="literal">NULL</span>, mythread, <span class="string">"B"</span>); </span><br><span class="line"><span class="comment">// join waits for the threads to finish </span></span><br><span class="line">Pthread_join(p1, <span class="literal">NULL</span>); </span><br><span class="line">Pthread_join(p2, <span class="literal">NULL</span>); </span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br></pre></td></tr></table></figure></li></ul><h3 id="condition-variables-2"><a class="markdownIt-Anchor" href="#condition-variables-2"></a> Condition Variables</h3><ul><li><p>Condition Variable: queue of waiting threads</p></li><li><p>B waits for a signal on CV before running: <code>wait(CV, …)</code></p></li><li><p>A sends signal to CV when time for B to run: <code>signal(CV, …)</code></p></li><li><p><code>wait(cond_t *cv, mutex_t *lock)</code></p><ul><li>assumes the lock is held when wait() is called</li><li>puts caller to sleep + releases the lock (atomically)</li><li>when awoken, reacquires lock before returning</li></ul></li><li><p><code>signal(cond_t *cv)</code></p><ul><li>wake a single waiting thread (if &gt;= 1 thread is waiting)</li><li>if there is no waiting thread, just return, doing nothing</li></ul></li></ul><h3 id="join-attempt-1-no-state"><a class="markdownIt-Anchor" href="#join-attempt-1-no-state"></a> Join Attempt 1: No State</h3><ul><li><p>Code</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// parent</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">thread_join</span><span class="params">()</span> </span>&#123; </span><br><span class="line">   Mutex_lock(&amp;m);     <span class="comment">// x </span></span><br><span class="line">   Cond_wait(&amp;c, &amp;m);  <span class="comment">// y </span></span><br><span class="line">   Mutex_unlock(&amp;m);   <span class="comment">// z </span></span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">// child</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">thread_exit</span><span class="params">()</span> </span>&#123; </span><br><span class="line">   Mutex_lock(&amp;m);    <span class="comment">// a </span></span><br><span class="line">   Cond_signal(&amp;c);   <span class="comment">// b </span></span><br><span class="line">   Mutex_unlock(&amp;m);  <span class="comment">// c </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Intended schedule</p><table><thead><tr><th>Time</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th></tr></thead><tbody><tr><td>Parent</td><td>x</td><td>y</td><td></td><td></td><td></td><td>z</td></tr><tr><td>Child</td><td></td><td></td><td>a</td><td>b</td><td>c</td><td></td></tr></tbody></table></li><li><p>Broken schedule</p><table><thead><tr><th>Time</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th></tr></thead><tbody><tr><td>Parent</td><td></td><td></td><td></td><td>x</td><td>y</td></tr><tr><td>Child</td><td>a</td><td>b</td><td>c</td><td></td><td></td></tr></tbody></table><ul><li>Parent is stuck because nobody will call signal</li></ul></li><li><p>Rule of Thumb 1</p><ul><li>Keep state in addition to CV’s</li><li>CV’s are used to signal threads when state changes</li><li>If state is already as needed, thread doesn’t wait for a signal!</li></ul></li></ul><h3 id="join-attempt-2-no-mutex-lock"><a class="markdownIt-Anchor" href="#join-attempt-2-no-mutex-lock"></a> Join Attempt 2: No Mutex Lock</h3><ul><li><p>Code</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// parent</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">thread_join</span><span class="params">()</span> </span>&#123; </span><br><span class="line">   Mutex_lock(&amp;m);         <span class="comment">// w</span></span><br><span class="line">   <span class="comment">// If the child process already finished executing</span></span><br><span class="line">   <span class="comment">// the parent process doesn't need to wait</span></span><br><span class="line">   <span class="keyword">if</span> (done == <span class="number">0</span>)          <span class="comment">// x</span></span><br><span class="line">       Cond_wait(&amp;c, &amp;m);  <span class="comment">// y </span></span><br><span class="line">   Mutex_unlock(&amp;m);       <span class="comment">// z </span></span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">// child</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">thread_exit</span><span class="params">()</span> </span>&#123; </span><br><span class="line">   done = <span class="number">1</span>;          <span class="comment">// a</span></span><br><span class="line">   Cond_signal(&amp;c);   <span class="comment">// b </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Intended schedule</p><table><thead><tr><th>Time</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th></tr></thead><tbody><tr><td>Parent</td><td></td><td></td><td>w</td><td>x</td><td>y</td><td>z</td></tr><tr><td>Child</td><td>a</td><td>b</td><td></td><td></td><td></td><td></td></tr></tbody></table></li><li><p>Broken schedule</p><table><thead><tr><th>Time</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th></tr></thead><tbody><tr><td>Parent</td><td>w</td><td>x</td><td></td><td></td><td>y</td></tr><tr><td>Child</td><td></td><td></td><td>a</td><td>b</td><td></td></tr></tbody></table><ul><li>Parent is stuck again</li></ul></li></ul><h3 id="join-attempt-3-state-mutex-lock"><a class="markdownIt-Anchor" href="#join-attempt-3-state-mutex-lock"></a> Join Attempt 3: State + Mutex Lock</h3><ul><li><p>Code</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// parent</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">thread_join</span><span class="params">()</span> </span>&#123; </span><br><span class="line">   Mutex_lock(&amp;m);         <span class="comment">// w</span></span><br><span class="line">   <span class="keyword">if</span> (done == <span class="number">0</span>)          <span class="comment">// x</span></span><br><span class="line">       Cond_wait(&amp;c, &amp;m);  <span class="comment">// y </span></span><br><span class="line">   Mutex_unlock(&amp;m);       <span class="comment">// z </span></span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">// child</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">thread_exit</span><span class="params">()</span> </span>&#123; </span><br><span class="line">   Mutex_lock(&amp;m);    <span class="comment">// a</span></span><br><span class="line">   done = <span class="number">1</span>;          <span class="comment">// b</span></span><br><span class="line">   Cond_signal(&amp;c);   <span class="comment">// c </span></span><br><span class="line">   Mutex_unlock(&amp;m);  <span class="comment">// d</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Schedule</p><table><thead><tr><th>Time</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th></tr></thead><tbody><tr><td>Parent</td><td>w</td><td>x</td><td>y</td><td></td><td></td><td></td><td>z</td></tr><tr><td>Child</td><td></td><td></td><td>a</td><td>b</td><td>c</td><td>d</td><td></td></tr></tbody></table></li><li><p>Rule of Thumb 2</p><ul><li>Hold mutex lock while calling wait/signal</li><li>Ensures no race between interacting with state and wait/signal</li></ul></li></ul><h3 id="producerconsumer-problem"><a class="markdownIt-Anchor" href="#producerconsumer-problem"></a> Producer/Consumer Problem</h3><ul><li>Example: UNIX pipes<ul><li><p>A pipe may have many writers and readers</p></li><li><p>Internally, there is a finite-sized buffer</p></li><li><p>Writers add data to the buffer</p><ul><li>Writers have to wait if buffer is full</li></ul></li><li><p>Readers remove data from the buffer</p><ul><li>Readers have to wait if buffer is empty</li></ul></li><li><p>Implementation:</p><ul><li>reads/writes to buffer require locking</li><li>when buffers are full, writers must wait</li><li>when buffers are empty, readers must wait</li></ul></li></ul></li></ul><pre>               Start (consumer)               |     +---------v---------------------------+------+Buf: |         |          data             |      |     +---------+---------------------------^------+                                           |                                           End (producer)</pre><ul><li>Producer/Consumer Problem<ul><li><p>Producers generate data (like pipe writers)</p></li><li><p>Consumers grab data and process it (like pipe readers)</p></li><li><p>Producer/consumer problems are frequent in systems (e.g. web servers)</p></li><li><p>General strategy use condition variables to:</p><ul><li>make producers wait when buffers are full</li><li>make consumers wait when there is nothing to consume</li></ul></li></ul></li></ul><h3 id="pc-attempt-1-one-cv"><a class="markdownIt-Anchor" href="#pc-attempt-1-one-cv"></a> P/C Attempt 1: One CV</h3><ul><li><p>Code</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. Producer grabs the lock</span></span><br><span class="line"><span class="comment">// 2. Check whether the buffer is full. If so, wait.</span></span><br><span class="line"><span class="comment">// 3. Put something to the buffer</span></span><br><span class="line"><span class="comment">// 4. Signal consumers to read</span></span><br><span class="line"><span class="comment">// 5. Release the lock</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">producer</span><span class="params">(<span class="keyword">void</span> *arg)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; loops; i++) &#123;</span><br><span class="line">    Mutex_lock(&amp;m);          <span class="comment">// p1</span></span><br><span class="line">    <span class="keyword">if</span> (numfull == max)      <span class="comment">// p2</span></span><br><span class="line">      Cond_wait(&amp;cond, &amp;m);  <span class="comment">// p3</span></span><br><span class="line">    do_fill(i);              <span class="comment">// p4</span></span><br><span class="line">    Cond_signal(&amp;cond);      <span class="comment">// p5</span></span><br><span class="line">    Mutex_unlock(&amp;m);        <span class="comment">// p6</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1. Consumer grabs the lock</span></span><br><span class="line"><span class="comment">// 2. Check whether the buffer is empty. If so, wait.</span></span><br><span class="line"><span class="comment">// 3. Get the content from buffer and remove it.</span></span><br><span class="line"><span class="comment">// 4. Signal consumers to write</span></span><br><span class="line"><span class="comment">// 5. Release the lock</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">consumer</span><span class="params">(<span class="keyword">void</span> *arg)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    Mutex_lock(&amp;m);         <span class="comment">// c1</span></span><br><span class="line">    <span class="keyword">if</span> (numfull == <span class="number">0</span>)       <span class="comment">// c2</span></span><br><span class="line">      Cond_wait(&amp;cond, &amp;m); <span class="comment">// c3</span></span><br><span class="line">    <span class="keyword">int</span> tmp = do_get();     <span class="comment">// c4</span></span><br><span class="line">    Cond_signal(&amp;cond);     <span class="comment">// c5</span></span><br><span class="line">    Mutex_unlock(&amp;m);       <span class="comment">// c6</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Broken schedule</p><table><thead><tr><th>Time</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th><th>11</th><th>12</th><th>13</th><th>14</th><th>15</th><th>16</th></tr></thead><tbody><tr><td>P</td><td></td><td></td><td></td><td></td><td></td><td></td><td>p1</td><td>p2</td><td>p4</td><td>p5</td><td>p6</td><td>p1</td><td>p2</td><td>p3</td><td></td><td></td></tr><tr><td>C1</td><td>c1</td><td>c2</td><td>c3</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>C2</td><td></td><td></td><td></td><td>c1</td><td>c2</td><td>c3</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>c4</td><td>c5</td></tr></tbody></table><ul><li>At time 16, Consumer 1 could signal Consumer 2 to wake up</li></ul></li></ul><h3 id="pc-attempt-2-two-cvs"><a class="markdownIt-Anchor" href="#pc-attempt-2-two-cvs"></a> P/C Attempt 2: Two CVs</h3><ul><li><p>How to wake the right thread? Use two condition variables</p></li><li><p>Code</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">producer</span><span class="params">(<span class="keyword">void</span> *arg)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; loops; i++) &#123;</span><br><span class="line">    Mutex_lock(&amp;m);          <span class="comment">// p1</span></span><br><span class="line">    <span class="keyword">if</span> (numfull == max)      <span class="comment">// p2</span></span><br><span class="line">      Cond_wait(&amp;empty, &amp;m); <span class="comment">// p3</span></span><br><span class="line">    do_fill(i);              <span class="comment">// p4</span></span><br><span class="line">    Cond_signal(&amp;fill);      <span class="comment">// p5</span></span><br><span class="line">    Mutex_unlock(&amp;m);        <span class="comment">// p6</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">consumer</span><span class="params">(<span class="keyword">void</span> *arg)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    Mutex_lock(&amp;m);         <span class="comment">// c1</span></span><br><span class="line">    <span class="keyword">if</span> (numfull == <span class="number">0</span>)       <span class="comment">// c2</span></span><br><span class="line">      Cond_wait(&amp;fill, &amp;m); <span class="comment">// c3</span></span><br><span class="line">    <span class="keyword">int</span> tmp = do_get();     <span class="comment">// c4</span></span><br><span class="line">    Cond_signal(&amp;empty);    <span class="comment">// c5</span></span><br><span class="line">    Mutex_unlock(&amp;m);       <span class="comment">// c6</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Broken schedule</p><table><thead><tr><th>Time</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th><th>11</th><th>12</th></tr></thead><tbody><tr><td>P</td><td></td><td></td><td></td><td>p1</td><td>p4</td><td>p5</td><td>p6</td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>C1</td><td>c1</td><td>c2</td><td>c3</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>c4</td></tr><tr><td>C2</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>c1</td><td>c4</td><td>c5</td><td>c6</td><td></td></tr></tbody></table><ul><li>At time 12, Consumer 1 wakes up but has nothing to read</li><li>Note: When <code>signal()</code> is called, the thread may not resume immediately</li></ul></li></ul><h3 id="pc-attempt-3-two-cvs-with-while"><a class="markdownIt-Anchor" href="#pc-attempt-3-two-cvs-with-while"></a> P/C Attempt 3: Two CVs with While</h3><ul><li><p>Idea: Recheck the shared variable is still in the state you want after waking up</p></li><li><p>Code</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">producer</span><span class="params">(<span class="keyword">void</span> *arg)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; loops; i++) &#123;</span><br><span class="line">    Mutex_lock(&amp;m);          <span class="comment">// p1</span></span><br><span class="line">    <span class="keyword">while</span> (numfull == max)   <span class="comment">// p2</span></span><br><span class="line">      Cond_wait(&amp;empty, &amp;m); <span class="comment">// p3</span></span><br><span class="line">    do_fill(i);              <span class="comment">// p4</span></span><br><span class="line">    Cond_signal(&amp;fill);      <span class="comment">// p5</span></span><br><span class="line">    Mutex_unlock(&amp;m);        <span class="comment">// p6</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> *<span class="title">consumer</span><span class="params">(<span class="keyword">void</span> *arg)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    Mutex_lock(&amp;m);         <span class="comment">// c1</span></span><br><span class="line">    <span class="keyword">while</span> (numfull == <span class="number">0</span>)    <span class="comment">// c2</span></span><br><span class="line">      Cond_wait(&amp;fill, &amp;m); <span class="comment">// c3</span></span><br><span class="line">    <span class="keyword">int</span> tmp = do_get();     <span class="comment">// c4</span></span><br><span class="line">    Cond_signal(&amp;empty);    <span class="comment">// c5</span></span><br><span class="line">    Mutex_unlock(&amp;m);       <span class="comment">// c6</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Rule of Thumb 3</p><ul><li>Whenever a lock is acquired, recheck assumptions about state!</li><li>Another thread could grab lock in between signal and wakeup from wait</li><li>Note that some libraries also have “spurious wakeups”</li><li>(may wake multiple waiting threads at signal or at any time)</li></ul></li></ul><h3 id="summary-2"><a class="markdownIt-Anchor" href="#summary-2"></a> Summary</h3><ul><li><p>Rules of Thumb for CVs</p><ol><li>Keep state in addition to CV’s</li><li>Always do wait/signal with lock held</li><li>Whenever thread wakes from waiting, recheck state</li></ol></li><li><p><code>wait(cond_t *cv, mutex_t *lock)</code></p><ul><li>assumes the lock is held when wait() is called</li><li>puts caller to sleep + releases the lock (atomically)</li><li>when awoken, reacquires lock before returning</li></ul></li><li><p><code>signal(cond_t *cv)</code></p><ul><li>wake a single waiting thread (if &gt;= 1 thread is waiting)</li><li>if there is no waiting thread, just return, doing nothing</li></ul></li></ul><h2 id="semaphores"><a class="markdownIt-Anchor" href="#semaphores"></a> Semaphores</h2><h3 id="introduction-2"><a class="markdownIt-Anchor" href="#introduction-2"></a> Introduction</h3><ul><li><p>Condition variables have no state (other than waiting queue)</p><ul><li>Programmer must track additional state</li></ul></li><li><p>Semaphores have state: track integer value</p><ul><li>State cannot be directly accessed by user program</li><li>But state determines behavior of semaphore operations</li></ul></li></ul><h3 id="semaphore-operations"><a class="markdownIt-Anchor" href="#semaphore-operations"></a> Semaphore Operations</h3><ul><li><p>Allocate and Initialize</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sem_init(<span class="keyword">sem_t</span> *s, <span class="keyword">int</span> initval) &#123;</span><br><span class="line">    s-&gt;value = initval; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>User cannot read or write value directly after initialization</li></ul></li><li><p>Wait or Test (sometime P() for Dutch) <code>sem_wait(sem_t*)</code></p><ul><li>Decrements sem value, Waits until value of sem is &gt;= 0</li></ul></li><li><p>Signal or Post (sometime V() for Dutch) <code>sem_post(sem_t*)</code></p><ul><li>Increment sem value, then wake a single waiter</li></ul></li></ul><h3 id="build-lock-from-semaphore"><a class="markdownIt-Anchor" href="#build-lock-from-semaphore"></a> Build Lock from Semaphore</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span>  </span><br><span class="line">    <span class="keyword">sem_t</span> sem; </span><br><span class="line">&#125; <span class="keyword">lock_t</span>; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    sem_init(&amp;lock-&gt;sem, <span class="number">1</span>);</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">acquire</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    sem_wait(&amp;lock-&gt;sem);</span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">release</span><span class="params">(<span class="keyword">lock_t</span> *lock)</span> </span>&#123; </span><br><span class="line">    sem_post(&amp;lock-&gt;sem);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="join-with-cv-vs-semaphores"><a class="markdownIt-Anchor" href="#join-with-cv-vs-semaphores"></a> Join with CV vs Semaphores</h3><ul><li><p>Join with Condition Variable</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// parent</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">thread_join</span><span class="params">()</span> </span>&#123; </span><br><span class="line">   Mutex_lock(&amp;m);         <span class="comment">// w</span></span><br><span class="line">   <span class="keyword">if</span> (done == <span class="number">0</span>)          <span class="comment">// x</span></span><br><span class="line">       Cond_wait(&amp;c, &amp;m);  <span class="comment">// y </span></span><br><span class="line">   Mutex_unlock(&amp;m);       <span class="comment">// z </span></span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">// child</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">thread_exit</span><span class="params">()</span> </span>&#123; </span><br><span class="line">   Mutex_lock(&amp;m);    <span class="comment">// a</span></span><br><span class="line">   done = <span class="number">1</span>;          <span class="comment">// b</span></span><br><span class="line">   Cond_signal(&amp;c);   <span class="comment">// c </span></span><br><span class="line">   Mutex_unlock(&amp;m);  <span class="comment">// d</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Join with Semaphores</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">sem_t</span> s;</span><br><span class="line">sem_init(&amp;s, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">thread_join</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    sem_wait(&amp;s);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">thread_exit</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    sem_post(&amp;s);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Join with Semaphores Example 1</p>  <pre>    s                       s                      s  +---+   parent wait()   +---+   child post()   +---+  | 0 |+----------------->| -1|+---------------->| 0 |  +---+                   +---+                  +---+                            ^                      ^                            |                      |                            Parent blocked         Parent resumes  </pre></li><li><p>Join with Semaphores Example 2</p>  <pre>    s                       s                      s  +---+   child post()    +---+  parent wait()   +---+  | 0 |+----------------->| 1 |+---------------->| 0 |  +---+                   +---+                  +---+  </pre></li></ul><h3 id="pc-1-producer-1-consumer-with-buffer-of-size-1"><a class="markdownIt-Anchor" href="#pc-1-producer-1-consumer-with-buffer-of-size-1"></a> P/C: 1 Producer &amp; 1 Consumer with Buffer of Size 1</h3><ul><li><p>Use 2 semaphores</p><ul><li>emptyBuffer: Initialize to 1</li><li>fullBuffer: Initialize to 0</li></ul></li><li><p>Producer</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    sem_wait(&amp;emptyBuffer);</span><br><span class="line">    Fill(&amp;buffer); </span><br><span class="line">    sem_signal(&amp;fullBuffer); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Consumer</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123; </span><br><span class="line">    sem_wait(&amp;fullBuffer);</span><br><span class="line">    Use(&amp;buffer); </span><br><span class="line">    sem_signal(&amp;emptyBuffer); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Example 1: Producer comes first</p><table><thead><tr><th>Time</th><th>Current Thread</th><th>emptyBuffer</th><th>fullBuffer</th></tr></thead><tbody><tr><td>Initial</td><td></td><td>1</td><td>0</td></tr><tr><td>1</td><td>Producer</td><td>0</td><td>1</td></tr><tr><td>2</td><td>Consumer</td><td>1</td><td>0</td></tr><tr><td>3</td><td>Producer</td><td>0</td><td>1</td></tr></tbody></table></li><li><p>Example 2: Consumer comes first</p><table><thead><tr><th>Time</th><th>Current Thread</th><th>emptyBuffer</th><th>fullBuffer</th></tr></thead><tbody><tr><td>Initial</td><td></td><td>1</td><td>0</td></tr><tr><td>1</td><td>Consumer</td><td>1</td><td>-1</td></tr><tr><td>2</td><td>Producer</td><td>0</td><td>0</td></tr><tr><td>3</td><td>Consumer</td><td>1</td><td>0</td></tr></tbody></table></li></ul><h3 id="pc-1-producer-1-consumer-with-buffer-of-size-n"><a class="markdownIt-Anchor" href="#pc-1-producer-1-consumer-with-buffer-of-size-n"></a> P/C: 1 Producer &amp; 1 Consumer with Buffer of Size N</h3><ul><li><p>Use 2 semaphores</p><ul><li>emptyBuffer: Initialize to N</li><li>fullBuffer: Initialize to 0</li></ul></li><li><p>Producer</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    sem_wait(&amp;emptyBuffer);</span><br><span class="line">    Fill(&amp;buffer[i]); </span><br><span class="line">    i = (i + <span class="number">1</span>) % N;</span><br><span class="line">    sem_signal(&amp;fullBuffer); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Consumer</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> j = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123; </span><br><span class="line">    sem_wait(&amp;fullBuffer);</span><br><span class="line">    Use(&amp;buffer[j]);</span><br><span class="line">    j = (j + <span class="number">1</span>) % N;</span><br><span class="line">    sem_signal(&amp;emptyBuffer); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Example 1: Producer comes first (N = 3)</p><table><thead><tr><th>Time</th><th>Curr</th><th>empty<br>Buffer</th><th>full<br>Buffer</th><th>Note</th></tr></thead><tbody><tr><td>Initial</td><td></td><td>3</td><td>0</td><td></td></tr><tr><td>1</td><td>P1</td><td>2</td><td>1</td><td>wait(emptyBuffer) + fill + signal(fullBuffer)</td></tr><tr><td>2</td><td>P2</td><td>1</td><td>2</td><td>wait(emptyBuffer) + fill + signal(fullBuffer)</td></tr><tr><td>3</td><td>P3</td><td>0</td><td>3</td><td>wait(emptyBuffer) + fill + signal(fullBuffer)</td></tr><tr><td>4</td><td>P4</td><td>-1</td><td>3</td><td>wait(emptyBuffer)</td></tr><tr><td>5</td><td>C1</td><td>0</td><td>2</td><td>wait(fullBuffer) + use + signal(emptyBuffer)</td></tr><tr><td>6</td><td>C2</td><td>1</td><td>1</td><td>wait(fullBuffer) + use + signal(emptyBuffer)</td></tr><tr><td>7</td><td>P4</td><td>0</td><td>2</td><td>fill + signal(fullBuffer)</td></tr></tbody></table></li><li><p>Example 2: Two consumers come first (N = 3)</p><table><thead><tr><th>Time</th><th>Curr</th><th>empty<br>Buffer</th><th>full<br>Buffer</th><th>Note</th></tr></thead><tbody><tr><td>Initial</td><td></td><td>3</td><td>0</td><td></td></tr><tr><td>1</td><td>C1</td><td>3</td><td>-1</td><td>wait(fullBuffer)</td></tr><tr><td>2</td><td>C2</td><td>3</td><td>-2</td><td>wait(fullBuffe)</td></tr><tr><td>3</td><td>P</td><td>2</td><td>-1</td><td>wait(emptyBuffer) + fill + signal(fullBuffer)</td></tr><tr><td>4</td><td>C1</td><td>3</td><td>-1</td><td>use + signal(emptyBuffer)</td></tr></tbody></table></li></ul><h3 id="pc-multiple-producers-consumers"><a class="markdownIt-Anchor" href="#pc-multiple-producers-consumers"></a> P/C: Multiple Producers &amp; Consumers</h3><ul><li><p>Requirements</p><ul><li>Each consumer must grab unique filled element</li><li>Each producer must grab unique empty element</li></ul></li><li><p>Attempt 1</p><ul><li><p>Producer</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    sem_wait(&amp;emptyBuffer); </span><br><span class="line">    my_i = findempty(&amp;buffer);</span><br><span class="line">    Fill(&amp;buffer[my_i]); </span><br><span class="line">    sem_signal(&amp;fullBuffer); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Consumer</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123; </span><br><span class="line">    sem_wait(&amp;fullBuffer); </span><br><span class="line">    my_j = findfull(&amp;buffer); </span><br><span class="line">    Use(&amp;buffer[my_j]); </span><br><span class="line">    sem_signal(&amp;emptyBuffer); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Problem: <code>findfull</code> and <code>findempty</code> are not thread-safe</p></li></ul></li><li><p>Attempt 2</p><ul><li><p>Producer</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    sem_wait(&amp;mutex);</span><br><span class="line">    sem_wait(&amp;emptyBuffer); </span><br><span class="line">    my_i = findempty(&amp;buffer);</span><br><span class="line">    Fill(&amp;buffer[my_i]); </span><br><span class="line">    sem_signal(&amp;fullBuffer); </span><br><span class="line">    sem_signal(&amp;mutex);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Consumer</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123; </span><br><span class="line">    sem_wait(&amp;mutex);</span><br><span class="line">    sem_wait(&amp;fullBuffer); </span><br><span class="line">    my_j = findfull(&amp;buffer); </span><br><span class="line">    Use(&amp;buffer[my_j]); </span><br><span class="line">    sem_signal(&amp;emptyBuffer); </span><br><span class="line">    sem_signal(&amp;mutex);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Problem</p><ul><li>Deadlock: Consumer grabs <code>mutex</code> and wait for <code>fullBuffer</code> for ever</li></ul></li></ul></li><li><p>Attempt 3</p><ul><li><p>Producer</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    sem_wait(&amp;emptyBuffer); </span><br><span class="line">    sem_wait(&amp;mutex);</span><br><span class="line">    my_i = findempty(&amp;buffer);</span><br><span class="line">    Fill(&amp;buffer[my_i]); </span><br><span class="line">    sem_signal(&amp;mutex);</span><br><span class="line">    sem_signal(&amp;fullBuffer); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Consumer</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123; </span><br><span class="line">    sem_wait(&amp;fullBuffer); </span><br><span class="line">    sem_wait(&amp;mutex);</span><br><span class="line">    my_j = findfull(&amp;buffer); </span><br><span class="line">    Use(&amp;buffer[my_j]); </span><br><span class="line">    sem_signal(&amp;mutex);</span><br><span class="line">    sem_signal(&amp;emptyBuffer); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Problem</p><ul><li>Cannot operate on multiple buffer locations at the same time</li><li>Only 1 thread at at time can be using of filling different buffers</li></ul></li></ul></li><li><p>Attempt 4</p><ul><li><p>Producer</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    sem_wait(&amp;emptyBuffer); </span><br><span class="line">    sem_wait(&amp;mutex);</span><br><span class="line">    my_i = findempty(&amp;buffer);</span><br><span class="line">    sem_signal(&amp;mutex);</span><br><span class="line">    Fill(&amp;buffer[my_i]); </span><br><span class="line">    sem_signal(&amp;fullBuffer); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Consumer</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123; </span><br><span class="line">    sem_wait(&amp;fullBuffer); </span><br><span class="line">    sem_wait(&amp;mutex);</span><br><span class="line">    my_j = findfull(&amp;buffer); </span><br><span class="line">    sem_signal(&amp;mutex);</span><br><span class="line">    Use(&amp;buffer[my_j]); </span><br><span class="line">    sem_signal(&amp;emptyBuffer); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Advantage</p><ul><li>Works and increases concurrency; only finding a buffer is protected by mutex;</li><li>Filling or Using different buffers can proceed concurrently</li></ul></li></ul></li></ul><h3 id="readerwriter-locks"><a class="markdownIt-Anchor" href="#readerwriter-locks"></a> Reader/Writer Locks</h3><ul><li><p>Idea</p><ul><li>Let multiple reader threads grab lock (shared)</li><li>Only one writer thread can grab lock (exclusive)<ul><li>No reader threads</li><li>No other writer threads</li></ul></li></ul></li><li><p>Code</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct_rwlock_t</span> &#123;</span><br><span class="line">    <span class="keyword">sem_t</span> lock; <span class="comment">// reader lock</span></span><br><span class="line">    <span class="keyword">sem_t</span> writelock;</span><br><span class="line">    <span class="keyword">int</span> readers; <span class="comment">// number of readers</span></span><br><span class="line">&#125; <span class="keyword">rwlock_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">rwlock_init</span><span class="params">(<span class="keyword">rwlock_t</span>*rw)</span> </span>&#123;</span><br><span class="line">    rw-&gt;readers = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// initialize locks to 1, similar to mutex initialization</span></span><br><span class="line">    sem_init(&amp;rw-&gt;lock, <span class="number">1</span>);  </span><br><span class="line">    sem_init(&amp;rw-&gt;writelock, <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">rwlock_acquire_readlock</span><span class="params">(<span class="keyword">rwlock_t</span> *rw)</span> </span>&#123; </span><br><span class="line">    sem_wait(&amp;rw-&gt;lock); </span><br><span class="line">    rw-&gt;readers++; </span><br><span class="line">    <span class="keyword">if</span> (rw-&gt;readers == <span class="number">1</span>) </span><br><span class="line">        sem_wait(&amp;rw-&gt;writelock); </span><br><span class="line">    sem_post(&amp;rw-&gt;lock); </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">rwlock_release_readlock</span><span class="params">(<span class="keyword">rwlock_t</span> *rw)</span> </span>&#123; </span><br><span class="line">    sem_wait(&amp;rw-&gt;lock); </span><br><span class="line">    rw-&gt;readers--; </span><br><span class="line">    <span class="keyword">if</span> (rw-&gt;readers == <span class="number">0</span>) </span><br><span class="line">        sem_post(&amp;rw-&gt;writelock); <span class="comment">// let other writes</span></span><br><span class="line">    sem_post(&amp;rw-&gt;lock); </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">rwlock_acquire_writelock</span><span class="params">(<span class="keyword">rwlock_t</span> *rw)</span> </span>&#123;</span><br><span class="line">    sem_wait(&amp;rw-&gt;writelock); </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">rwlock_release_writelock</span><span class="params">(<span class="keyword">rwlock_t</span> *rw)</span> </span>&#123;</span><br><span class="line">    sem_post(&amp;rw-&gt;writelock); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Example</p><table><thead><tr><th>Time</th><th>Current Action</th><th>lock</th><th>writelock</th><th>readers</th></tr></thead><tbody><tr><td>Initial</td><td></td><td>1</td><td>1</td><td>0</td></tr><tr><td>1</td><td>T1 <code>acquire_readlock</code></td><td><del>0</del> 1</td><td>0</td><td>1</td></tr><tr><td>2</td><td>T2 <code>acquire_readlock</code></td><td><del>0</del> 1</td><td>0</td><td>2</td></tr><tr><td>3</td><td>T3 <code>acquire_writelock</code></td><td>1</td><td>-1</td><td>2</td></tr><tr><td>4</td><td>T1 <code>release_readlock</code></td><td><del>0</del> 1</td><td>-1</td><td>1</td></tr><tr><td>5</td><td>T2 <code>release_readlock</code></td><td><del>0</del> 1</td><td>0</td><td>0</td></tr></tbody></table></li><li><p>Quiz 1</p><ul><li>T1: <code>acquire_readlock()</code> =&gt; T1 running</li><li>T2: <code>acquire_readlock()</code> =&gt; T2 running</li><li>T3: <code>acquire_writelock()</code> =&gt; T3 blocked, waiting for write lock</li></ul></li><li><p>Quiz 2</p><ul><li>T6: <code>acquire_writelock()</code> =&gt; T6 running</li><li>T4: <code>acquire_readlock()</code> =&gt; T4 blocked, waiting for read lock</li><li>T5: <code>acquire_readlock()</code> =&gt; T5 blocked, waiting for read lock</li></ul></li></ul><h3 id="build-zemaphore-from-lock-and-cv"><a class="markdownIt-Anchor" href="#build-zemaphore-from-lock-and-cv"></a> Build Zemaphore from Lock and CV</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span> </span><br><span class="line">    <span class="keyword">int</span> value; </span><br><span class="line">    <span class="keyword">cond_t</span> cond; </span><br><span class="line">    <span class="keyword">lock_t</span> lock; </span><br><span class="line">&#125; <span class="keyword">zem_t</span>; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">zem_init</span><span class="params">(<span class="keyword">zem_t</span> *z, <span class="keyword">int</span> value)</span> </span>&#123; </span><br><span class="line">    z-&gt;value = value; </span><br><span class="line">    cond_init(&amp;z-&gt;cond); </span><br><span class="line">    lock_init(&amp;z-&gt;lock); </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">// waits until value &gt; 0. and decrement</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">zem_wait</span><span class="params">(<span class="keyword">zem_t</span> *z)</span> </span>&#123; </span><br><span class="line">    lock_acquire(&amp;z-&gt;lock); </span><br><span class="line">    z-&gt;value--; </span><br><span class="line">    <span class="keyword">while</span> (z-&gt;value &lt; <span class="number">0</span>) </span><br><span class="line">       cond_wait(&amp;z-&gt;cond); </span><br><span class="line">    lock_release(&amp;z-&gt;lock); </span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">// increment value, then wake a single waiter</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">zem_post</span><span class="params">(<span class="keyword">zem_t</span> *z)</span> </span>&#123; </span><br><span class="line">    lock_acquire(&amp;z-&gt;lock); </span><br><span class="line">    z-&gt;value++; </span><br><span class="line">    cond_signal(&amp;z-&gt;cond); </span><br><span class="line">    lock_release(&amp;z-&gt;lock); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="summary-3"><a class="markdownIt-Anchor" href="#summary-3"></a> Summary</h3><ul><li><p>Semaphores are equivalent to locks + condition variables</p><ul><li>Can be used for both mutual exclusion and ordering</li></ul></li><li><p>Semaphores contain state</p><ul><li>How they are initialized depends on how they will be used</li><li>Init to 0: Join (1 thread must arrive first, then other)</li><li>Init to N: Number of available resources</li></ul></li><li><p>sem_wait(): Decrement and waits until value &gt;= 0</p></li><li><p>sem_post(): Increment value, then wake a single waiter (atomic)</p></li><li><p>Can use semaphores in producer/consumer and for reader/writer locks</p></li></ul><h2 id="concurrency-bugs"><a class="markdownIt-Anchor" href="#concurrency-bugs"></a> Concurrency Bugs</h2><h3 id="concurrency-in-medicine-therac-25-1980s"><a class="markdownIt-Anchor" href="#concurrency-in-medicine-therac-25-1980s"></a> Concurrency in Medicine: Therac-25 (1980’s)</h3><blockquote><p>“The accidents occurred when the high-power electron beam was activated<br>instead of the intended low power beam, and without the beam spreader plate<br>rotated into place. Previous models had hardware interlocks in place to prevent<br>this, but Therac-25 had removed them, depending instead on software interlocks<br>for safety. The software interlock could fail due to a race condition.”</p></blockquote><blockquote><p>“…in three cases, the injured patients later died.”</p></blockquote><ul><li>Source: <a href="http://en.wikipedia.org/wiki/Therac-25" target="_blank" rel="noopener">http://en.wikipedia.org/wiki/Therac-25</a></li></ul><h3 id="concurrency-study"><a class="markdownIt-Anchor" href="#concurrency-study"></a> Concurrency Study</h3><p><img src="https://i.imgur.com/77XWz8c.png" alt=""></p><h3 id="atomicity-mysql"><a class="markdownIt-Anchor" href="#atomicity-mysql"></a> Atomicity: MySQL</h3><ul><li><p>Bug</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Thread 1</span></span><br><span class="line"><span class="keyword">if</span> (thd-&gt;proc_info) &#123;</span><br><span class="line"> <span class="comment">// ...</span></span><br><span class="line"> <span class="built_in">fputs</span>(thd-&gt;proc_info, <span class="comment">/*...*/</span>);</span><br><span class="line"> <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Thread 2</span></span><br><span class="line">thd-&gt;proc_info = <span class="literal">NULL</span>;</span><br></pre></td></tr></table></figure></li><li><p>Fix</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Thread 1</span></span><br><span class="line">pthread_mutex_lock(&amp;lock);</span><br><span class="line"><span class="keyword">if</span> (thd-&gt;proc_info) &#123;</span><br><span class="line"> <span class="comment">// ...</span></span><br><span class="line"> <span class="built_in">fputs</span>(thd-&gt;proc_info, <span class="comment">/*...*/</span>);</span><br><span class="line"> <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line">pthread_mutex_unlock(&amp;lock);</span><br></pre></td></tr></table></figure>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Thread 2</span></span><br><span class="line">pthread_mutex_lock(&amp;lock);</span><br><span class="line">thd-&gt;proc_info = <span class="literal">NULL</span>;</span><br><span class="line">pthread_mutex_unlock(&amp;lock);</span><br></pre></td></tr></table></figure></li></ul><h3 id="ordering-mozilla"><a class="markdownIt-Anchor" href="#ordering-mozilla"></a> Ordering: Mozilla</h3><ul><li><p>Bug</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Thread 1</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123; </span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    mThread = PR_CreateThread(mMain, <span class="comment">/*...*/</span>);</span><br><span class="line">    <span class="comment">// ...  </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Thread 2</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">mMain</span><span class="params">(<span class="comment">/*...*/</span>)</span> </span>&#123; </span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    mState = mThread-&gt;State;</span><br><span class="line">    <span class="comment">// ...  </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Fix</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Thread 1</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123; </span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    mThread = PR_CreateThread(mMain, <span class="comment">/*...*/</span>);</span><br><span class="line"></span><br><span class="line">    pthread_mutex_lock(&amp;mtLock);</span><br><span class="line">    mtInit = <span class="number">1</span>; </span><br><span class="line">    pthread_cond_signal(&amp;mtCond);</span><br><span class="line">    pthread_mutex_unlock(&amp;mtLock);  </span><br><span class="line">    <span class="comment">// ...  </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Thread 2</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">mMain</span><span class="params">(<span class="comment">/*...*/</span>)</span> </span>&#123; </span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    pthread_mutex_lock(&amp;mtLock);</span><br><span class="line">    <span class="keyword">while</span> (mtInit == <span class="number">0</span>) </span><br><span class="line">        pthread_cond_wait(&amp;mtCond, &amp;mtLock);  </span><br><span class="line">    pthread_mutex_unlock(&amp;mtLock);  </span><br><span class="line">    </span><br><span class="line">    mState = mThread-&gt;State;</span><br><span class="line">    <span class="comment">// ...  </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="deadlock"><a class="markdownIt-Anchor" href="#deadlock"></a> Deadlock</h2><h3 id="definition"><a class="markdownIt-Anchor" href="#definition"></a> Definition</h3><ul><li>No progress can be made because two or more threads are waiting for the other to take some action and thus neither ever does</li></ul><h3 id="example-1-circular-dependency"><a class="markdownIt-Anchor" href="#example-1-circular-dependency"></a> Example 1: Circular Dependency</h3><ul><li><p>Code</p><table><thead><tr><th>Thread 1</th><th>Thread 2</th></tr></thead><tbody><tr><td><code>lock(&amp;A);</code> <br><br><br> <code>lock(&amp;B);</code>(blocked)</td><td><br><code>lock(&amp;B);</code>  <br> <code>lock(&amp;A);</code>(blocked)<br><br></td></tr></tbody></table></li><li><p>Circular Dependency<br><img src="https://i.imgur.com/dG4Krbd.png" alt=""></p><ul><li>Cycle in dependency graph -&gt; possible to have deadlock</li></ul></li><li><p>Fix Deadlock Code</p><table><thead><tr><th>Thread 1</th><th>Thread 2</th></tr></thead><tbody><tr><td><code>lock(&amp;A);</code> <br><code>lock(&amp;B);</code></td><td><code>lock(&amp;A);</code>  <br> <code>lock(&amp;A);</code></td></tr></tbody></table></li><li><p>Non-Circular Dependency<br><img src="https://i.imgur.com/yJibQZG.png" alt=""></p></li></ul><h3 id="example-2-encapsulation"><a class="markdownIt-Anchor" href="#example-2-encapsulation"></a> Example 2: Encapsulation</h3><ul><li>Code</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set_t</span> *set_intersection(<span class="keyword">set_t</span> *s1, <span class="keyword">set_t</span> *s2) &#123;</span><br><span class="line">   <span class="keyword">set_t</span> *rv = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(*rv));</span><br><span class="line">   mutex_lock(&amp;s1-&gt;lock);</span><br><span class="line">   mutex_lock(&amp;s2-&gt;lock);</span><br><span class="line">   <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; s1-&gt;len; i++) &#123;</span><br><span class="line">      <span class="keyword">if</span> (set_contains(s2, s1-&gt;items[i])) &#123;</span><br><span class="line">         set_add(rv, s1-&gt;items[i]);</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   mutex_unlock(&amp;s2-&gt;lock);</span><br><span class="line">   mutex_unlock(&amp;s1-&gt;lock);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>Deadlock scenario</p><ul><li>Thread 1: <code>rv = set_intersection(setA, setB);</code></li><li>Thread 2: <code>rv = set_intersection(setB, setA);</code></li></ul></li><li><p>Encapsulation</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (m1 &gt; m2) &#123;</span><br><span class="line">  <span class="comment">// grab locks in high-to-low address order</span></span><br><span class="line">  pthread_mutex_lock(m1);</span><br><span class="line">  pthread_mutex_lock(m2);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  pthread_mutex_lock(m2);</span><br><span class="line">  pthread_mutex_lock(m1);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>Problem: Deadlock happens when <code>m1 == m2</code></li></ul></li></ul><h3 id="deadlock-theory"><a class="markdownIt-Anchor" href="#deadlock-theory"></a> Deadlock Theory</h3><ul><li><p>Deadlocks can only happen with these four conditions:</p><ol><li>mutual exclusion</li><li>hold-and-wait</li><li>no preemption</li><li>circular wait</li></ol></li><li><p>Can eliminate deadlock by eliminating any one condition</p></li></ul><h3 id="1-mutual-exclusion"><a class="markdownIt-Anchor" href="#1-mutual-exclusion"></a> 1. Mutual Exclusion</h3><ul><li><p>Problem: Threads claim exclusive control of resources that they require</p></li><li><p>Strategy: Eliminate locks! Replace locks with atomic primitive</p></li><li><p>Lock-free <code>add</code></p><ul><li><p>Implement <code>add</code> using lock</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> *val, <span class="keyword">int</span> amt)</span> </span>&#123;</span><br><span class="line">  Mutex_lock(&amp;m);</span><br><span class="line">  *val += amt;</span><br><span class="line">  Mutex_unlock(&amp;m);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Atomic primitive <code>CompareAndSwap</code></p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">CompareAndSwap</span><span class="params">(<span class="keyword">int</span> *address, <span class="keyword">int</span> expected, <span class="keyword">int</span> <span class="keyword">new</span>)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (*address == expected) &#123;</span><br><span class="line">    *address = <span class="keyword">new</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;  <span class="comment">// success</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;  <span class="comment">// failure</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Implement <code>add</code> without lock</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> *val, <span class="keyword">int</span> amt)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">do</span> &#123;</span><br><span class="line">    <span class="keyword">int</span> old = *value;</span><br><span class="line">  &#125; <span class="keyword">while</span> (!CompareAndSwap(val, old, old + amt);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>Wait-free Linked List Insert</p><ul><li><p>Implement <code>insert</code> using lock</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">insert</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">node_t</span> *n = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(*n));</span><br><span class="line">  n-&gt;val = val;</span><br><span class="line">  lock(&amp;m);</span><br><span class="line">  n-&gt;next = head;</span><br><span class="line">  head = n;</span><br><span class="line">  unlock(&amp;m);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Implement <code>insert</code> using while loop</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">insert</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">node_t</span> *n = Malloc(<span class="keyword">sizeof</span>(*n));</span><br><span class="line">  n-&gt;val = val;</span><br><span class="line">  <span class="keyword">do</span> &#123;</span><br><span class="line">    n-&gt;next = head;</span><br><span class="line">  &#125; <span class="keyword">while</span> (!CompareAndSwap(&amp;head, n-&gt;next, n));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li></ul><h3 id="2-hold-and-wait"><a class="markdownIt-Anchor" href="#2-hold-and-wait"></a> 2. Hold and Wait</h3><ul><li><p>Problem: Threads hold resources allocated to them while waiting for additional resources</p></li><li><p>Strategy: Acquire all locks atomically once. Can release locks over time, but cannot acquire again until all have been released</p></li><li><p>How to do this? Use a meta lock:</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">lock(&amp;meta);</span><br><span class="line">lock(&amp;L1); <span class="comment">/*...*/</span> lock(&amp;L10);</span><br><span class="line">unlock(&amp;L10); <span class="comment">/*...*/</span> unlock(&amp;L1);</span><br><span class="line">unlock(&amp;meta);</span><br></pre></td></tr></table></figure></li><li><p>Disadvantages</p><ul><li>Locks are not fine-grained</li></ul></li></ul><h3 id="3-no-preemption"><a class="markdownIt-Anchor" href="#3-no-preemption"></a> 3. No Preemption</h3><ul><li><p>Problem: Resources (e.g., locks) cannot be forcibly removed from threads that are</p></li><li><p>Strategy: if thread can’t get what it wants, release what it holds</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">top: </span><br><span class="line">lock(A);</span><br><span class="line"><span class="keyword">if</span> (trylock(B) == <span class="number">-1</span>) &#123; <span class="comment">// try to lock B</span></span><br><span class="line">  unlock(A); <span class="comment">// if failed, also unlock A</span></span><br><span class="line">  <span class="keyword">goto</span> top;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Disadvantages</p><ul><li>Live lock: A situation in which two or more processes continuously change their states in response to changes in the other process(es) without doing any useful work</li></ul></li></ul><h3 id="circular-wait"><a class="markdownIt-Anchor" href="#circular-wait"></a> Circular Wait</h3><ul><li><p>Circular chain of threads such that each thread holds a resource (e.g., lock)<br>being requested by next thread in the chain.</p></li><li><p>Strategy:</p><ul><li>decide which locks should be acquired before others</li><li>if A before B, never acquire A if B is already held!</li><li>document this, and write code accordingly</li></ul></li><li><p>Works well if system has distinct layers</p></li></ul><h2 id="concurrent-data-structures"><a class="markdownIt-Anchor" href="#concurrent-data-structures"></a> Concurrent Data Structures</h2><h3 id="scalability-measure"><a class="markdownIt-Anchor" href="#scalability-measure"></a> Scalability Measure</h3><ul><li><p>N times as much work on N cores as done on 1 core.</p></li><li><p>Strong scalability</p><ul><li><p>Fix input size, increase number of cores, can have better performance</p></li><li><p>e.g. Matrix multiplication: <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>A</mi><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow></msub><mo>×</mo><msub><mi>B</mi><mrow><mi>n</mi><mo>×</mo><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_{m\times n}\times B_{n\times d}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.891661em;vertical-align:-0.208331em;"></span><span class="base"><span class="mord"><span class="mord mathit">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.25833100000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">m</span><span class="mbin mtight">×</span><span class="mord mathit mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"></span></span></span></span></span><span class="mord rule" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mord rule" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathit" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">n</span><span class="mbin mtight">×</span><span class="mord mathit mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"></span></span></span></span></span></span></span></span> requires <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>m</mi><mi>n</mi><mi>d</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">O(mnd)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathit">m</span><span class="mord mathit">n</span><span class="mord mathit">d</span><span class="mclose">)</span></span></span></span> FLOPS (floating point operations per second)</p></li></ul>  <pre> Time    ^   |   |     **   |     **   |     **   |     **   |     **     **   |     **     **   |     **     **     **   |     **     **     **     **   +-----++-----++-----++-----++----> Number of Cores   0     1      2      3      4</pre></li></ul><ul><li><p>Weak scaling:</p><ul><li><p>Increase input size with number of cores</p></li><li><p>e.g. Matrix multiplication</p></li></ul><table><thead><tr><th></th><th>A</th><th>B</th><th>FLOPS</th></tr></thead><tbody><tr><td>1 core</td><td>100 × 100</td><td>100 × 100</td><td>10<sup>6</sup></td></tr><tr><td>2 core</td><td>100 × 200</td><td>200 × 100</td><td>2×10<sup>6</sup></td></tr><tr><td>3 core</td><td>100 × 300</td><td>300 × 100</td><td>2×10<sup>6</sup></td></tr><tr><td>4 core</td><td>100 × 400</td><td>400 × 100</td><td>4×10<sup>6</sup></td></tr></tbody></table>  <pre> Time    ^   |   |     **     **     **     **   |     **     **     **     **   |     **     **     **     **   |     **     **     **     **   |     **     **     **     **   |     **     **     **     **   |     **     **     **     **   |     **     **     **     **   +-----++-----++-----++-----++----> Number of Cores   0     1      2      3      4  </pre></li></ul><h3 id="counter"><a class="markdownIt-Anchor" href="#counter"></a> Counter</h3><ul><li><p>Non-thread-safe Counter</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> __<span class="title">counter_t</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> value;</span><br><span class="line">&#125; <span class="keyword">counter_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">(<span class="keyword">counter_t</span> * c)</span> </span>&#123;</span><br><span class="line">    c-&gt;value = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">increment</span><span class="params">(<span class="keyword">counter_t</span> * c)</span> </span>&#123;</span><br><span class="line">    c-&gt;value++;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">get</span><span class="params">(<span class="keyword">counter_t</span> * c)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> c-&gt;value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>Problem: Two threads calls <code>increment</code> at the same time</li></ul></li><li><p>Thread-safe counter</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> __<span class="title">counter_t</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> value;</span><br><span class="line">    <span class="keyword">pthread_mutex_t</span> lock;</span><br><span class="line">&#125; <span class="keyword">counter_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">(<span class="keyword">counter_t</span> * c)</span> </span>&#123;</span><br><span class="line">    c-&gt;value = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">increment</span><span class="params">(<span class="keyword">counter_t</span> * c)</span> </span>&#123;</span><br><span class="line">    Pthread_mutex_lock(&amp;c-&gt;lock);</span><br><span class="line">    c-&gt;value++;</span><br><span class="line">    Pthread_mutex_unlock(&amp;c-&gt;lock);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">get</span><span class="params">(<span class="keyword">counter_t</span> * c)</span> </span>&#123;</span><br><span class="line">    Pthread_mutex_lock(&amp;c-&gt;lock);</span><br><span class="line">    <span class="keyword">return</span> c-&gt;value;</span><br><span class="line">    Pthread_mutex_unlock(&amp;c-&gt;lock);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Linearizability</p><ul><li><p>Even if two threads execute in parallel on multiple cores, the effect that you see should be as if all of them are executed in some linear order.</p></li><li><p>Example: T1 and T2 call <code>increment</code> first, then T3 calls <code>get</code>.</p></li><li><p>Since T3 arrived after T1 and T2, we would want T3 to see the values after T1 and T2 have finished executing as if these were three instructions executed by a single processor</p></li></ul></li><li><p>The Underlying Problem</p><ul><li>Ticket lock</li></ul>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">spinlock_t</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> current_ticket; <span class="comment">// turn</span></span><br><span class="line">    <span class="keyword">int</span> next_ticket;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">spin_lock</span><span class="params">(<span class="keyword">spinlock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    t = atomic_inc(lock-&gt;next_ticket)</span><br><span class="line">    <span class="keyword">while</span> (t != lock-&gt;current_ticket); <span class="comment">// spin</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">spin_unlock</span><span class="params">(<span class="keyword">spinlock_t</span> *lock)</span> </span>&#123;</span><br><span class="line">    lock-&gt;current_ticket++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>If one of the thread holds the lock,  all of the other threads need to check the lock</li><li>So each lock acquisition becomes more and more expensive as you go from like two to four to eight…</li></ul></li></ul><h3 id="approximate-counter-sloppy-counter"><a class="markdownIt-Anchor" href="#approximate-counter-sloppy-counter"></a> Approximate Counter (Sloppy Counter)</h3><ul><li><p>Motivation</p><ul><li>with standard thread-safe counter (strongest possible consistency) performance is poor under multithreads. Scalability is poor.</li><li>Cross-core messages are expensive under multicore system (Conclusion from “An analysis of Linux Scalability to Many Cores - Boyd-Wickizer et. al OSDI 2010, in the article they use 48core machine to benchmark linux”). This is because ticket lock in linux: if one of the core holds the lock all other cores need to check with this core holdiing the lock what is the next turn value going to be. We want to reduce the number of cross-core messages, which is very expensive under this situation. One way is to relax consistency.</li></ul></li><li><p>Idea</p><ul><li>Maintain a counter per-core and a global counter</li><li>Global counter lock</li><li>Per-core locks if more than 1 thread per-core</li></ul></li><li><p>Increment:</p><ul><li>update local counters at threshold update global</li></ul></li><li><p>Read:</p><ul><li>global counter (maybe inaccurate?)</li></ul></li><li><p>Code</p></li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> __<span class="title">counter_t</span> &#123;</span></span><br><span class="line">  <span class="keyword">int</span> global;                      <span class="comment">// global count</span></span><br><span class="line">  <span class="keyword">pthread_mutex_t</span> glock;           <span class="comment">// global lock</span></span><br><span class="line">  <span class="keyword">int</span> local[NUMCPUS];              <span class="comment">// local count (per cpu)</span></span><br><span class="line">  <span class="keyword">pthread_mutex_t</span> llock[NUMCPUS];  <span class="comment">// ... and locks</span></span><br><span class="line">  <span class="keyword">int</span> threshold;                   <span class="comment">// update frequency</span></span><br><span class="line">&#125; <span class="keyword">counter_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// init: record threshold, init locks, init values of all local counts and</span></span><br><span class="line"><span class="comment">// global count</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">(<span class="keyword">counter_t</span>* c, <span class="keyword">int</span> threshold)</span> </span>&#123;</span><br><span class="line">  c-&gt;threshold = threshold;</span><br><span class="line">  c-&gt;global = <span class="number">0</span>;</span><br><span class="line">  pthread_mutex_init(&amp;c-&gt;glock, <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; NUMCPUS; i++) &#123;</span><br><span class="line">    c-&gt;local[i] = <span class="number">0</span>;</span><br><span class="line">    pthread_mutex_init(&amp;c-&gt;llock[i], <span class="literal">NULL</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// usually, just grab local lock and update local amount once local</span></span><br><span class="line"><span class="comment">// count has risen by ’threshold’, grab global lock and transfer local values to it</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">update</span><span class="params">(<span class="keyword">counter_t</span>* c, <span class="keyword">int</span> threadID, <span class="keyword">int</span> amt)</span> </span>&#123;</span><br><span class="line">  pthread_mutex_lock(&amp;c-&gt;llock[threadID]);</span><br><span class="line">  c-&gt;local[threadID] += amt;                 <span class="comment">// assumes amt &gt; 0</span></span><br><span class="line">  <span class="keyword">if</span> (c-&gt;local[threadID] &gt;= c-&gt;threshold) &#123;  <span class="comment">// transfer to global</span></span><br><span class="line">    pthread_mutex_lock(&amp;c-&gt;glock);</span><br><span class="line">    c-&gt;global += c-&gt;local[threadID];</span><br><span class="line">    pthread_mutex_unlock(&amp;c-&gt;glock);</span><br><span class="line">    c-&gt;local[threadID] = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  pthread_mutex_unlock(&amp;c-&gt;llock[threadID]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// get: just return global amount (which may not be perfect)</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">get</span><span class="params">(<span class="keyword">counter_t</span>* c)</span> </span>&#123;</span><br><span class="line">  pthread_mutex_lock(&amp;c-&gt;glock);</span><br><span class="line">  <span class="keyword">int</span> val = c-&gt;global;</span><br><span class="line">  pthread_mutex_unlock(&amp;c-&gt;glock);</span><br><span class="line">  <span class="keyword">return</span> val;  <span class="comment">// only approximate!</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="concurrent-linked-list"><a class="markdownIt-Anchor" href="#concurrent-linked-list"></a> Concurrent Linked List</h3><ul><li><p>First Attempt</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">List_Insert</span><span class="params">(<span class="keyword">list_t</span> *L, <span class="keyword">int</span> key)</span> </span>&#123;</span><br><span class="line">  pthread_mutex_lock(&amp;L-&gt;lock);</span><br><span class="line">  <span class="keyword">node_t</span> *<span class="keyword">new</span> = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">node_t</span>));</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">new</span> == <span class="literal">NULL</span>) &#123;</span><br><span class="line">    perror(<span class="string">"malloc"</span>);</span><br><span class="line">    pthread_mutex_unlock(&amp;L-&gt;lock);</span><br><span class="line">    <span class="keyword">return</span>;  <span class="comment">//  fail</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">new</span>-&gt;key = key;</span><br><span class="line">  <span class="keyword">new</span>-&gt;next = L-&gt;head;</span><br><span class="line">  L-&gt;head = <span class="keyword">new</span>;</span><br><span class="line">  pthread_mutex_unlock(&amp;L-&gt;lock);</span><br><span class="line">  <span class="keyword">return</span>;  <span class="comment">//  success</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Better Implementation (Shorter Critical Section)</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">List_Insert</span><span class="params">(<span class="keyword">list_t</span> *L, <span class="keyword">int</span> key)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">node_t</span> *<span class="keyword">new</span> = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">node_t</span>));</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">new</span> == <span class="literal">NULL</span>) &#123;</span><br><span class="line">    perror(<span class="string">"malloc"</span>);</span><br><span class="line">    <span class="keyword">return</span>;  <span class="comment">//  fail</span></span><br><span class="line">  &#125;</span><br><span class="line">  pthread_mutex_lock(&amp;L-&gt;lock);</span><br><span class="line">  <span class="keyword">new</span>-&gt;key = key;</span><br><span class="line">  <span class="keyword">new</span>-&gt;next = L-&gt;head;</span><br><span class="line">  L-&gt;head = <span class="keyword">new</span>;</span><br><span class="line">  pthread_mutex_unlock(&amp;L-&gt;lock);</span><br><span class="line">  <span class="keyword">return</span>;  <span class="comment">//  success</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="hash-table-from-list"><a class="markdownIt-Anchor" href="#hash-table-from-list"></a> Hash Table from List</h3><ul><li><p>Idea</p><ul><li>Avoid contention by using different locks in each buckets — more fine-grained locks &amp; reduce cross threads contentions, leads to better scalling under multithreads performane</li></ul></li><li><p>Code</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> BUCKETS (101)</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> __<span class="title">hash_t</span> &#123;</span></span><br><span class="line">  <span class="keyword">list_t</span> lists[BUCKETS];</span><br><span class="line">&#125; <span class="keyword">hash_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">Hash_Insert</span><span class="params">(<span class="keyword">hash_t</span> *H, <span class="keyword">int</span> key)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> bucket = key % BUCKETS;</span><br><span class="line">  <span class="keyword">return</span> List_Insert(&amp;H-&gt;lists[bucket], key);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="concurrent-queue"><a class="markdownIt-Anchor" href="#concurrent-queue"></a> Concurrent Queue</h3><ul><li>Idea: use 2 locks to ensure that threads can enqueue/dequeue without conflicting with each other</li><li>One more thing to check in the following implementation: when there is only 1 elment – head and tail points to the same thing in queue, grab both locks</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Queue_Enqueue</span><span class="params">(<span class="keyword">queue_t</span> *q, <span class="keyword">int</span> value)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">node_t</span> *tmp = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">node_t</span>));</span><br><span class="line">  assert(tmp != <span class="literal">NULL</span>);</span><br><span class="line">  tmp-&gt;value = value;</span><br><span class="line">  tmp-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">  pthread_mutex_lock(&amp;q-&gt;tailLock);</span><br><span class="line">  q-&gt;tail-&gt;next = tmp;</span><br><span class="line">  q-&gt;tail = tmp;</span><br><span class="line">  pthread_mutex_unlock(&amp;q-&gt;tailLock);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">Queue_Dequeue</span><span class="params">(<span class="keyword">queue_t</span> *q, <span class="keyword">int</span> *value)</span> </span>&#123;</span><br><span class="line">  pthread_mutex_lock(&amp;q-&gt;headLock);</span><br><span class="line">  <span class="keyword">node_t</span> *tmp = q-&gt;head;</span><br><span class="line">  <span class="keyword">node_t</span> *newHead = tmp-&gt;next;</span><br><span class="line">  <span class="keyword">if</span> (newHead == <span class="literal">NULL</span>) &#123;</span><br><span class="line">    pthread_mutex_unlock(&amp;q-&gt;headLock);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;  <span class="comment">// queue was empty</span></span><br><span class="line">  &#125;</span><br><span class="line">  *value = newHead-&gt;value;</span><br><span class="line">  q-&gt;head = newHead;</span><br><span class="line">  pthread_mutex_unlock(&amp;q-&gt;headLock);</span><br><span class="line">  <span class="built_in">free</span>(tmp);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="summary-4"><a class="markdownIt-Anchor" href="#summary-4"></a> Summary</h3><ul><li><p>Simple approach: Add a lock to each method’s start and end!  example: java keyword synchronized<br>public synchronized get(){} This kind of synchronoized keyword is very standard in high level language but this may reduce performance under multicore scalablility</p></li><li><p>Check for scalability – weak scaling, strong scaling</p></li><li><p>If you are not happy with scalability properties, try to optimize by: Avoid cross-thread, cross-core traffic, using methods such as</p><ul><li>Per-core(sloppy) counter, relax consistency</li><li>Buckets in hashtable, reduce cross threads contention, more fine grained locks</li><li>keep critical section small</li><li>not using locks is faster than using locks</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;cs537-operating-system-summary-part-2-concurrency&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#cs537-operating-system-summary-part-2-concurr
      
    
    </summary>
    
    
      <category term="OS" scheme="http://th2zz.github.io/tags/OS/"/>
    
  </entry>
  
  <entry>
    <title>Boyer–Moore majority vote algorithm</title>
    <link href="http://th2zz.github.io/2019/03/25/Boyer%E2%80%93Moore%20majority%20vote%20algorithm/"/>
    <id>http://th2zz.github.io/2019/03/25/Boyer–Moore majority vote algorithm/</id>
    <published>2019-03-25T03:38:32.000Z</published>
    <updated>2019-03-25T05:16:09.226Z</updated>
    
    <content type="html"><![CDATA[<h1 id="boyermoore-majority-vote-algorithm"><a class="markdownIt-Anchor" href="#boyermoore-majority-vote-algorithm"></a> Boyer–Moore majority vote algorithm</h1><p>Boyer–Moore majority vote algorithm is an algorithm that finds the majority element and its count from a given sequence in O(N)TIME O(1)SPACE.</p><h2 id="pseudocode"><a class="markdownIt-Anchor" href="#pseudocode"></a> Pseudocode</h2><ul><li>Initialize an element m and a counter i with i = 0</li><li>For each element x of the input sequence:<ul><li>If i = 0, then assign m = x and i = 1</li><li>else if m = x, then assign i = i + 1</li><li>else assign i = i − 1</li></ul></li><li>Return m<br>初始化major元素 major = arr[0]，counter = 1<br>遍历序列中每个元素 1:end<br>if counter == 0 reset: major to be current pointer and counter to be 1<br>else if major == current element increment counter<br>else (current element is not major and counter need not to be reset) decrement counter</li></ul><h2 id="example"><a class="markdownIt-Anchor" href="#example"></a> Example</h2><p>Leetcode 169<br>Given an array of size n, find the majority element. The majority element is the element that appears more than ⌊ n/2 ⌋ times.<br>You may assume that the array is non-empty and the majority element always exist in the array.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">    public int majorityElement(int[] num) &#123;</span><br><span class="line">        int major=num[0], count = 1;</span><br><span class="line">        for(int i=1; i&lt;num.length;i++)&#123;</span><br><span class="line">            if(count==0)&#123;</span><br><span class="line">                count++;</span><br><span class="line">                major=num[i];</span><br><span class="line">            &#125;else if(major==num[i])&#123;</span><br><span class="line">                count++;</span><br><span class="line">            &#125;else count--;</span><br><span class="line">        &#125;</span><br><span class="line">        return major;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Reference:<br><a href="https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_majority_vote_algorithm" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Boyer–Moore_majority_vote_algorithm</a><br><a href="https://www.zhihu.com/question/49973163/answer/235921864" target="_blank" rel="noopener">https://www.zhihu.com/question/49973163/answer/235921864</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;boyermoore-majority-vote-algorithm&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#boyermoore-majority-vote-algorithm&quot;&gt;&lt;/a&gt; Boyer–Moore majorit
      
    
    </summary>
    
    
      <category term="Algorithm and Data Structures" scheme="http://th2zz.github.io/tags/Algorithm-and-Data-Structures/"/>
    
  </entry>
  
  <entry>
    <title>Threaded Binary Tree and Morris Traversal</title>
    <link href="http://th2zz.github.io/2019/03/23/Threaded%20Binary%20Tree%20and%20Morris%20Traversal/"/>
    <id>http://th2zz.github.io/2019/03/23/Threaded Binary Tree and Morris Traversal/</id>
    <published>2019-03-22T20:58:08.000Z</published>
    <updated>2019-03-22T20:58:39.460Z</updated>
    
    <content type="html"><![CDATA[<h1 id="threaded-binary-tree-and-morris-traversal"><a class="markdownIt-Anchor" href="#threaded-binary-tree-and-morris-traversal"></a> Threaded Binary Tree and Morris Traversal</h1><h2 id="motivation"><a class="markdownIt-Anchor" href="#motivation"></a> Motivation</h2><p>对于有着空的左孩子右孩子指针的节点 内存被浪费了，所以在TBT里我们利用这些内存来储存一些地址</p><h2 id="transform-a-normal-binary-tree-to-tbt"><a class="markdownIt-Anchor" href="#transform-a-normal-binary-tree-to-tbt"></a> Transform a normal binary tree to TBT</h2><ol><li>最左边最右边的空指针不改动</li><li>将其他的空指针改为：<ul><li><pre><code>Left ptr = inorder predecessor 因为该节点没有inorder predecessor 中序遍历第一个节点</code></pre></li><li><pre><code>Right ptr = inorder successor 因为该节点没有inorder successor 中序遍历最后一个节点</code></pre></li></ul></li></ol><p><img src="https://i.imgur.com/sr6MQQ7.jpg" alt=""><br>我们可以在节点里加入两个flag来代表左指针右指针指向的是ancestor还是child<br>最后对于中序遍历的起点和终点的左右指针 连向dummy node flag设为ancestor<br><img src="https://i.imgur.com/OE9qckF.png" alt=""></p><p>莫里斯遍历利用线段树的概念可以实现iterative inorder traversal of tree without using stack TIME O(N) SPACE O(1)<br>Pseudocode</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Initialize current as root </span><br><span class="line">While current is not NULL</span><br><span class="line">   If current does not has a left child</span><br><span class="line">      a) access current&apos;s data</span><br><span class="line">      b) Go to the right, i.e., current = current-&gt;right</span><br><span class="line">   Else</span><br><span class="line">      a) Make current as right child of the rightmost </span><br><span class="line">         node in current&apos;s left subtree</span><br><span class="line">      b) Go to that left child, i.e., current = current-&gt;left  (set current&apos;s left to be null)</span><br></pre></td></tr></table></figure><p>LeetCode94: use above method to achieve inorder traversal</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">    public List&lt;Integer&gt; inorderTraversal(TreeNode node) &#123;</span><br><span class="line">        List&lt;Integer&gt; list = new ArrayList();</span><br><span class="line"></span><br><span class="line">        while(node != null) &#123;</span><br><span class="line">            if(node.left == null) &#123;</span><br><span class="line">                list.add(node.val);</span><br><span class="line">                node = node.right;</span><br><span class="line">            &#125;</span><br><span class="line">            else &#123;</span><br><span class="line">                TreeNode nextNode = node.left;</span><br><span class="line">                TreeNode p = node.left;</span><br><span class="line">                while(p.right != null) p = p.right;</span><br><span class="line">                p.right = node;//p:rightmost node in the leftsubtree</span><br><span class="line">                node.left = null;</span><br><span class="line">                node = nextNode;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return list;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;threaded-binary-tree-and-morris-traversal&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#threaded-binary-tree-and-morris-traversal&quot;&gt;&lt;/a&gt; Threa
      
    
    </summary>
    
    
      <category term="Algorithm and Data Structures" scheme="http://th2zz.github.io/tags/Algorithm-and-Data-Structures/"/>
    
  </entry>
  
  <entry>
    <title>Database Management System - Relational Design Theory</title>
    <link href="http://th2zz.github.io/2019/03/19/Database/"/>
    <id>http://th2zz.github.io/2019/03/19/Database/</id>
    <published>2019-03-18T18:00:41.000Z</published>
    <updated>2019-04-21T23:48:17.969Z</updated>
    
    <content type="html"><![CDATA[<h1 id="cs564-dbms-relational-design-theory"><a class="markdownIt-Anchor" href="#cs564-dbms-relational-design-theory"></a> <strong>CS564 - DBMS - Relational Design Theory</strong></h1><h2 id="sql"><a class="markdownIt-Anchor" href="#sql"></a> SQL</h2><h3 id="relational-algebra-and-calculus"><a class="markdownIt-Anchor" href="#relational-algebra-and-calculus"></a> Relational algebra and Calculus</h3><p><img src="https://i.imgur.com/kksvzjk.png" alt=""></p><h3 id="keys"><a class="markdownIt-Anchor" href="#keys"></a> Keys</h3><ul><li>A<strong>superkey</strong> is a set of one or more attributes that, taken collectively, allow us to identify uniquely a tuple in the relation</li><li>Such minimal superkeys are called <strong>candidate keys</strong>.</li><li>We shall use the term <strong>primary key</strong> to denote a candidate key that is chosen by the database designer as the principal means of identifying tuples within a relation.</li><li><strong>Foreign Key</strong> is a set of attributes in a referencing relation, such that for each tuple in the referencing relation, the values of the foreign key attributes are guaranteed to occur as the primary key value of a tuple in the referenced relation.</li></ul><h3 id="join"><a class="markdownIt-Anchor" href="#join"></a> Join</h3><ul><li>natural join combines two tables based on identical columns</li><li>Cartesian product operation combines tuples from two relations, but unlike the join operation, its result contains all pairs of tuples from the two relations</li></ul><h3 id="sql-language"><a class="markdownIt-Anchor" href="#sql-language"></a> SQL Language</h3><ul><li>SQL allows us to use the keyword all to specify explicitly that duplicates are not removed</li><li><strong>varchar(n)</strong>: A variable-length character string with user-specified maximum length n. The full form, character varying, is equivalent.</li><li><strong>numeric(p, d)</strong>:Afixed-point numberwith user-specified precision. The number consists of p digits (plus a sign), and d of the p digits are to the right of the decimal point.</li><li><strong>Percent (%)</strong>: The % character matches any substring.</li><li><strong>Underscore (_)</strong>: The character _ matches any character.</li><li>The set operation automatically eliminates duplicates</li></ul><p><img src="https://i.imgur.com/G2hgY3K.png" alt=""></p><h2 id="database-design-er-model"><a class="markdownIt-Anchor" href="#database-design-er-model"></a> Database Design (ER Model)</h2><h3 id="terms"><a class="markdownIt-Anchor" href="#terms"></a> Terms</h3><ul><li>Entity</li><li>Attribute<ul><li>Domain</li><li>Key</li><li>Primary Key can not be null</li></ul></li><li>Relationship<ul><li>Descriptive attribute, the attribute of the entity in between two entities</li><li>A relationship should be uniquely identified</li><li>Instance of relationship set is a set of relationships</li><li>Sometimes a relationship can involve two identities in the same enetity set</li></ul></li><li>Constraints<ul><li>Participation constraint, total, partial</li><li>weak enetity set</li><li>ISA inheritance relationship set<ul><li>specialzation, generalization</li><li>overlap, covering constraint</li></ul></li></ul></li></ul><h3 id="the-relational-model"><a class="markdownIt-Anchor" href="#the-relational-model"></a> The Relational Model</h3><ul><li>Integrity Constriant<ul><li>Foreign key constraint</li></ul></li></ul><h2 id="relational-design-theory"><a class="markdownIt-Anchor" href="#relational-design-theory"></a> Relational Design Theory</h2><h3 id="函数依赖-functional-dependency"><a class="markdownIt-Anchor" href="#函数依赖-functional-dependency"></a> 函数依赖 Functional Dependency</h3><ul><li><p>考虑如下的university database schema<br><img src="https://i.imgur.com/rjGtPin.png" width="500" height="200"><br>将表instructor和department替换为其自然连接的结果不是一个好的选择<br><img src="https://i.imgur.com/JltoS4y.png" width="400"><br>因为对于每个instructor都有部门budget信息大量重复 我们需要保证任何更新操作都要同步budget。 另一个缺点是natural inner join会去除左右两边为null的情况，所以没有instructor的部门就无法在表中被表示。<br><strong>但如果我们先有inst_dept表，我们该如何知道这个设计不好并且应该被分解成instructor和department呢？</strong><br>我们需要发现每个department必须只有1个building,每个department必须只有一个budget。<br>Not every ER design can be precise enough to avoid such problems，so we need to allow designers to specify rules such as “<strong>each specific value of dept_name corresponds to at most one budget</strong>” even in cases where dept_name is not the primary key for the schema.<br>In this case, we need to write a rule “<strong>if there were a schema(dept_name,budget),then dept_name is able to serve as the primary key</strong>.” This rule is specified as a functional dependency:<br><img src="https://i.imgur.com/aaCGsjY.png" width="250"><br>This gives sufficient information to recognize the problem of inst_dept schema. Therefore functional dependency says what relational instances are allowed under certain constraints.<br>Functional depedency generalizes notions of key in a relation. It depicts relationship between attributes.</p></li><li><p><strong>Definition</strong>: A relational instance satisfies functional dependency from attribute A-&gt;B if (any) two tuples having same value of attribute A also have same value of attribute B. i.e. A uniquely determines B</p></li><li><p><strong>A trivial functional dependency</strong> is the one which will always hold in a relation. <strong>A-&gt;B and B is a subset of A.</strong></p></li><li><p><strong>Non-Trivial functional dependency</strong> may or may not hold in a relation. <strong>A-&gt;B and B is NOT a subset of A.</strong></p></li><li><p><strong>Properties of functional dependency</strong><br>“Armstrong’s Axioms”<br><img src="https://i.imgur.com/zkhjneI.png" alt=""><br>Other<br><img src="https://i.imgur.com/nNsRewf.png" alt=""><br><img src="https://i.imgur.com/D9pWMoO.png" alt=""></p></li><li><p><strong>&quot;A set of functional dependencies&quot; F</strong> is a set of FD constraints on legal relational instances in a relation.</p></li><li><p><strong>&quot;The closure of FDs set F&quot; F+</strong> is a set of all FDs that can be inferred from given the set F (<strong>Note that this includes all FDs in F itself</strong>).</p></li><li><p><strong>Attribute Closure</strong>: Attribute closure of an attribute set A is a set of all attributes that can be functionally determined from elements of set A (<strong>Note that this includes attributes in A itself</strong>).<br>Examples:<br><img src="https://i.imgur.com/hf0hLCc.png" alt=""></p></li><li><p><strong>Determining equivalence of functional dependencies</strong><br>Check whether 2 FD sets are subset of each other’s closure.</p></li><li><p><strong>Computing minimal cover</strong><br>A minimal cover of a FD set A is the smallest set of FDs that covers A.<br><img src="https://i.imgur.com/ItMURpT.png" alt=""><br><img src="https://i.imgur.com/HOT0QpT.png" alt=""></p></li><li><p><strong>Other notes</strong><br>所有非主属性都完全函数依赖于每个候选键<br>所有主属性都完全函数依赖于每个不包含它的候选键<br>没有任何属性完全函数依赖于非候选键的任何一组属性</p></li></ul><h3 id="数据异常-data-anomalies"><a class="markdownIt-Anchor" href="#数据异常-data-anomalies"></a> 数据异常 Data Anomalies</h3><p>以下的学生课程关系的函数依赖为 Sno, Cname -&gt; Sname, Sdept, Mname, Grade，键码为 {Sno, Cname}。也就是说，确定学生和课程之后，就能确定其它信息。</p><table><thead><tr><th style="text-align:center">Sno</th><th style="text-align:center">Sname</th><th style="text-align:center">Sdept</th><th style="text-align:center">Mname</th><th style="text-align:center">Cname</th><th style="text-align:center">Grade</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">学生-1</td><td style="text-align:center">学院-1</td><td style="text-align:center">院长-1</td><td style="text-align:center">课程-1</td><td style="text-align:center">90</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">学生-2</td><td style="text-align:center">学院-2</td><td style="text-align:center">院长-2</td><td style="text-align:center">课程-2</td><td style="text-align:center">80</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">学生-2</td><td style="text-align:center">学院-2</td><td style="text-align:center">院长-2</td><td style="text-align:center">课程-1</td><td style="text-align:center">100</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">学生-3</td><td style="text-align:center">学院-2</td><td style="text-align:center">院长-2</td><td style="text-align:center">课程-2</td><td style="text-align:center">95</td></tr></tbody></table><p>不符合范式的关系，会产生很多异常，主要有以下四种异常：</p><ul><li>冗余数据：例如 <code>学生-2</code> 出现了两次。</li><li>修改异常：修改了一个记录中的信息，但是另一个记录中相同的信息却没有被修改。</li><li>删除异常：删除一个信息，那么也会丢失其它信息。例如删除了 <code>课程-1</code> 需要删除第一行和第三行，那么 <code>学生-1</code> 的信息就会丢失。</li><li>插入异常：例如想要插入一个学生的信息，如果这个学生还没选课，那么就无法插入。</li></ul><h3 id="范式-normal-form"><a class="markdownIt-Anchor" href="#范式-normal-form"></a> 范式 Normal Form</h3><p>范式理论是为了解决以上提到四种异常。<br>高级别范式的依赖于低级别的范式，1NF 是最低级别的范式。<br><img src="https://i.imgur.com/v1zy4Cw.png" width="250" height="200"></p><h4 id="分解"><a class="markdownIt-Anchor" href="#分解"></a> 分解</h4><p><strong>Universal Relation:</strong> A relation that captures all the information in schema and is decomposable into smaller relations.</p><ul><li><p>Decomposition of a relation is done when a relation in relational model is not in appropriate normal form. A good/detailed ER model should end up directly as a 3NF or BCNF. The functional dependencies guide us to determine entities and their relationships</p></li><li><p>Ideal decomposition should be <strong>lossless</strong> and <strong>dependency preserving</strong>.<br>For relation R decomposed into R1 and R2:<br><img src="https://i.imgur.com/LIH6YcZ.png" width="300"></p></li><li><p>Example:<br><img src="https://i.imgur.com/HRk77Rk.png" width="300"><br><img src="https://i.imgur.com/BKpXIIy.png" width="300"><br>employee表被分解为employee1表和employee2表：因为employee可以重名，所以我们将分解结果natural join会无法还原employee表。</p></li><li><p><strong>Lossless decomposition(lossless join decomposition) Requirements</strong><br><img src="https://i.imgur.com/7it87CU.png" alt=""></p></li><li><p><strong>Dependency preserving decomposition</strong><br>If we decompose a relation R into relations R1 and R2, All dependencies of R either must be a part of R1 or R2 or must be derivable from combination of FD’s of R1 and R2.</p><ul><li>Example:</li></ul><ol><li>R (A, B, C, D) with FD set{A-&gt;BC} is decomposed into R1(ABC) and R2(AD) which is dependency preserving because FD A-&gt;BC is a part of R1(ABC).</li><li>R(A,B,C,D) and functional dependencies A-&gt;B and C-&gt;D. Then the decomposition of R into R1(AB) and R2(CD) is dependency preserving but not lossless join because it violates the second condition of lossless join and A-&gt;B can be ensured in R1(AB) and C-&gt;D can be ensured in R2(CD). Hence it is dependency preserving decomposition.</li></ol></li></ul><h4 id="1-第一范式-1nf-atomicity原子性"><a class="markdownIt-Anchor" href="#1-第一范式-1nf-atomicity原子性"></a> 1. 第一范式 (1NF) Atomicity(原子性)</h4><p>表的属性不可分（表的属性不可为复合属性）。然而注意复合属性有时也是有用的并被大量实际使用于面向对象数据库。</p><h4 id="2-boycecodd-normal-formbcnf-每个表中只有一个候选键"><a class="markdownIt-Anchor" href="#2-boycecodd-normal-formbcnf-每个表中只有一个候选键"></a> 2. Boyce–Codd normal form(BCNF) 每个表中只有一个候选键</h4><p>BCNF is a slightly stronger version of 3NF.<br>Every BCNF satisfies 3NF. It eliminates all redundancy that can be discovered based on functional dependencies.<br><strong>A database design is in BCNF</strong> if each member of the set of relation schemas that constitutes the design is in BCNF.</p><p><strong>Definition：</strong><br>A relational schema R is in BCNF with respect to a set of functional dependencies F if for all functional dependencies in F+ of form A-&gt;B where A,B are subsets of R, at least one of the following holds:</p><ul><li>A-&gt;B is a trivial functional dependency (B is a subset of A)</li><li>A is a super key of schema R</li></ul><p><strong>Another equivalent definition (important):</strong><br>For all nontrivial FD A-&gt;B, A must be a super key of schema R.<br><strong>The negated definition</strong><br>A relational schema R is not in BCNF w.r.t FDs set F if there exists a FD in F+ of form A-&gt;B where A,B are subsets of R s.t.<br>A-&gt;B is a nontrivial FD (B is not a subset of A) <strong>AND</strong> A is not a super key of schema R.<br><strong>Example</strong>:<br>inst_dept (ID, name, salary, dept_name, building, budget) is not in BCNF because dept_name-&gt;budget is a nontrivial FD and dept_name is not a super key of inst_dept.<br>The schema instructor and department are not in BCNF because for all nontrivial FDs, either left side is not super key, or is super key. (in that case: ID, dept_name can be super key for each schema).<br><strong>Decomposing relational schema to BCNF</strong><br>For a relational schema R not in BCNF, we must have at least 1 nontrivial FD A-&gt;B s.t. A is not a super key for R.<br>We decompose R into 2 schemas:<br><img src="https://i.imgur.com/NbVERSD.png" width="180"><br>For inst_dept, A=dept_name, B={building,budget}, it can be decomposed to (dept_name, building, budget) AND (ID,name,salary,dept_name)<br><strong>Problem of BCNF:</strong></p><ul><li>BCNF is not dependency preserving.</li></ul><h4 id="3-第三范式-3nf-2nf消除传递函数依赖"><a class="markdownIt-Anchor" href="#3-第三范式-3nf-2nf消除传递函数依赖"></a> 3. 第三范式 (3NF) 2NF&amp;消除传递函数依赖</h4><p>BCNF requires A to be a superkey for nontrival FD A-&gt;B. 3NF relaxes the constraints by allowing A to not be a super key.<br><strong>Definition：</strong><br>A relational schema R is in 3NF with respect to a set of functional dependencies F if for all functional dependencies in F+ of form A-&gt;B where A,B are subsets of R, at least one of the following holds:</p><ul><li>A-&gt;B is a trivial functional dependency (B is a subset of A)</li><li>A is a super key of schema R</li><li>Each attribute X in B-A is contained in a candidate key in R</li></ul><table><thead><tr><th style="text-align:center">Sno</th><th style="text-align:center">Sname</th><th style="text-align:center">Sdept</th><th style="text-align:center">Mname</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">学生-1</td><td style="text-align:center">学院-1</td><td style="text-align:center">院长-1</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">学生-2</td><td style="text-align:center">学院-2</td><td style="text-align:center">院长-2</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">学生-3</td><td style="text-align:center">学院-2</td><td style="text-align:center">院长-2</td></tr></tbody></table><p>存在以下transitive functional dependency：</p><ul><li>Sno -&gt; Sdept -&gt; Mname</li></ul><p>可以进行以下分解：</p><table><thead><tr><th style="text-align:center">Sno</th><th style="text-align:center">Sname</th><th style="text-align:center">Sdept</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">学生-1</td><td style="text-align:center">学院-1</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">学生-2</td><td style="text-align:center">学院-2</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">学生-3</td><td style="text-align:center">学院-2</td></tr></tbody></table><table><thead><tr><th style="text-align:center">Sdept</th><th style="text-align:center">Mname</th></tr></thead><tbody><tr><td style="text-align:center">学院-1</td><td style="text-align:center">院长-1</td></tr><tr><td style="text-align:center">学院-2</td><td style="text-align:center">院长-2</td></tr></tbody></table><p><img src="https://i.imgur.com/iLeQOu8.png" alt=""></p><h3 id="multi-dimensional-database"><a class="markdownIt-Anchor" href="#multi-dimensional-database"></a> Multi-dimensional database</h3><p><img src="https://i.imgur.com/1RU9DJz.jpg" alt=""></p><p>Think spreadsheets and reporting but generalized.</p><ul><li>A star schema is the simplest form of a dimensional model, in which data is organized into facts and dimensions.  A fact is an event that is counted or measured, such as a sale or login.  A dimension contains reference information about the fact, such as date, product, or customer. A star schema is diagramed by surrounding each fact with its associated dimensions. The resulting diagram resembles a star.<br><img src="https://i.imgur.com/7xGywCG.png" alt=""></li><li>Example:<br><img src="https://i.imgur.com/n4OrKwb.jpg" alt=""></li></ul><h3 id="levels-of-abstraction-in-dbms"><a class="markdownIt-Anchor" href="#levels-of-abstraction-in-dbms"></a> Levels of abstraction in DBMS</h3><ul><li>Physical Schema is the way the relations are actually stored in SSD/HDD. It also defines indexes, statistics etc. defined on the table. (Indexes are defined using DDL.)</li><li>Logical (Conceptual) Schema is the DDL for creating the table. (It can sometimes specify the physical schema.)</li><li>External Schema is the DDL that define’s the external user’s view of the database. Though some “base” tables are directly visible, most of it is protected through views.</li></ul><h2 id="storage-and-file-structure"><a class="markdownIt-Anchor" href="#storage-and-file-structure"></a> Storage and File Structure</h2><h3 id="storage-overview"><a class="markdownIt-Anchor" href="#storage-overview"></a> Storage Overview</h3><ul><li>Persistent storage nonvolatile memory<ul><li>Data in a DBMS has to be persistent</li><li>SSD: flash memory based, faster and more expensive</li><li>HDD: magnetic storage, slower and cheaper</li><li>Tapes: disks are the new tapes, still great for archiving</li><li>Cloud server</li></ul></li><li>Volatile storage<ul><li>DRAM</li></ul></li></ul><h3 id="memory-hierarchy"><a class="markdownIt-Anchor" href="#memory-hierarchy"></a> Memory hierarchy</h3><p><img src="https://i.imgur.com/1EP43L3.jpg" alt=""></p><h3 id="disk"><a class="markdownIt-Anchor" href="#disk"></a> Disk</h3><p><img src="https://i.imgur.com/RJ2GrlY.png" alt=""></p><ul><li><p>The disk surface is logically divided into tracks, which are subdivided into sectors.</p><ul><li>A <strong>sector</strong> is the smallest unit of information that can be read from or written to the disk.</li><li>The <strong>read–write head</strong> stores information on a sector magnetically as reversals of the direction of magnetization of the magnetic material.</li><li>The <strong>platters</strong> that are <strong>fixed on a spindle rod</strong> spin, say 90 rps</li><li>Arm assembly moves in or out to position a head on desired track.</li><li>The tracks make an imaginary 空心<strong>cylinder</strong>: tracks with the same radius on all surfaces of disks platters     <strong>#cylinder = #tracks/surface</strong></li><li>#surface = #tracks/#cylinder = 2#platters</li><li>Only one head used at a time</li><li><strong>Block size</strong> is a multiple of sector size (fixed, usually 512 bytes)</li><li><strong>capacity</strong> = heads(#surfaces) x cylinder x sectors x 512 (typical size of one sector in bytes) =  #surfaces * #tracks * #sectors per track * bytes per sector</li></ul></li><li><p>Seek time: the time for repositioning the arm to change track.</p></li><li><p>Rotational delay: the time for getting to the right sector = 0.5(60s/磁盘转速rpm)   0.5为average</p></li><li><p>transfer time: actual overhead for transfering data = moving head across block</p></li></ul><p>Seek time + rotational delay is the major contributor to delay.<br><strong>Formatting</strong>: defining polar coordinate system on disk surface.<br><strong>wear leveling</strong>: storing hot data on less weared sectors and storing cold data on more weared sector to extend service time of the disk.</p><ul><li><p>RAID 0 Data stripping<br>RAID 0 consists of striping, but no mirroring or parity. Compared to a spanned volume, the capacity of a RAID 0 volume is the same; it is the sum of the capacities of the disks in the set. But because striping distributes the contents of each file among all disks in the set, the failure of any disk causes all files, the entire RAID 0 volume, to be lost. A broken spanned volume at least preserves the files on the unfailing disks. The benefit of RAID 0 is that the throughput of read and write operations to any file is multiplied by the number of disks because, unlike spanned volumes, reads and writes are done concurrently,[11] and the cost is complete vulnerability to drive failures.</p></li><li><p>RAID 1 Mirroring<br>RAID 1 consists of data mirroring, without parity or striping. Data is written identically to two drives, thereby producing a “mirrored set” of drives. Thus, any read request can be serviced by any drive in the set. If a request is broadcast to every drive in the set, it can be serviced by the drive that accesses the data first (depending on its seek time and rotational latency), improving performance. Sustained read throughput, if the controller or software is optimized for it, approaches the sum of throughputs of every drive in the set, just as for RAID 0. Actual read throughput of most RAID 1 implementations is slower than the fastest drive. Write throughput is always slower because every drive must be updated, and the slowest drive limits the write performance. The array continues to operate as long as at least one drive is functioning.</p></li><li><p>RAID 5 Stripping with Distributed Parity<br>Upon failure of a single drive, subsequent reads can be calculated from the distributed parity such that no data is lost. RAID 5 requires at least three disks.</p></li><li><p>RAID 6 two parity disks<br>RAID 6 consists of block-level striping with double distributed parity. Double parity provides fault tolerance up to two failed drives. This makes larger RAID groups more practical, especially for high-availability systems, as large-capacity drives take longer to restore. RAID 6 requires a minimum of four disks. As with RAID 5, a single drive failure results in reduced performance of the entire array until the failed drive has been replaced.[11] With a RAID 6 array, using drives from multiple sources and manufacturers, it is possible to mitigate most of the problems associated with RAID 5. The larger the drive capacities and the larger the array size, the more important it becomes to choose RAID 6 instead of RAID 5.</p></li></ul><h3 id="database-buffer"><a class="markdownIt-Anchor" href="#database-buffer"></a> Database Buffer</h3><ul><li>A major goal of the database system is to minimize the number of block transfers between the disk and memory.</li><li>The subsystem responsible for the allocation of buffer space is called the buffer manager.</li></ul><h3 id="file-organization"><a class="markdownIt-Anchor" href="#file-organization"></a> File Organization</h3><p><img src="https://i.imgur.com/V8RvRQk.jpg" alt=""></p><p><strong>A fixed length record</strong> is one where the length of the fields in each record has been set to be a certain maximum number of characters long. Suppose a field that was going to contain a name was set to be 25 characters long. This means that the field could only ever contain up to 25 characters. If all the fields in the record have a fixed length like this then the record is said to be a fixed length record. The problem with fixed length records is that each field very rarely contains the maximum number of characters allowed. This means that a lot of space is needlessly set aside and wasted. Also, values sometimes cannot be entered because they are too large to fit inside the allowed space in a field. The advantage of fixed length records is that they make file processing much easier because the start and end of each record is always a fixed number of characters apart. This makes it much easier to locate both indicidual records and fields.<br><img src="https://i.imgur.com/FdzIIl7.png" alt=""></p><p><img src="https://i.imgur.com/O6PKrwj.jpg" alt=""><br>A <strong>variable length record</strong> is one where the length of a field can change to allow data of any size to fit. The advantage of variable length records is that space is not wasted, only the space needed is ever used. The main problem with variable length records is that it is much more difficult to locate the start and end of individual records and fields. This is because they are not separated by a fixed amount of characters. To separate variable length recordseach field has a special character to mark where it ends- called an end- of- field marker. When records need to be located the computer must count through the end- of- field markers to locate individual records and fields.</p><p><img src="https://i.imgur.com/VBlJR9B.png" alt=""></p><p><img src="https://i.imgur.com/6NoscfG.png" alt=""><br><img src="https://i.imgur.com/TXo6UxW.png" alt=""><br><img src="https://i.imgur.com/t6f8Eqi.png" alt=""><br><img src="https://i.imgur.com/cdRtHS5.png" alt=""></p><ul><li>Columnar storage<br>A column-oriented DBMS (or columnar database management system) is a database management system (DBMS) that stores data tables by column rather than by row. Practical use of a column store versus a row store differs little in the relational DBMS world. Both columnar and row databases can use traditional database query languages like SQL to load data and perform queries. Both row and columnar databases can become the backbone in a system to serve data for common extract, transform, load (ETL) and data visualization tools. However, by storing data in columns rather than rows, the database can more precisely access the data it needs to answer a query rather than scanning and discarding unwanted data in rows. Query performance is increased for certain workloads.</li></ul><h3 id="storage-summary"><a class="markdownIt-Anchor" href="#storage-summary"></a> Storage summary</h3><ul><li>Databases must have persistent storage: SSD, HDD Their performance characteristics affect database design</li><li>Buffer manager tries to keep the optimal set of data blocks (pages) in memory to minimize I/O</li><li>must be able to “lock” (pin) a page in memory</li><li>must be able to write / flush page to disk on demand</li><li>Rows comprise both fixed and variable length fields</li><li>Slotted page format is flexible to keep records organized and accessible on a page</li><li>Single column values could be stored in fixed length records, but are usually compressed via encodings</li><li>Compression is used at both column and block level Heap files are ok but most databases use B+ trees</li><li>Columnar storage is another tool in the database tool-kit, soon all DBMS vendors will have it</li></ul><h2 id="indexing-and-hashing"><a class="markdownIt-Anchor" href="#indexing-and-hashing"></a> Indexing and Hashing</h2><h3 id="b-tree"><a class="markdownIt-Anchor" href="#b-tree"></a> B+ tree</h3><ul><li><strong>Properties</strong><ul><li><p>It can be shown that the number of I/O operations needed in the worst case for an insertion is proportional to logn/2(N), where n is the maximum number of pointers in a node, and N is the number of records in the file being indexed.</p></li><li><p>It contains up to n − 1 search-key values K1 , K2 , . . . , Kn − 1 , and n pointers  P1 , P2 , . . . , Pn . The search-key values within a node are kept in sorted order; thus, if i &lt; j, then Ki &lt; Kj<br><img src="https://i.imgur.com/ApVXPRo.png" alt=""></p></li><li><p>Each <strong>non-leaf</strong> node in the tree has between n/2 and n children, where n is fixed for a particular tree.</p></li><li><p>A <strong>non-leaf</strong> node may hold up to n pointers, and must hold at least n/2 pointers. The number of pointers in a node is called the fanout of the node.</p></li><li><p>Each <strong>leaf</strong> can hold up to n − 1 values. We allow leaf nodes to contain as few as (n − 1)/2 values. With n = 4 in our example B±tree, each leaf must contain at least 2 values, and at most 3 values.</p></li><li><p>Since, n = 4 and 1 &lt; (n − 1)/2, we must either merge the node with a sibling node, or redistribute the entries between the nodes, to ensure that each node is at least half-full.</p></li></ul></li><li>Insertion<ul><li>Split</li><li>Coalesce</li></ul></li><li>Deletion<ul><li>if the occupancy of a node falls below 2n/3, the system attempts to borrow an entry from one of the sibling nodes</li><li>Borrow left, pick max one</li><li>Borrow right, pick min one</li><li>Merge left, shift left, change parent</li><li>Merge right, shift right, change parent</li></ul></li><li><strong>Non-unique search key</strong>: If a relation can have more than one record containing the same search key value (that is, two or more records can have the same values for the indexed attributes), the search key is said to be a non-unique search key.</li><li><strong>Bulk-loading in B+ tree</strong><ul><li>Insertion of a large number of entries at a time into an index is referred to as bulk loading of the index.</li><li>sort the file on the search key of the index being constructed</li><li>There is a significant benefit to sorting the entries before inserting them into the B+tree.</li><li>nodes will never have to be read from disk during bulk load, if the B+ tree was empty to start with. Each leaf node will thus incur only one I/O operation even though many entries may be inserted into the node.</li></ul></li><li><strong>bottom-up B+ tree construction</strong><ul><li>it can be constructed faster by building it bottom-up, from the leaf level, instead of using the usual insert procedure.</li><li>we break up the sorted entries into blocks, keeping as many entries in a block as can fit in the block; the resulting blocks form the leaf level of the B±tree. The minimum value in each block, alongwith the pointer to the block, is used to create entries in the next level of the B±tree, pointing to the leaf blocks</li></ul></li></ul><h3 id="hashing"><a class="markdownIt-Anchor" href="#hashing"></a> HASHING</h3><h4 id="static-hashing"><a class="markdownIt-Anchor" href="#static-hashing"></a> Static Hashing</h4><ul><li>We use the term <strong>bucket</strong> to denote a unit of storage that can store one or more records.</li><li>let <strong>K</strong> denote the set of all search-key values, and let <strong>B</strong> denote the set of all bucket addresses. A <strong>hash function h</strong> is a function from K to B. Let h denote a hash function.</li><li>Hash function should be random and uniform</li><li>Algorithm is similiar to Data Structure Hash Table</li></ul><h4 id="dynamic-hashing"><a class="markdownIt-Anchor" href="#dynamic-hashing"></a> Dynamic Hashing</h4><p><img src="https://i.imgur.com/jAg67QV.png" alt=""></p><h3 id="bitmap"><a class="markdownIt-Anchor" href="#bitmap"></a> BITMAP</h3><ul><li>A <strong>bitmap</strong> is simply an array of bits. In its simplest form, a bitmap index on the attribute A of relation r consists of one bitmap for each value that A can take. Each bitmap has as many bits as the number of records in the relation. The ith bit of the bitmap for value vj is set to 1 if the record numbered i has the value vj for attribute A. All other bits of the bitmap are set to 0.</li></ul><p><img src="https://i.imgur.com/bjJkZQR.png" alt=""></p><ul><li>To recognize deleted records,we can store an <strong>existence bitmap</strong>, in which bit i is 0 if record i does not exist and 1 otherwise.<ul><li>If some records have been deleted, however, just computing the complement of a bitmap is not sufficient. Bits corresponding to such records would be 0 in the original bitmap, but would become 1 in the complement, although the records don’t exist.</li></ul></li><li><strong>Limitation</strong><ul><li>If there are further conditions, the fraction of records satisfying all the conditions is likely to be quite small.</li><li>If the fraction is large, scanning the entire relation would remain the cheaper alternative.</li></ul></li><li><strong>Counting the number of bits that are 1 in a bitmap</strong> can be done quickly by a clever technique. We can maintain an array with 256 entries, where the ith entry stores the number of bits that are 1 in the binary representation of i.</li></ul><h3 id="储存与索引总结"><a class="markdownIt-Anchor" href="#储存与索引总结"></a> 储存与索引总结</h3><p>atomicity problem:  transaction is executed totally or not at all<br>integrated storage structure: index file 和record file一起<br>seperate file: 相反</p><p>clustered index 与原数据同顺序<br>clustered indexes do not guarantee sequential storage on the disk. Managing exactly where data is placed on the disk is the job of the OS, not the DBMS. But it suggests that items are ordered generally according to the clustering key.</p><p>With a non clustered index there is a second list that has pointers to the physical rows. You can have many non clustered indexes, although each new index will increase the time it takes to write new records.</p><p>It is generally faster to read from a clustered index if you want to get back all the columns. You do not have to go first to the index and then to the table.</p><p>Writing to a table with a clustered index can be slower, if there is a need to rearrange the data</p><p>primary index: using primary key for indexing</p><p>secondary index: otherwise</p><p>index以block为单位进行index  within block用offset</p><p>hash index  通过哈希函数生成hash address to a bucket with possible overflow chain for managing collision<br>cheaper than B+tree if no overflow occurs Access: O(1+#overflow buckets)<br>所以hash索引的最大的特点就是等值查询快，不能进行范围索引。<br>位图索引适合静态low-cardinality重复数据<br>b树索引同时支持范围及等值查询</p><p>b tree m-way(order m, m fanout, m-1info fields) search tree with additional constraints:  叶子层高度相同 root 2 key  其他节点至少半满ceiling(order/2)来尽量减少高度    若想要插入的位置已满  recursively按中序遍历顺序将中点上移 同时将前驱后继节点分开 始终保持节点半满的要求<br>b+ tree 更贴近多级索引，是在b树基础上, nonleaf node sparse index 减少disk page access  支持equality search 在叶子层将nonleaf节点key按中序遍历顺序拷贝下来 叶子层包含record ptrs 保持中序遍历顺序建立链表 形成dense &amp; clustered index 从而支持range search<br>删除： 左合并 右合并 来满足半满的限制  split if necessary can propagate to root.<br>order=#ptr fields = p    /node<br>#k,v fields = p-1          /node</p><p>(p-1)(key_ptr_size + record_ptr_size) + p(block_ptr_size) &lt;= blocksize=512</p><p>static hashing: linear congruential hash function with fixed #hash buckets  use overflow chain to manage contention</p><p>extendible hashing: nonlinear hashing congruential function such as h_k(v)=h(v) mod 2^k  use directory of size 2^k to store ptrs to hash buckets<br>when collisions happen increment k value and maps it elsewhere</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;cs564-dbms-relational-design-theory&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#cs564-dbms-relational-design-theory&quot;&gt;&lt;/a&gt; &lt;strong&gt;CS564 - D
      
    
    </summary>
    
    
      <category term="Database" scheme="http://th2zz.github.io/tags/Database/"/>
    
  </entry>
  
  <entry>
    <title>Operating System - Virtualization</title>
    <link href="http://th2zz.github.io/2019/03/16/Operating%20System%20-%20Virtualization/"/>
    <id>http://th2zz.github.io/2019/03/16/Operating System - Virtualization/</id>
    <published>2019-03-15T20:06:41.000Z</published>
    <updated>2019-04-11T02:01:28.494Z</updated>
    
    <content type="html"><![CDATA[<h1 id="cs537-operating-system-summary-part-1-virtualization"><a class="markdownIt-Anchor" href="#cs537-operating-system-summary-part-1-virtualization"></a> <strong>CS537 - Operating System Summary Part 1 Virtualization</strong></h1><h1 id="virtualization"><a class="markdownIt-Anchor" href="#virtualization"></a> Virtualization</h1><h2 id="process"><a class="markdownIt-Anchor" href="#process"></a> Process</h2><h3 id="what-is-a-process"><a class="markdownIt-Anchor" href="#what-is-a-process"></a> What is a process</h3><ul><li>A running program is a process</li><li>Stream of executing instructions and their “context”</li></ul><h3 id="thread"><a class="markdownIt-Anchor" href="#thread"></a> Thread</h3><ul><li>Can have multiple threads within a single process</li><li>Lightweight process</li><li>Share an address space</li></ul><h3 id="why-do-we-need-processes"><a class="markdownIt-Anchor" href="#why-do-we-need-processes"></a> Why do we need processes?</h3><ul><li>Share CPU: Time sharing</li></ul><h3 id="os-scheduler"><a class="markdownIt-Anchor" href="#os-scheduler"></a> OS Scheduler</h3><ul><li>Scheduler save context when process is pause</li><li>Restore context on resumption</li></ul><h3 id="goals-for-cpu-virtualization"><a class="markdownIt-Anchor" href="#goals-for-cpu-virtualization"></a> Goals for CPU Virtualization</h3><ul><li><p>Policy goals</p><ul><li>Virtualize CPU resource using processes</li><li>Reschedule process for fairness? efficiency?</li></ul></li><li><p>Mechanism goals</p><ul><li>Efficiency: Time sharing should not add overhead</li><li>Control: OS should be able to intervene when required</li></ul></li></ul><h2 id="mechanism"><a class="markdownIt-Anchor" href="#mechanism"></a> Mechanism</h2><h3 id="system-call"><a class="markdownIt-Anchor" href="#system-call"></a> System call</h3><ul><li><p>User mode and kernel mode</p><ul><li>User processes run in user mode (restricted mode)</li><li>OS runs in kernel mode (not restricted)</li></ul></li><li><p>System call</p><ul><li>Separate user mode from kernel mode for security</li><li>Use system call to invoke kernel mode functions</li></ul></li><li><p>Procedure for calling read()</p><ol><li>Set system call table index to 6 <code>movl $6, %eax</code></li><li>Call trap with id 64 <code>int $64</code></li></ol></li></ul><p><img src="https://i.imgur.com/7hmjTrj.png" alt=""></p><h3 id="dispatch-mechanism"><a class="markdownIt-Anchor" href="#dispatch-mechanism"></a> Dispatch mechanism</h3><ul><li><p>Dispatch loop</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">while (1) &#123;</span><br><span class="line">    runprocessA for some time-slice</span><br><span class="line">    stop process A and save its context</span><br><span class="line">    load context of another process B</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Cooperative Multi-tasking</p><ul><li>Trust process to relinquish CPU through traps</li><li>Provide special yield() system call</li><li>Processes can <strong>misbehave</strong></li></ul></li><li><p>Timer-based Multi-tasking</p><ul><li>Hardware generates timer interrupt (CPU or separate chip)</li><li>User must not be able to mask timer interrupt</li></ul></li></ul><p><img src="https://i.imgur.com/eE325zz.png" alt=""></p><h2 id="policy"><a class="markdownIt-Anchor" href="#policy"></a> Policy</h2><h3 id="vocabulary"><a class="markdownIt-Anchor" href="#vocabulary"></a> Vocabulary</h3><ul><li>Workload: set of jobs (arrival time, run_time)</li><li>Job ~ Current execution of a process</li><li>Scheduler: Decides which ready job to run</li><li>Metric: measurement of scheduling quality</li><li>Turnaround time = completion time - arrival time</li><li>Response time = first run time - arrival time</li></ul><h3 id="fifo-first-in-first-out"><a class="markdownIt-Anchor" href="#fifo-first-in-first-out"></a> FIFO (First In, First Out)</h3><ul><li>Disadvantage: Turnaround time suffers when short jobs must wait for long jobs (Convoy Effect)</li></ul><img src="https://i.imgur.com/p6B5iuB.png" width="75%" style="margin:auto; display: block;"><h3 id="sjf-shortest-job-first"><a class="markdownIt-Anchor" href="#sjf-shortest-job-first"></a> SJF (Shortest job first)</h3><ul><li>Disadvantage: Only schedule new job when previous job voluntarily relinquishes CPU</li></ul><img src="https://i.imgur.com/4L0JHF6.png" width="75%" style="margin:auto; display: block;"><h3 id="stcf-shortest-time-to-completion-first"><a class="markdownIt-Anchor" href="#stcf-shortest-time-to-completion-first"></a> STCF (Shortest Time-to-Completion First)</h3><ul><li>Preemptive: Schedule different job by taking CPU away from running job</li><li>Always run job that will complete the quickest</li></ul><img src="https://i.imgur.com/F97B6qw.png" width="75%" style="margin:auto; display: block;"><h3 id="round-robin"><a class="markdownIt-Anchor" href="#round-robin"></a> Round Robin</h3><ul><li>Goal: reduce response time</li><li>Trade-off: increase turnaround time</li></ul><img src="https://i.imgur.com/aNCUwiF.png" width="75%" style="margin:auto; display: block;"><h3 id="io-aware-scheduling"><a class="markdownIt-Anchor" href="#io-aware-scheduling"></a> I/O Aware Scheduling</h3><ul><li>Goal: process won’t hold CPU when doing IO</li></ul><img src="https://i.imgur.com/S8TUga8.png" width="75%" style="margin:auto; display: block;"><h3 id="multilevel-feedback-queue"><a class="markdownIt-Anchor" href="#multilevel-feedback-queue"></a> Multilevel Feedback Queue</h3><ul><li><p>Motivation: Run-time of each job is not known</p></li><li><p>Approach</p><ul><li>Multiple levels of round-robin</li><li>Each level has higher priority than lower level</li><li>Can preempt them</li></ul></li><li><p>Rules</p><ol><li>If priority(A) &gt; Priority(B), A runs</li><li>If priority(A) == Priority(B), A &amp; B run in RR</li><li>Processes start at top priority</li><li>If job uses whole slice, demote process (longer time slices at lower priorities)</li></ol></li><li><p>Avoid starvation</p><ul><li>Problem: Low priority job may never get scheduled</li><li>Solution: Periodically boost priority of all jobs (or all jobs thathaven’t been scheduled)</li></ul></li></ul><img src="https://i.imgur.com/RL4PuJC.png" width="50%" style="margin:auto; display: block;"><h1 id="memory-virtualization"><a class="markdownIt-Anchor" href="#memory-virtualization"></a> Memory Virtualization</h1><h2 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h2><h3 id="goals"><a class="markdownIt-Anchor" href="#goals"></a> Goals</h3><ul><li><strong>Transparency</strong>: Process is unaware of sharing</li><li><strong>Protection</strong>: Cannot corrupt OS or other process memory</li><li><strong>Efficiency</strong>: Do not waste memory or slow down processes</li><li><strong>Sharing</strong>: Enable sharing between cooperating processes</li></ul><h3 id="address-space"><a class="markdownIt-Anchor" href="#address-space"></a> Address space</h3><ul><li>Stack: No fragmentation</li><li>Heap: Consists of allocated and free areas (holes)<br><img src="https://i.imgur.com/we79L5F.png" alt=""></li></ul><h3 id="memory-access-example"><a class="markdownIt-Anchor" href="#memory-access-example"></a> Memory Access Example</h3><table><thead><tr><th>Assembly</th><th>Access for Instruction</th><th>Access for Execution</th></tr></thead><tbody><tr><td><code>0x10: movl 0x8(%rbp), %edi</code></td><td>Fetch instruction at 0x10</td><td>Load from 0x208</td></tr><tr><td><code>0x13: addl $0x3, %edi</code></td><td>Fetch instruction at 0x13</td><td>No memory access</td></tr><tr><td><code>0x19: movl %edi, 0x8(%rbp)</code></td><td>Fetch instruction at 0x19</td><td>Store to 0x208</td></tr></tbody></table><h2 id="basic-mechanisms"><a class="markdownIt-Anchor" href="#basic-mechanisms"></a> Basic Mechanisms</h2><h3 id="time-sharing"><a class="markdownIt-Anchor" href="#time-sharing"></a> Time Sharing</h3><ul><li>On process switch, save current process’s memory to disk and load another process’s memory from disk.</li><li>Ridiculously poor performance</li></ul><h3 id="static-relocation"><a class="markdownIt-Anchor" href="#static-relocation"></a> Static Relocation</h3><ul><li><p>Idea</p><ul><li>OS rewrites each program before loading it as a process in memory</li><li>Each rewrite for different process uses different addresses and pointers</li><li>Change jumps, loads of static data</li></ul></li><li><p>Disadvantage</p><ul><li>Process can destroy OS or other processes</li><li>No privacy</li><li>Cannot move address space after it has been placed</li><li>May not be able to allocate new process</li></ul></li></ul><p><img src="https://i.imgur.com/840IDak.png" alt=""></p><h3 id="dynamic-relocation-introduction"><a class="markdownIt-Anchor" href="#dynamic-relocation-introduction"></a> Dynamic Relocation: Introduction</h3><ul><li><p>Goal: Protect processes from one another</p></li><li><p>Memory Management Unit (MMU)</p><ul><li>MMU dynamically changes process address at every memory reference</li><li>Process generates <strong>logical</strong> or <strong>virtual</strong> addresses (in their address space)</li><li>Memory hardware uses <strong>physical</strong> or <strong>real</strong> addresses</li></ul></li></ul><p><img src="https://i.imgur.com/1rZVwO8.png" alt=""></p><ul><li>Two operating modes<ul><li><p>Kernel mode</p><ul><li>Can manipulate contents of MMU</li><li>Allows OS to access all of physical memory</li></ul></li><li><p>User mode</p><ul><li>Perform translation of logical address to physical address</li></ul></li></ul></li></ul><h3 id="dynamic-relocation-base-register"><a class="markdownIt-Anchor" href="#dynamic-relocation-base-register"></a> Dynamic Relocation: Base Register</h3><ul><li>Translation on every memory access of user process</li><li>MMU adds base register to logical address to form physical address</li><li>Store offset in base register</li><li>Each process has different value in base register</li><li>Dynamic relocation by changing value of base register.</li></ul><p><img src="https://i.imgur.com/Eika7Rs.png" alt=""></p><ul><li><p>Quiz</p><ul><li>What entity should do translation of addresses with base register? <strong>Hardware</strong></li><li>What entity should modify the base register? <strong>OS</strong></li></ul></li><li><p>Problem: No protection</p></li></ul><h3 id="dynamic-relocation-base-bounds"><a class="markdownIt-Anchor" href="#dynamic-relocation-base-bounds"></a> Dynamic Relocation: Base + Bounds</h3><ul><li><p>Idea</p><ul><li>limit the address space with a bounds register</li><li>Base register: smallest physical addr (or starting location)</li><li>Bounds register: size of this process’s virtual address space</li><li>OS kills process if process loads/stores beyond bounds</li></ul></li><li><p>Implementation</p><ul><li>MMU compares logical address to bounds register</li><li>if logical address is greater, then generate error</li><li>MMU adds base register to logical address to form physical address</li></ul></li></ul><p><img src="https://i.imgur.com/Qoqdgtb.png" alt=""></p><ul><li><p>Context switch</p><ol><li>Change to privileged mode</li><li>Save base and bounds registers of old process</li><li>Load base and bounds registers of new process</li><li>Change to user mode and jump to new process</li></ol></li><li><p>Advantages</p><ul><li>Provides protection (both read and write) across address spaces</li><li>Supports dynamic relocation</li><li>Simple, inexpensive implementation: Few registers, little logic in MMU</li><li>Fast: Add and compare in parallel</li></ul></li><li><p>Disadvantages</p><ul><li>Each process must be allocated contiguously in physical memory</li><li>Must allocate memory that may not be used by process</li><li>No partial sharing: Cannot share limited parts of address space</li></ul></li></ul><h3 id="segmentation"><a class="markdownIt-Anchor" href="#segmentation"></a> Segmentation</h3><ul><li><p>Idea</p><ul><li>MMU contains Segment Table (per process)</li><li>Each segment has own base and bounds, protection bits</li><li>Example: 14 bit logical address, 4 segments;</li></ul></li><li><p>Example</p><ul><li><p>Segment Table</p><table><thead><tr><th>Segment</th><th>Base</th><th>Bounds</th><th>R W</th></tr></thead><tbody><tr><td>0</td><td>0x2000</td><td>0x6ff</td><td>1 0</td></tr><tr><td>1</td><td>0x0000</td><td>0x4ff</td><td>1 1</td></tr><tr><td>2</td><td>0x3000</td><td>0xfff</td><td>1 1</td></tr><tr><td>3</td><td>0x0000</td><td>0x000</td><td>0 0</td></tr></tbody></table></li><li><p>Translation</p><table><thead><tr><th>Logical address</th><th>Segment</th><th>Base</th><th>Physical address</th></tr></thead><tbody><tr><td>0x0240</td><td>0</td><td>0x2000</td><td>0x2240</td></tr><tr><td>0x1108</td><td>1</td><td>0x0000</td><td>0x1108</td></tr><tr><td>0x256c</td><td>2</td><td>0x3000</td><td>0x356c</td></tr><tr><td>0x3002</td><td>3</td><td>0x0000</td><td>Fail</td></tr></tbody></table></li></ul></li><li><p>Advantages</p><ul><li>No extra memory access</li><li>Enables sparse allocation of address space</li><li>Stack and heap can grow independently</li><li>Enables sharing of selected segments</li><li>Read-only status for code</li><li>Supports dynamic relocation of each segment</li></ul></li><li><p>Disadvantages</p><ul><li>Each segment must be allocated contiguously</li><li>May not have sufficient physical memory for large segments?</li><li>External Fragmentation</li></ul></li></ul><h3 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h3><table><thead><tr><th>Description</th><th>Name of approach</th></tr></thead><tbody><tr><td>One process uses RAM at a time</td><td>Time Sharing</td></tr><tr><td>Rewrite code and addresses before running</td><td>Static Relocation</td></tr><tr><td>Add per-process starting location to virt addr to obtain phys addr</td><td>Base</td></tr><tr><td>dynamic approach that verifies address is in valid range</td><td>Base + Bounds</td></tr><tr><td>Several base+bound pairs per process</td><td>Segmentation</td></tr></tbody></table><h2 id="paging"><a class="markdownIt-Anchor" href="#paging"></a> Paging</h2><h3 id="fragmentation"><a class="markdownIt-Anchor" href="#fragmentation"></a> Fragmentation</h3><ul><li><p>Definition</p><ul><li>Free memory that can’t be usefully allocated</li></ul></li><li><p>Types of fragmentation</p><ul><li>External: Visible to allocator (e.g., OS)</li><li>Internal: Visible to requester</li></ul></li></ul><h3 id="introduction-for-paging"><a class="markdownIt-Anchor" href="#introduction-for-paging"></a> Introduction for Paging</h3><ul><li><p>Goal</p><ul><li>Eliminate requirement that address space is contiguous</li><li>Eliminate external fragmentation</li><li>Grow segments as needed</li></ul></li><li><p>Idea</p><ul><li>Divide address spaces and physical memory into fixed-sized pages (usually 4KB)</li></ul></li></ul><h3 id="translation-of-page-addresses"><a class="markdownIt-Anchor" href="#translation-of-page-addresses"></a> Translation of Page Addresses</h3><ul><li>Logical address<ul><li>High-order bits of address designate page number</li><li>Low-order bits of address designate offset within page</li></ul></li></ul><p><img src="https://i.imgur.com/EuMGAwS.png" alt=""></p><ul><li><p>Address Format</p><table><thead><tr><th>Page Size</th><th>Low Bits</th><th>Virt Addr Bits</th><th>High Bits</th><th>Virt Pages</th></tr></thead><tbody><tr><td>16 bytes</td><td>log(16) = 4</td><td>10</td><td>10 - 4 = 6</td><td>2 ^ 6 = 64</td></tr><tr><td>1 KB</td><td>log(1K) = 10</td><td>20</td><td>20 - 10 = 10</td><td>2 ^ 10 = 1024</td></tr><tr><td>1 MB</td><td>log(1M) = 20</td><td>32</td><td>32 - 20 = 12</td><td>2 ^ 12 = 4K</td></tr><tr><td>512 bytes</td><td>log(512) = 9</td><td>16</td><td>16 - 9 = 7</td><td>2 ^ 7 = 128</td></tr><tr><td>4 KB</td><td>log(4K) = 12</td><td>32</td><td>32 -12 = 20</td><td>2 ^ 20 = 1M</td></tr></tbody></table></li><li><p>Address Translation</p><ul><li>Number of bits in virtual address <strong>need not equal</strong> number of bits in physical address</li></ul></li></ul><p><img src="https://i.imgur.com/HZcAtTC.png" alt=""></p><h3 id="pagetables"><a class="markdownIt-Anchor" href="#pagetables"></a> Pagetables</h3><ul><li><p>How should OS translate VPN to PPN?</p><ul><li>Simple solution: Linear page table aka array</li></ul></li><li><p>Example<br><img src="https://i.imgur.com/uWlRJnw.png" alt=""></p><ul><li>Page table for P1: 3, 1, 7, 10</li><li>Page table for P2: 0, 4, 2, 6</li><li>Page table for P3: 8, 5, 9, 11</li></ul></li><li><p>How big is a pagetable</p><ul><li>Given 32-bit address space, 4KB pages, 4 byte entries</li><li>4KB pages =&gt; 12 bit for offset</li><li>32-bit address space =&gt; 20 bit for VPN =&gt; 2 ^ 20 = 1MB entries</li><li>1MB entries * 4 byte per entry = 4MB</li></ul></li><li><p>Where are pagetables stored</p><ul><li>Store each page table in memory</li><li>Hardware finds page table base with register (e.g., CR3 on x86)</li></ul></li><li><p>What happens on a context-switch?</p><ul><li>Change contents of page table base register to newly scheduled process</li><li>Save old page table base register in PCB of descheduled process</li></ul></li><li><p>What other info is in pagetable entries besides translation?</p><ul><li>valid bit</li><li>protection bits</li><li>present bit (needed later)</li><li>reference bit (needed later)</li><li>dirty bit (needed later)</li></ul></li></ul><h3 id="memory-access-with-paging"><a class="markdownIt-Anchor" href="#memory-access-with-paging"></a> Memory Access with Paging</h3><ul><li><p>Given</p><ul><li>Current instruction: <code>0x0010: movl 0x1100, %edi</code></li><li>Assume PT is at phys addr 0x5000</li><li>Assume PTE’s are 4 bytes</li><li>Assume 4KB pages =&gt; 12 bits for offset</li><li>Page table for current process: 2, 0, 80, 99</li></ul></li><li><p>Fetch instruction at logical addr 0x0010</p><ul><li>Access page table to get ppn for vpn 0</li><li>Mem ref 1: 0x5000</li><li>Learn vpn 0 is at ppn 2</li><li>Fetch instruction at 0x2010 (Mem ref 2)</li></ul></li><li><p>Exec, load from logical addr 0x1100</p><ul><li>Access page table to get ppn for vpn 1</li><li>Mem ref 3: 0x5000</li><li>Learn vpn 1 is at ppn 0</li><li>movl from 0x0100 into reg (Mem ref 4)</li></ul></li></ul><h3 id="advantages-of-paging"><a class="markdownIt-Anchor" href="#advantages-of-paging"></a> Advantages of Paging</h3><ul><li><p>No external fragmentation</p><ul><li>Any page can be placed in any frame in physical memory</li></ul></li><li><p>Fast to allocate and free</p><ul><li>Alloc: No searching for suitable free space</li><li>Free: Doesn’t have to coalesce with adjacent free space</li></ul></li><li><p>Simple to swap-out portions of memory to disk (later lecture)</p><ul><li>Page size matches disk block size</li><li>Can run process when some pages are on disk</li><li>Add “present” bit to PTE</li></ul></li></ul><h3 id="disadvantages-of-paging"><a class="markdownIt-Anchor" href="#disadvantages-of-paging"></a> Disadvantages of Paging</h3><ul><li><p>Internal fragmentation: Page size may not match size needed by process</p><ul><li>Wasted memory grows with larger pages</li><li>Tension?</li></ul></li><li><p>Additional memory reference to page table -&gt; Very inefficient</p><ul><li>Page table must be stored in memory</li><li>MMU stores only base address of page table</li></ul></li><li><p>Storage for page tables may be substantial</p><ul><li>Simple page table: Requires PTE for all pages in address space</li><li>Entry needed even if page not allocated?</li></ul></li></ul><h3 id="paging-translation-steps"><a class="markdownIt-Anchor" href="#paging-translation-steps"></a> Paging Translation Steps</h3><ol><li>extract VPN (virt page num) from VA (virt addr)</li><li>calculate addr of PTE (page table entry)</li><li>read PTE from memory</li><li>extract PFN (page frame num)</li><li>build PA (phys addr)</li><li>read contents of PA from memory into register</li></ol><h2 id="tlb"><a class="markdownIt-Anchor" href="#tlb"></a> TLB</h2><h3 id="motivative-example-iterating-array"><a class="markdownIt-Anchor" href="#motivative-example-iterating-array"></a> Motivative Example: Iterating Array</h3><ul><li><p>Code</p>  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++)&#123; </span><br><span class="line">    sum += a[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Memory Access</p><table><thead><tr><th>What virtual addresses?</th><th>What physical addresses?</th></tr></thead><tbody><tr><td>load 0x3000</td><td>load 0x100C <br>load 0x7000</td></tr><tr><td>load 0x3004</td><td>load 0x100C <br>load 0x7004</td></tr><tr><td>load 0x3008</td><td>load 0x100C <br>load 0x7008</td></tr><tr><td>load 0x300C</td><td>load 0x100C <br>load 0x7008</td></tr></tbody></table></li></ul><h3 id="introduction-2"><a class="markdownIt-Anchor" href="#introduction-2"></a> Introduction</h3><ul><li>Strategy: Cache Page Translations</li><li>TLB stands for Translation Lookaside Buffer<br><img src="https://i.imgur.com/mEwtslZ.png" alt=""></li></ul><h3 id="tlb-organization"><a class="markdownIt-Anchor" href="#tlb-organization"></a> TLB Organization</h3><ul><li><p>TLB Entry</p><table><thead><tr><th>Tag (virtual page number)</th><th>Physical page number (page table entry)</th></tr></thead><tbody></tbody></table></li><li><p>Fully associative</p><ul><li>Any given translation can be anywhere in the TLB</li><li>Hardware will search the entire TLB in parallel</li></ul></li></ul><h3 id="example-iterating-array-with-tlb"><a class="markdownIt-Anchor" href="#example-iterating-array-with-tlb"></a> Example: Iterating Array with TLB</h3><ul><li><p>Code</p>  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2048</span>; i++)&#123; </span><br><span class="line">    sum += a[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Page table for current process (starting at 0x0000)</p>  <table>      <tbody>          <tr>              <td>PPN</td>              <td>1</td>              <td>5</td>              <td>4</td>              <td>…</td>          </tr>          <tr>              <td>VPN</td>              <td>0</td>              <td>1</td>              <td>2</td>              <td>3</td>          </tr>      </tbody>  </table></li><li><p>TLB</p><table><thead><tr><th>Valid</th><th>VPN</th><th>PPN</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>5</td></tr><tr><td>1</td><td>2</td><td>4</td></tr></tbody></table></li><li><p>Memory Access</p><table><thead><tr><th>What virtual addresses?</th><th>What physical addresses?</th></tr></thead><tbody><tr><td>load 0x1000</td><td>load 0x0004 <br>load 0x5000</td></tr><tr><td>load 0x1004</td><td>(TLB hit) <br>load 0x5004</td></tr><tr><td>load 0x1008</td><td>(TLB hit) <br>load 0x5008</td></tr><tr><td>load 0x100C</td><td>(TLB hit) <br>load 0x500C</td></tr><tr><td>…</td><td>…</td></tr><tr><td>load 0x2000</td><td>load 0x0008 <br>load 0x4000</td></tr><tr><td>load 0x2004</td><td>(TLB hit) <br>load 0x4004</td></tr></tbody></table></li><li><p>Performance</p><ul><li># TLB lookups = number of accesses to a = 2048</li><li># TLB misses = 2</li><li>Miss rate = 2/2048 = 0.1%</li><li>Hit rate = 1 – miss rate = 99.9%</li></ul></li></ul><h3 id="tlb-replacement-policies"><a class="markdownIt-Anchor" href="#tlb-replacement-policies"></a> TLB Replacement Policies</h3><ul><li><p>Access Patterns</p><ul><li>Sequential array accesses almost always hit in TLB: Very fast!</li><li>Highly random, with no repeat accesses: Slow</li></ul></li><li><p>Code Example</p><table><thead><tr><th>Workload A</th><th>Workload B</th></tr></thead><tbody><tr><td><img src="https://i.imgur.com/fg4fYXO.png" alt=""></td><td><img src="https://i.imgur.com/b3eYUnz.png" alt=""></td></tr><tr><td></td><td></td></tr><tr><td><img src="https://i.imgur.com/HWMGImG.png" alt=""></td><td><img src="https://i.imgur.com/iMYOS03.png" alt=""></td></tr></tbody></table></li><li><p>Workload Locality</p><ul><li>Spatial Locality: future access will be to nearby addresses</li><li>Temporal Locality: future access will be repeats to the same data</li></ul></li><li><p>What TLB characteristics are best for each type?</p><ul><li><p>Spatial:</p><ul><li>Access same page repeatedly; need same vpn à ppn translation</li><li>Same TLB entry re-used</li></ul></li><li><p>Temporal:</p><ul><li>Access same address near in future</li><li>Same TLB entry re-used in near future</li><li>How near in future? How many TLB entries are there?</li></ul></li></ul></li><li><p>Replacement policies</p><ul><li>LRU: evict Least-Recently Used TLB slot when needed</li><li>Random: Evict randomly choosen entry</li></ul></li></ul><h3 id="context-switches"><a class="markdownIt-Anchor" href="#context-switches"></a> Context Switches</h3><ul><li><p>What happens if a process uses cached TLB entries from another process?</p><ol><li><p>Flush TLB on each switch</p><ul><li>Costly</li><li>lose all recently cached translations</li></ul></li><li><p>Track which entries are for which process</p><ul><li>Address Space Identifier</li><li>Tag each TLB entry with an 8-bit ASID</li></ul></li></ol></li><li><p>TLB Example with ASID</p><ul><li><p>Pagetable</p><ul><li>P1 (ASID 11): 1, 5, 4, …</li><li>P2 (ASID 12): 6, 2, 3, …</li></ul></li><li><p>TLB</p><table><thead><tr><th>Valid</th><th>Virt</th><th>Phys</th><th>ASID</th></tr></thead><tbody><tr><td>0</td><td>1</td><td>9</td><td>11</td></tr><tr><td>1</td><td>1</td><td>5</td><td>11</td></tr><tr><td>1</td><td>1</td><td>2</td><td>12</td></tr><tr><td>1</td><td>0</td><td>1</td><td>11</td></tr></tbody></table></li><li><p>Memory access</p><table><thead><tr><th>Virtual</th><th>Physical</th></tr></thead><tbody><tr><td>load 0x1444 with ASID 12</td><td>0x2444</td></tr><tr><td>load 0x1444 with ASID 11</td><td>0x5444</td></tr></tbody></table></li></ul></li><li><p>TLB Performance</p><ul><li><p>Context switches are expensive</p></li><li><p>Even with ASID, other processes “pollute” TLB</p><ul><li>Discard process A’s TLB entries for process B’s entries</li></ul></li><li><p>Architectures can have multiple TLBs</p><ul><li>1 TLB for data, 1 TLB for instructions</li><li>1 TLB for regular pages, 1 TLB for “super pages”</li></ul></li></ul></li></ul><h3 id="tlb-misses"><a class="markdownIt-Anchor" href="#tlb-misses"></a> TLB Misses</h3><ul><li><p>Who Handles TLB MISS? Hardware or OS?</p></li><li><p>Hardware: CPU must know where pagetables are</p><ul><li>CR3 register on x86</li><li>Pagetable structure fixed and agreed upon between HW and OS</li><li>HW “walks” the pagetable and fills TLB</li></ul></li><li><p>OS: “Software-managed TLB”</p><ul><li>CPU traps into OS upon TLB miss</li><li>OS interprets pagetables as it chooses</li><li>Modifying TLB entries is privileged</li><li>Need same protection bits in TLB as pagetable - rwx</li></ul></li></ul><h3 id="summary-2"><a class="markdownIt-Anchor" href="#summary-2"></a> Summary</h3><ul><li><p>Pages are great, but accessing page tables for every memory access is slow</p></li><li><p>Cache recent page translations -&gt; TLB</p><ul><li>Hardware performs TLB lookup on every memory access</li></ul></li><li><p>TLB performance depends strongly on workload</p><ul><li>Sequential workloads perform well</li><li>Workloads with temporal locality can perform well</li></ul></li><li><p>In different systems, hardware or OS handles TLB misses</p></li><li><p>TLBs increase cost of context switches</p><ul><li>Flush TLB on every context switch</li><li>Add ASID to every TLB entry</li></ul></li></ul><h2 id="smaller-page-tables"><a class="markdownIt-Anchor" href="#smaller-page-tables"></a> Smaller Page Tables</h2><h3 id="motivation"><a class="markdownIt-Anchor" href="#motivation"></a> Motivation</h3><ul><li><p>How big are page tables</p><ol><li><p>PTE’s are 2 bytes, and 32 possible virtual page numbers</p><ul><li>2 bytes * 32 = 64 bytes</li></ul></li><li><p>PTE’s are 2 bytes, virtual addrs are 24 bits, pages are 16 bytes</p><ul><li>16 bytes page =&gt; 4 bit offset =&gt; 20 bit VPN</li><li>=&gt; 2^20 Pages =&gt;  2^20 * 2 = 2MB for page tables</li></ul></li><li><p>PTE’s are 4 bytes, virtual addrs are 32 bits, and pages are 4 KB</p><ul><li>4KB page =&gt; 12 bit offset =&gt; 20 bit VPN</li><li>=&gt; 2^20 Pages =&gt;  2^20 * 4 = 4MB for page tables</li></ul></li><li><p>PTE’s are 4 bytes, virtual addrs are 64 bits, and pages are 4 KB</p><ul><li>4KB page =&gt; 12 bit offset =&gt; 52 bit VPN</li><li>=&gt; 2^52 Pages =&gt;  2^52 * 4 = 18.0143985 PB for page tables</li></ul></li></ol></li><li><p>Why are Page Tables so Large?</p><ul><li>Many invalid PT entries</li></ul></li></ul><p><img src="https://i.imgur.com/hw6UrkL.png" alt=""></p><ul><li>Summary<ul><li><p>Storage for page tables may be substantial</p></li><li><p>Simple page table: Requires PTE for all pages in address space</p></li><li><p>Entry needed even if page not allocated.</p></li></ul></li></ul><h3 id="smaller-page-tables-2"><a class="markdownIt-Anchor" href="#smaller-page-tables-2"></a> Smaller Page Tables</h3><ul><li><p>Use more complex page tables, instead of just big array</p></li><li><p>Any data structure is possible with software-managed TLB</p><ul><li><p>Hardware looks for vpn in TLB on every memory access</p></li><li><p>If TLB does not contain vpn, TLB miss</p><ul><li>Trap into OS and let OS find vpn-&gt;ppn translation</li><li>OS notifies TLB of vpn-&gt;ppn for future accesses</li></ul></li></ul></li><li><p>Other approaches</p><ol><li><p>Segmented Pagetables</p></li><li><p>Multi-level Pagetables</p><ul><li>Page the page tables</li><li>Page the pagetables of page tables…</li></ul></li><li><p>Inverted Pagetables</p></li></ol></li></ul><h3 id="paging-with-segmentation"><a class="markdownIt-Anchor" href="#paging-with-segmentation"></a> Paging with Segmentation</h3><ul><li><p>Idea</p><ul><li><p>Divide address space into segments (code, heap, stack)</p></li><li><p>Divide each segment into fixed-sized pages</p></li><li><p>Logical address divided into three portions</p><table><thead><tr><th>seg # (4 bits)</th><th>page number (8 bits)</th><th>page offset (12 bits)</th></tr></thead><tbody></tbody></table></li></ul></li><li><p>Implementation</p><ul><li>Each segment has a page table</li><li>Each segment track base (physical address) and bounds of the page table</li></ul></li><li><p>Quiz</p><ul><li><p>Logical address layout</p><table><thead><tr><th>seg # (4 bits)</th><th>page number (8 bits)</th><th>page offset (12 bits)</th></tr></thead><tbody></tbody></table></li><li><p>Segment Table</p><table><thead><tr><th>Segment</th><th>Base</th><th>Bounds</th><th>R W</th></tr></thead><tbody><tr><td>0</td><td>0x002000</td><td>0xff</td><td>1 0</td></tr><tr><td>1</td><td>0x000000</td><td>0x00</td><td>0 0</td></tr><tr><td>2</td><td>0x001000</td><td>0x0f</td><td>1 1</td></tr></tbody></table></li><li><p>Translation</p><table><thead><tr><th>Virtual</th><th>Seg</th><th>Base</th><th>Offset</th><th>PPN</th><th>Physical</th><th>Note</th></tr></thead><tbody><tr><td>0x002070 R</td><td>0</td><td>0x002000</td><td>2</td><td>0x004</td><td>0x004070</td><td></td></tr><tr><td>0x202016 R</td><td>2</td><td>0x001000</td><td>2</td><td>0x003</td><td>0x003016</td><td></td></tr><tr><td>0x104c84 R</td><td>1</td><td>-</td><td>-</td><td>-</td><td>-</td><td>R = 0</td></tr><tr><td>0x010424 W</td><td>0</td><td>-</td><td>-</td><td>-</td><td>-</td><td>W = 0</td></tr><tr><td>0x210014 W</td><td>2</td><td>-</td><td>-</td><td>-</td><td>-</td><td>bounds</td></tr><tr><td>0x203568 W</td><td>2</td><td>0x001000</td><td>3</td><td>0x02a</td><td>0x02a568</td><td></td></tr></tbody></table></li></ul></li><li><p>Advantages</p><ul><li><p>Advantages of Segments</p><ul><li>Supports sparse address spaces.</li><li>Decreases size of page tables. If segment not used, not need for page table</li></ul></li><li><p>Advantages of Pages</p><ul><li>No external fragmentation</li><li>Segments can grow without any reshuffling</li><li>Can run process when some pages are swapped to disk (next lecture)</li></ul></li><li><p>Advantages of Both</p><ul><li>Increases flexibility of sharing: Share either single page or entire segment</li></ul></li></ul></li><li><p>Disadvantages</p><ul><li>Potentially large page tables (for each segment)</li><li>Must allocate each page table contiguously</li><li>More problematic with more address bits</li></ul></li></ul><h3 id="multilevel-page-tables"><a class="markdownIt-Anchor" href="#multilevel-page-tables"></a> Multilevel Page Tables</h3><ul><li><p>Goal: Allow each page tables to be allocated non-contiguously</p></li><li><p>Idea: Page the page tables</p><ul><li>Creates multiple levels of page tables; outer level “page directory”</li><li>Only allocate page tables for pages in use</li><li>Used in x86 architectures (hardware can walk known structure)</li></ul></li></ul><p><img src="https://i.imgur.com/9bSULQI.png" alt=""></p><ul><li><p>Multilevel Pagetable Translation</p><ul><li><p>Page directory and page tables</p><table><thead><tr><th></th><th>0x0</th><th>0x1</th><th>…</th><th>0xE</th><th>0xF</th></tr></thead><tbody><tr><td>Page directory</td><td>0x3</td><td>-</td><td>…</td><td>-</td><td>0x92</td></tr><tr><td>PT @PPN 0x3</td><td>0x10</td><td>0x23</td><td>…</td><td>-</td><td>-</td></tr><tr><td>PT @PPN 0x92</td><td>-</td><td>-</td><td>…</td><td>0x55</td><td>0x45</td></tr></tbody></table></li><li><p>Address layout</p><table><thead><tr><th>outer page (4)</th><th>inner page (4)</th><th>page offset (12)</th></tr></thead><tbody></tbody></table></li></ul><ol><li><p>Translate 0x01ABC</p><ul><li>Outer page = 0x0 =&gt; Use page table at 0x3</li><li>Inner page = 0x1 =&gt; PPN = 0x23</li><li>Physical address = 0x23ABC</li></ul></li><li><p>Translate 0xFEED0</p><ul><li>Outer page = 0xF =&gt; Use page table at 0x92</li><li>Inner page = 0xE =&gt; PPN = 0x55</li><li>Physical address = 0x55ED0</li></ul></li></ol></li><li><p>Address Format for Multilevel Paging</p><ul><li>Given 30-bit address with 4KB page size</li><li>#bits for page offset = log(4K) = 12</li><li>4 bytes per PTE =&gt; 1K entries per page =&gt; #bits for inner page = log(1K) = 10</li><li>#bits for outer page = 30 - 10 - 12 = 8</li></ul></li><li><p>Pagetable with 3 levels</p><ul><li><p>Problem</p><ul><li>Page directories (outer level) may not fit in a page</li></ul></li><li><p>Solution</p><ul><li>Split page directories into pieces</li><li>Use another page dir to refer to the page dir pieces.</li></ul></li><li><p>Memory Addressability Comparison</p><ul><li>1 level = 2<sup>10</sup> * 2<sup>12</sup> = 4MB</li><li>2 level = (2<sup>10</sup>)<sup>2</sup> * 2<sup>12</sup> = 4GB</li><li>3 level = (2<sup>10</sup>)<sup>3</sup> * 2<sup>12</sup> = 4TB</li></ul></li></ul></li><li><p>Quiz: Count Memory Access</p><ul><li><p>Assumption</p><ul><li>3-level page table</li><li>256-byte pages</li><li>16-bit addresses</li><li>ASIC of current process is 211</li></ul></li><li><p>TLB</p><table><thead><tr><th>ASID</th><th>VPN</th><th>PFN</th><th>Valid</th></tr></thead><tbody><tr><td>211</td><td>0xbb</td><td>0x91</td><td>1</td></tr><tr><td>211</td><td>0xff</td><td>0x23</td><td>1</td></tr><tr><td>122</td><td>0x05</td><td>0x91</td><td>1</td></tr><tr><td>211</td><td>0x05</td><td>0x12</td><td>0</td></tr></tbody></table></li></ul><ol><li><p>0xAA10: movl 0x1111, %edi</p><ul><li><p>TLB miss for 0xAA10 =&gt; 3 memory accesses for page table + 1 more to get the instruction</p></li><li><p>TLB miss for 0x1111 =&gt; 3 memory accesses for page table + 1 more to get the instruction</p></li><li><p>Total: 4 memory accesses</p></li></ul></li><li><p>0xBB13: addl $0x3, %edi</p><ul><li>TLB hit for 0xBB13 =&gt; 1 access more to get the instruction</li></ul></li><li><p>0x0519: movl %edi, 0xFF10</p><ul><li><p>TLB miss for 0x0519 =&gt; 3 memory access for page table + 1 more to get the instruction</p></li><li><p>TLB hit for 0xFF10 =&gt; 1 access more to get the instruction</p></li><li><p>Total: 5 memory accesses</p></li></ul></li></ol></li></ul><h3 id="inverted-page-table"><a class="markdownIt-Anchor" href="#inverted-page-table"></a> Inverted Page Table</h3><ul><li><p>Only need entries for virtual pages w/ valid physical mappings</p></li><li><p>Naïve approach:</p><ul><li>Search through data structure &lt;ppn, vpn+asid&gt; to find match</li><li>Too much time to search entire table</li></ul></li><li><p>Better:</p><ul><li>Find possible matches entries by hashing vpn+asid</li><li>Smaller number of entries to search for exact match</li></ul></li><li><p>Managing inverted page table requires software-controlled TLB</p></li></ul><h2 id="swapping"><a class="markdownIt-Anchor" href="#swapping"></a> Swapping</h2><h3 id="motivation-2"><a class="markdownIt-Anchor" href="#motivation-2"></a> Motivation</h3><ul><li>Support processes when not enough physical memory</li><li>Single process with very large address space</li><li>Multiple processes with combined address spaces</li></ul><h3 id="idea"><a class="markdownIt-Anchor" href="#idea"></a> Idea</h3><ul><li><p>OS keeps unreferenced pages on disk</p><ul><li>Slower, cheaper backing store than memory</li></ul></li><li><p>Process can run when not all pages are loaded into main memory</p></li><li><p>OS and hardware cooperate to make large disk seem like memory</p><ul><li>Same behavior as if all of address space in main memory</li></ul></li></ul><h3 id="locality-of-reference"><a class="markdownIt-Anchor" href="#locality-of-reference"></a> Locality of Reference</h3><ul><li><p>Leverage locality of reference within processes</p><ul><li>Spatial: reference memory addresses near previously referenced addresses</li><li>Temporal: reference memory addresses that have referenced in the past</li><li>Processes spend majority of time in small portion of code</li></ul></li><li><p>Implication:</p><ul><li>Process only uses small amount of address space at any moment</li><li>Only small amount of address space must be resident in physical memory</li></ul></li><li><p>Memory Hierarchy</p><p><img src="https://i.imgur.com/pi58bfR.png" alt=""></p></li></ul><h3 id="mechanism-2"><a class="markdownIt-Anchor" href="#mechanism-2"></a> Mechanism</h3><ul><li><p>Each page in virtual address space maps to one of three locations:</p><ul><li>Physical main memory: Small, fast, expensive</li><li>Disk (backing store): Large, slow, cheap</li><li>Nothing (error): Free</li></ul></li><li><p>Extend page tables with an extra bit: present</p><ul><li>permissions (r/w), valid, present</li><li>Page in memory: present bit set in PTE</li><li>Page on disk: present bit cleared<ul><li>PTE points to block on disk</li><li>Causes trap into OS when page is referenced</li></ul></li></ul></li><li><p>Procedure</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Hardware checks TLB</span><br><span class="line"><span class="keyword">if</span> TLB hit</span><br><span class="line">    address translation is done</span><br><span class="line">    page in physical memory</span><br><span class="line"><span class="keyword">else</span> <span class="comment">// TLB miss</span></span><br><span class="line">    Hardware <span class="keyword">or</span> OS walk page tables</span><br><span class="line">    <span class="keyword">if</span> PTE designates page is present</span><br><span class="line">        page in physical memory (i.e., present bit is cleared)</span><br><span class="line">    <span class="keyword">else</span> <span class="comment">// page fault</span></span><br><span class="line">        Trap into OS (<span class="keyword">not</span> handled by hardware)</span><br><span class="line">        OS selects victim page in memory to replace</span><br><span class="line">        <span class="keyword">if</span> victim page is modified</span><br><span class="line">            write victim page out to disk</span><br><span class="line">        OS reads referenced page from disk into memory</span><br><span class="line">        Page table is updated, present bit is <span class="built_in">set</span></span><br><span class="line">        Process continues execution</span><br></pre></td></tr></table></figure></li></ul><h3 id="policy-page-selection"><a class="markdownIt-Anchor" href="#policy-page-selection"></a> Policy: Page selection</h3><ul><li><p>When should a page on disk be brought into memory?</p></li><li><p>Demand paging: Load page only when page fault occurs</p><ul><li>Intuition: Wait until page must absolutely be in memory</li><li>When process starts: No pages are loaded in memory</li><li>Problems: Pay cost of page fault for every newly accessed page</li></ul></li><li><p>Prepaging (anticipatory, prefetching): Load page before referenced</p><ul><li>OS predicts future accesses (oracle) and brings pages into memory early</li><li>Works well for some access patterns (e.g., sequential)</li></ul></li><li><p>Hints: Combine above with user-supplied hints about page references</p><ul><li>User specifies: may need page in future, don’t need this page anymore, or sequential access pattern, …</li><li>Example: madvise() in Unix</li></ul></li></ul><h3 id="policy-page-replacement"><a class="markdownIt-Anchor" href="#policy-page-replacement"></a> Policy: Page replacement</h3><ul><li><p>Which resident page in memory should be thrown out to disk?</p></li><li><p>OPT: Replace page not used for longest time in future</p><ul><li>Advantages: Guaranteed to minimize number of page faults</li><li>Disadvantages: Requires that OS predict the future; Not practical, but good for comparison</li></ul></li><li><p>FIFO: Replace page that has been in memory the longest</p><ul><li>Intuition: First referenced long time ago, done with it now</li><li>Advantages: Fair: All pages receive equal residency; Easy to implement</li><li>Disadvantage: Some pages may always be needed</li></ul></li><li><p>LRU: Replace page not used for longest time in past</p><ul><li>Intuition: Use past to predict the future</li><li>Advantages: With locality, LRU approximates OPT</li><li>Disadvantages: Harder to implement and does not handle all workloads well</li></ul></li><li><p>Comparison</p><table><thead><tr><th>LRU, OPT</th><th>FIFO</th></tr></thead><tbody><tr><td>Guaranteed to  have fewer page faults<br>Smaller memory sizes ⊆ larger memory sizes<br>Smaller cache ⊆ bigger cache</td><td>Usually have fewer page faults <br>May actually have more page faults!</td></tr></tbody></table></li></ul><h3 id="implementing-lru"><a class="markdownIt-Anchor" href="#implementing-lru"></a> Implementing LRU</h3><ul><li><p>Software Perfect LRU</p><ul><li>OS maintains ordered list of physical pages by reference time</li><li>When page is referenced: Move page to front of list</li><li>When need victim: Pick page at back of list</li><li>Trade-off: Slow on memory reference, fast on replacement</li></ul></li><li><p>Hardware Perfect LRU</p><ul><li>Associate timestamp register with each page</li><li>When page is referenced: Store system clock in register</li><li>When need victim: Scan through registers to find oldest clock</li><li>Trade-off: Fast on memory reference, slow on replacement (especially as size of memory grows)</li></ul></li><li><p>Approximating LRU: Clock Algorithm</p><ul><li><p>Hardware</p><ul><li>Keep use (or reference) bit for each page frame</li><li>When page is referenced: set use bit (page was used recently)</li></ul></li><li><p>Operating System</p><ul><li>Page replacement: Look for page with use bit cleared (has not been referenced for a while)</li></ul><ol><li>Keep pointer to last examined page frame</li><li>Traverse pages in circular buffer</li><li>Clear use bits as search</li><li>Stop when find page with already cleared use bit, replace this page</li></ol></li></ul></li></ul><img src="https://i.imgur.com/WYNCIhZ.png" style="margin:auto; display: block;"><h2 id="summary-3"><a class="markdownIt-Anchor" href="#summary-3"></a> Summary</h2><ul><li><p>Abstraction: Virtual address space with code, heap, stack</p></li><li><p>Address translation</p><ul><li>Contiguous memory: base, bounds, segmentation</li><li>Using fixed sizes pages with page tables</li></ul></li><li><p>Challenges with paging</p><ul><li>Extra memory references: avoid with TLB</li><li>Page table size: avoid with multi-level paging, inverted page tables etc.</li></ul></li><li><p>Larger address spaces: Swapping mechanisms, policies (LRU, Clock)</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;cs537-operating-system-summary-part-1-virtualization&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#cs537-operating-system-summary-part-1-virt
      
    
    </summary>
    
    
      <category term="OS" scheme="http://th2zz.github.io/tags/OS/"/>
    
  </entry>
  
  <entry>
    <title>Process Control</title>
    <link href="http://th2zz.github.io/2019/02/11/process%20control/"/>
    <id>http://th2zz.github.io/2019/02/11/process control/</id>
    <published>2019-02-10T20:15:32.000Z</published>
    <updated>2019-03-20T22:41:52.066Z</updated>
    
    <content type="html"><![CDATA[<h1 id="进程控制"><a class="markdownIt-Anchor" href="#进程控制"></a> 进程控制</h1><ul><li>pid</li><li>fork</li><li>wait</li><li>exec</li></ul><h2 id="pid"><a class="markdownIt-Anchor" href="#pid"></a> pid</h2><p>每一个进程都有一个独特的非负整型pid</p><p>pid可以用来生成独特的文件名</p><p>进程终止时 pid会被回收重用</p><p>大部分unix系统会有代码来延迟重用从而保证新创建的进程和刚刚终止的进程pid相同</p><p>pid 1 通常为init process， 会在启动结束时被kernel invoke其program file在/etc/init （老版本的UNIX系统）或者/sbin/init   （较新版本。 这个进程负责bring up unix system after kernel has been bootstrapped by reading system-dependent initialization files: the /etc/rc* files or /etc/inittab and the files in /etc/init.d. 来带系统进入一定的状态：比如多用户状态。</p><p>init process is a user process (with superuser privileges) that never dies.</p><p>例子： mac os X 10.4里的launchd process</p><p>通常每个unix系统有自己的内核进程， 有的系统pid2时pagedaemon 负责支持系统虚拟内存paging</p><p>以下所有函数都没有error return</p><p><img src="/img_rand/a1.png" alt=""></p><h2 id="fork"><a class="markdownIt-Anchor" href="#fork"></a> fork</h2><p>现存进程可以用fork来创建新进程</p><p><img src="/img_rand/a2.png" alt=""></p><p>这个函数被call一次会返回两次</p><p>在子进程中返回值为0 原因：子进程只能有一个父进程 可以getppid来获得</p><p>parent process返回值为子进程pid 原因：避免子进程pid被其他进程获</p><p>子进程父进程在fork之后会继续执行接下来的命令</p><p>The child is a copy of the parent. For example, the child gets a copy of the parent’s data space, heap, and stack. 但是会share text segment</p><p>Modern implementations don’t perform a complete copy of the parent’s data, stack, and heap, since a fork is often followed by an exec. Instead, a technique called copy-on-write (COW) is used. These regions are shared by the parent and the child and have their protection changed by the kernel to read-only. If either process tries to modify these regions, the kernel then makes a copy of that piece of memory only, typically a ‘‘page’’ in a virtual memory system. </p><p><img src="/img_rand/a3.png" alt=""></p><p>通常父子进程执行顺序是nondeterministic的 这取决与kernel的调度算法</p><p>若需要sychronize action 可以使用如上代码中的sleep来使父进程等待子进程的执行， 但我们没有保证2秒的时间是合适的</p><p>其他同步方式 race conditions section 8.9  signal section 10.16</p><p>sizeof 和 strlen的 区别：</p><p>When we write to standard output, we subtract 1 from the size of buf to avoid writing the terminating null byte. Although strlen will calculate the length of a string not including the terminating null byte, sizeof calculates the size of the buffer, which does include the terminating null byte. </p><p>Another difference is that using strlen requires a function call, whereas sizeof calculates the buffer length at compile time,(更快) as the buffer is initialized with a known string and its size is fixed.</p><p>为什么打印了两遍？write是没有缓冲的。 stdio库是有缓冲的：stdout如果连接着terminal device 会被line buffered 否则会被fully buffered</p><p>所以刚开始的printf缓存区被清空了 但当我们重定向输出到文件的时候 printf打印了两行。 在第二个情况下 printf在fork前被呼叫了1次，但在呼叫fork后buffer里缓存还在，buffer里的内容被拷贝到子进程 此时父子进程都有这个相同的 内容没被清空的buffer。 最后一个printf appends its data to the existing buffer.进程终止时 缓存区清空.</p>### file shareing<p>当我们重定向父进程的stdout输出的时候 子进程stdout也被重定向</p><p>这是fork的一个特性： all file descriptors that are open in the parent are duplicated in the child. The parent and the child share a file table entry for every open descriptor </p><p>也就是说 父子进程同时进行输出到stdout时 一定要共享file offset. 若父进程输出被重定向，我们需要子进程在输出到stdout时更新父进程file offset。 这样不仅子进程可以在父进程wait时候输出到stdout，在子进程结束输出时父进程可以在同位置继续之前的输出。 如果没有共享file offset 这种互动会很难实现</p><p><img src="/img_rand/a4.png" alt=""></p><p>通常有两种情况来处理 fork之后的descriptors的使用</p><ol><li>父进程等待子进程结束：parent need to do nothing. 任何共享的descriptors会被子进程更新</li><li>父进程子进程都有自己的事情要干：fork之后父子进程各自关闭其不需要的descriptors，open descriptors互不干涉 这种情况常见于网络服务器</li></ol><p>其他被子进程继承的属性：</p><ul><li>Real user ID, real group ID, effective user ID, and effective group ID</li><li>Supplementary group IDs</li><li>Process group ID</li><li>Session ID</li><li>Controlling terminal</li><li>The set-user-ID and set-group-ID flags</li><li>Current working directory</li><li>Root directory</li><li>File mode creation mask</li><li>Signal mask and dispositions</li><li>The close-on-exec flag for any open file descriptors</li><li>Environment</li><li>Attached shared memory segments</li><li>Memory mappings</li><li>Resource limits</li></ul><p>父子进程的区别：</p><ul><li>fork返回值</li><li>pid</li><li>ppid</li><li>子进程的tms_utime, tms_stime, tms_cutime, and tms_cstime值为0</li><li>父进程的文件锁不会被子进程继承</li><li>Pending alarms are cleared for the child.</li><li>The set of pending signals for the child is set to the empty set.</li></ul><p>fork通常失败的原因有 太多进程存在于系统或者 对于当前用户进程数量超过系统限制： CHILD_MAX specifies the maximum number of simultaneous processes per real user ID.</p><p>fork 的两种使用</p><ul><li>当一个进程想要自我复制从而 父子进程同时执行一片相同的代码时：常见于网络服务器 the parent waits for a service request from a client. When the request arrives, the parent calls fork and lets the child handle the request. The parent goes back to waiting for the next service request to arrive. </li><li>当一个进程想要执行一个不同的程序 这种情况下通常子进程使用exec right after it returns from the fork.（spawn by some other OS）</li></ul>## wait<p>When a process terminates, either normally or abnormally, the kernel notifies the parent by sending the SIGCHLD signal to the parent.</p><p>Because the termination of a child is an asynchronous event—it can happen at any time while the parent is running—this signal is the asynchronous notification from the kernel to the parent.</p><p>The parent can choose to ignore this signal, or it can provide a function that is called when the signal occurs: a signal handler. </p><p>The default action for this signal is to be ignored.</p><p>For now, we need to be aware that a process that calls wait or waitpid can:</p><ul><li>Block, if all of its children are still running</li><li>Return immediately with the termination status of a child, if a child has terminated and is waiting for its termination status to be fetched</li><li>Return immediately with an error, if it doesn’t have any child processes</li></ul><p>If the process is calling wait because it received the SIGCHLD signal, we expect wait to return immediately. But if we call it at any random point in time, it can block.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;进程控制&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#进程控制&quot;&gt;&lt;/a&gt; 进程控制&lt;/h1&gt;
&lt;ul&gt;
	&lt;li&gt;pid&lt;/li&gt;
	&lt;li&gt;fork&lt;/li&gt;
	&lt;li&gt;wait&lt;/li&gt;
	&lt;li&gt;exec&lt;/li&gt;
&lt;/ul&gt;
      
    
    </summary>
    
    
      <category term="OS" scheme="http://th2zz.github.io/tags/OS/"/>
    
  </entry>
  
  <entry>
    <title>Automata, language, and computational complexity</title>
    <link href="http://th2zz.github.io/2018/12/25/TCS/"/>
    <id>http://th2zz.github.io/2018/12/25/TCS/</id>
    <published>2018-12-25T01:22:41.000Z</published>
    <updated>2019-03-20T21:15:44.035Z</updated>
    
    <content type="html"><![CDATA[<h2 id="参考课程内容-httpscoursesengrillinoiseducs373sp2013lectures"><a class="markdownIt-Anchor" href="#参考课程内容-httpscoursesengrillinoiseducs373sp2013lectures"></a> <strong>参考课程内容</strong> <a href="https://courses.engr.illinois.edu/cs373/sp2013/Lectures/" target="_blank" rel="noopener">https://courses.engr.illinois.edu/cs373/sp2013/Lectures/</a></h2><h4 id="nfa-to-dfa-subset-construction"><a class="markdownIt-Anchor" href="#nfa-to-dfa-subset-construction"></a> <strong>NFA to DFA subset construction</strong></h4><p><a href="https://www.youtube.com/watch?v=Y92dtMnarAU&amp;list=PLBlnK6fEyqRgp46KUv4ZY69yXmpwKOIev&amp;index=19" target="_blank" rel="noopener">https://www.youtube.com/watch?v=Y92dtMnarAU&amp;list=PLBlnK6fEyqRgp46KUv4ZY69yXmpwKOIev&amp;index=19</a></p><h4 id="ε-nfa-to-nfa-algorithm"><a class="markdownIt-Anchor" href="#ε-nfa-to-nfa-algorithm"></a> <strong>ε-NFA to NFA Algorithm</strong></h4><p><a href="https://www.youtube.com/watch?v=Jz4YQ09nOxA&amp;index=44&amp;list=PLBlnK6fEyqRgp46KUv4ZY69yXmpwKOIev" target="_blank" rel="noopener">https://www.youtube.com/watch?v=Jz4YQ09nOxA&amp;index=44&amp;list=PLBlnK6fEyqRgp46KUv4ZY69yXmpwKOIev</a></p><h4 id="dfa-to-regular-expression-state-elimination"><a class="markdownIt-Anchor" href="#dfa-to-regular-expression-state-elimination"></a> <strong>DFA to regular expression State Elimination</strong></h4><p><a href="https://www.youtube.com/watch?v=fyJumUElTGY" target="_blank" rel="noopener">https://www.youtube.com/watch?v=fyJumUElTGY</a></p><h4 id="dfa-to-regex-dynamic-programmingtransitive-closure-method"><a class="markdownIt-Anchor" href="#dfa-to-regex-dynamic-programmingtransitive-closure-method"></a> <strong>DFA to regex Dynamic programming/transitive closure method</strong></h4><p><a href="https://www.classes.cs.uchicago.edu/archive/2015/winter/28000-1/Lec2.pdf" target="_blank" rel="noopener">https://www.classes.cs.uchicago.edu/archive/2015/winter/28000-1/Lec2.pdf</a><br><a href="https://www.cs.dartmouth.edu/~ac/Teach/CS39-Winter09/SlidesAndNotes/lec09dfa2regexp.pdf" target="_blank" rel="noopener">https://www.cs.dartmouth.edu/~ac/Teach/CS39-Winter09/SlidesAndNotes/lec09dfa2regexp.pdf</a><br><a href="https://cs.stackexchange.com/questions/2016/how-to-convert-finite-automata-to-regular-expressions" target="_blank" rel="noopener">https://cs.stackexchange.com/questions/2016/how-to-convert-finite-automata-to-regular-expressions</a></p><h4 id="closure-properties-of-regular-language-regular-expression"><a class="markdownIt-Anchor" href="#closure-properties-of-regular-language-regular-expression"></a> <strong>Closure properties of regular language &amp; regular expression</strong></h4><p><img src="/img_520/1.png" alt=""><br><img src="/img_520/2.png" alt=""><br><img src="/img_520/3.png" alt=""></p><h4 id="regex-to-nfa-translation"><a class="markdownIt-Anchor" href="#regex-to-nfa-translation"></a> <strong>Regex to nfa translation</strong></h4><p><img src="/img_520/4.png" alt=""></p><h4 id="dfa-minimization-algorithm"><a class="markdownIt-Anchor" href="#dfa-minimization-algorithm"></a> <strong>Dfa minimization algorithm</strong></h4><p>Minimization of DFA - Table Filling Method (Myhill-Nerode Theorem)<br><img src="/img_520/5.png" alt=""></p><h4 id="myhill-nerode-theorem"><a class="markdownIt-Anchor" href="#myhill-nerode-theorem"></a> <strong>Myhill-nerode theorem</strong></h4><p><img src="/img_520/6.png" alt=""><br>Further more there is a minimized dfa having precisely one state for each equivalence class!!!<br><strong>equivalence classes classification</strong>: how to tell what equivalence classes are there?<br><a href="https://courses.cs.washington.edu/courses/cse322/05wi/handouts/MyhillNerode.pdf" target="_blank" rel="noopener">https://courses.cs.washington.edu/courses/cse322/05wi/handouts/MyhillNerode.pdf</a><br>Regular: we can use above algorithm on DFA minimization to find out each equivalence classes<br>Nonregular:<br><img src="/img_520/7.png" alt=""></p><h4 id="pumping-lemma-prove-nonregular-language"><a class="markdownIt-Anchor" href="#pumping-lemma-prove-nonregular-language"></a> <strong>Pumping lemma prove nonregular language</strong></h4><p><img src="/img_520/8.png" alt=""></p><p>Testing regularity finite language is regular  infinite language can be tested by pumping lemma</p><h4 id="testing-whether-a-language-is-regular-or-not"><a class="markdownIt-Anchor" href="#testing-whether-a-language-is-regular-or-not"></a> <strong>Testing whether a language is regular or not</strong></h4><p><a href="https://www.youtube.com/watch?v=KSczX111n3U" target="_blank" rel="noopener">https://www.youtube.com/watch?v=KSczX111n3U</a></p><h4 id="cfg-design-regular-language-to-cfg"><a class="markdownIt-Anchor" href="#cfg-design-regular-language-to-cfg"></a> <strong>CFG DESIGN  Regular language to CFG,</strong></h4><p><img src="/img_520/9.png" alt=""><br>对每一个dfa的state设计一个nonterminal variable；<br>对于每个transition  add 相应的rule   （根据不同的input）<br>对于accepting state的nonterminal variable 让他生成空的string<br>This cfg generates the same language that dfa recognizes.</p><h4 id="ambiguity"><a class="markdownIt-Anchor" href="#ambiguity"></a> <strong>AMBIGUITY</strong></h4><p>A string is derived ambiguously if it has one or more left/right most derivation tree.<br>A Grammar G is ambiguous if it generates some string ambiguously.</p><h4 id="chompsky-normal-form"><a class="markdownIt-Anchor" href="#chompsky-normal-form"></a> <strong>Chompsky Normal Form</strong></h4><p>(CFG simplification: removal of null ε production + unit production elimination + adding auxiliary variable &amp; rewrite)<br><a href="https://www.youtube.com/watch?v=EF09zxzpVbk&amp;list=PLBlnK6fEyqRgp46KUv4ZY69yXmpwKOIev&amp;t=5s&amp;index=76" target="_blank" rel="noopener">https://www.youtube.com/watch?v=EF09zxzpVbk&amp;list=PLBlnK6fEyqRgp46KUv4ZY69yXmpwKOIev&amp;t=5s&amp;index=76</a><br><img src="/img_520/10.png" alt=""></p><p><img src="/img_520/11.png" alt=""><br><img src="/img_520/12.png" alt=""><br>For each direct null production A-&gt; null , look for all productions whose right hand side contains A. Replace each occurrences of A in these production with null.  By each occurences, it means all possible location of A that can be nullified. Finsh the resulting productions without A-&gt;null, looking for the next one for ex B-&gt;null until no null productions exist.</p><p><strong>Or a graph-algorithm:</strong><br>Create a directed cyclic graph where each vertex represent a nonterminal for all nonterminals.<br>Add an edge if there is a unit production.<br>Collapse all strongly connected components into a single vertex (meaning these nonterminal are equivalent, merge their production rules in the grammar)<br>Start from sink S, augment production rules of the sink to all nonterminals that go to sink, then remove the edges from all nonterminals that go to sink.  Repeat this until no edges exist</p><p><strong>CYK algorithm O(n^3)<br>(Dynamic Programming parsing/recognizing if a string is in the language of cfg)<br>Assume in put is in CNF form.</strong><br><img src="/img_520/13.png" alt=""><br>For example, to parse <strong>“id ( id , id )” 6 character sequence,</strong> we construct 6 by 6 grid with diagonals filled in all possible nonterminal that can derive the i-th symbol for i=1 to i=6.<br><img src="/img_520/14.png" alt=""><br>Then we fill in each successive diagonals bottom up:<br>For each square, consider ALL possible ordered pair of the nonterminals one from left one from below, for each pair, if it can be derived from a rule(notice we have cnf), we put the lhs nonterminal of that rule to that squares<br><img src="/img_520/15.png" alt=""><br>If the starting nonterminal appear in the upper right corner of the grid we accept the string</p><p><strong>Non determinstic Push down automata<br>Equivalence of cfg and nondeterminstic pda :</strong><br>A language is generated by a cfg = it is recognized by a npda<br><a href="https://people.eecs.berkeley.edu/~sseshia/172/lectures/Slides8.pdf" target="_blank" rel="noopener">https://people.eecs.berkeley.edu/~sseshia/172/lectures/Slides8.pdf</a><br><img src="/img_520/16.png" alt=""></p><p>For example.<br><img src="/img_520/17.png" alt=""><br><img src="/img_520/18.png" alt=""><br><img src="/img_520/19.png" alt=""><br><img src="/img_520/20.png" alt=""></p><p><strong>Non context-free language</strong>:<br><img src="/img_520/21.png" alt=""></p><blockquote><p>For any context free language L, there is a pumping length p such that for any string<br>z ∈  L of sufficient length p≥1 or more, there is a decomposition of string z into 5−PART uvwxy s.t.:</p><ol><li>|vwx|≤p    middle three≤p (not too far apart)</li><li>|vx|&gt;0 pumping part of length nonegative</li><li>for any i≥0  uv^i wx^i y  stays in L<br><img src="/img_520/22.png" alt=""><br><strong>Both CFG-PL AND REG-PL are necessary but not sufficient conditions for context-freeness/regularity.</strong></li></ol></blockquote><p><strong>pumping lemma proof idea:</strong> for a sufficiently long string and its parse tree, the longest path in the tree by pigenhole principle must have nonterminals that repeat. Therefore Pumping up or down vx, it will remains a valid parse tree</p><p><strong>Language hierarchy &amp; Decidable and recognizable language</strong><br><img src="/img_520/23.png" alt=""><br>A <strong>decision problem</strong> can be expressed as a language, which is a set<br>A language is called a Recursively enumerable set (language) [also recognizable, partially decidable, semidecidable, Turing-acceptable or Turing-recognizable] if it is a recursively enumerable subset in the set of all possible words over the alphabet of the language, i.e., if there exists a Turing machine which will enumerate all valid strings of the language.</p><p>Recursive set, decidable set, computable set refers to the set of decision problem that are decidable in polynomial time</p><p>A complete set is a set of problems that are “hard”:<br>Np hard: every problem in np can reduce to it<br>Ex. To prove np-complete  first show it is np, then prove it is np hard, namely choose a np complete problem and reduce to it<br><img src="/img_520/24.png" alt=""><br><a href="https://en.wikipedia.org/wiki/Complete_(complexity)" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Complete_(complexity)</a></p><p><img src="/img_520/25.png" alt=""><br><img src="/img_520/26.png" alt=""><br><img src="/img_520/27.png" alt=""></p><p><strong>Proving problems undecidable<br>Turing machine and halting problem</strong><br>Refers to handouts<br><img src="/img_520/28.png" alt=""><br><img src="/img_520/29.png" alt=""><br><strong>多带图灵机与单带图灵机等价</strong><br>A turing machine accepts input if there is a sequence of configuration from starting config to accepting config<br>A turing machine is decidable if there is some decider for it(always halt and acc or rej).<br>Every NDTM has a equivalent DTM<br>ATM, HaltTM, Etm, Eqtm, PCP is undecidable but Turing-recognizable/recursively enumerable<br><img src="/img_520/30.png" alt=""><br><img src="/img_520/31.png" alt=""></p><p><strong>Undecidability and Rice’s theorem<br>Rice’s theorem:</strong><br><img src="/img_520/32.png" alt=""><br>A property is a set of Turing machine. A TM satisfies P means TM is in the set.<br>A property P is nontrivial means there is a TM that satisfies it and there is a TM that does not satisfies it.<br>A property P is trivial means either it is satisfied by all TMs or it is satisfied by no TMs.</p><p>Any nontrivial property about the r.e. language recognized by a Turing machine is undecidable.</p><p><strong>Reduction</strong> <a href="https://en.wikipedia.org/wiki/Reduction_(complexity)" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Reduction_(complexity)</a><br>A reduces to B means we can use an efficient solution of B as a subroutine to solve A     hardness of B 大于等于 A<br><strong>Computational complexity</strong><br><a href="https://blog.csdn.net/golden1314521/article/details/51470999" target="_blank" rel="noopener">https://blog.csdn.net/golden1314521/article/details/51470999</a></p><p>NP completeness theory is designed to be applied only to decision problem.<br>解决一个decision problem 等价于recognizing a corresponding language<br>A language is a set that contains all strings accepted by the turing machine.<br><strong>Class P</strong>： 以单带图灵机定义的【 所有多项式时间内deterministically recognizable language】<br><strong>Class NP</strong>: NTM Augmented Model of one tape turing machine with guessing ability<br>NTM 定义了 class NP: All languages recognizable nondeterministically in Polynomial time / there is a polynomial time NDTM program that accepts the language<br>NP is the class of languages that have polynomial time verifiers for the membership of an arbitrary instance given.<br><img src="/img_520/33.png" alt=""></p><p>A p-time mapping reduce to B means:  there is a transformation function that given an instance a of A 包装成 instance of B f(a)=b in polynomial time such that membership of  a and b in A and B. resp 同进同出</p><p>多项式时间于伪多项式时间<br>动态规划解决subsetsum</p><h4 id="textbook-reference"><a class="markdownIt-Anchor" href="#textbook-reference"></a> <strong>Textbook Reference</strong></h4><p>Computers and Intractability A Guide to the Theory of NP Completeness -  Michael R. Garey and David S. Johnson<br>Introduction to the theory of computation third edition - Michael Sipser<br>Introduction To Automata Theory, Languages, And Computation 3rd - John E. Hopcroft, Rajeev Motwani, Jeffrey D. Ullman</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;参考课程内容-httpscoursesengrillinoiseducs373sp2013lectures&quot;&gt;&lt;a class=&quot;markdownIt-Anchor&quot; href=&quot;#参考课程内容-httpscoursesengrillinoiseducs373sp
      
    
    </summary>
    
    
      <category term="Theory of computation" scheme="http://th2zz.github.io/tags/Theory-of-computation/"/>
    
  </entry>
  
  <entry>
    <title>real analysis</title>
    <link href="http://th2zz.github.io/2018/12/10/real-analysis/"/>
    <id>http://th2zz.github.io/2018/12/10/real-analysis/</id>
    <published>2018-12-09T18:00:41.000Z</published>
    <updated>2019-02-04T21:04:45.743Z</updated>
    
    <content type="html"><![CDATA[<p>summary and notes upon compeletion of the course and self study notes.<br><a href="https://github.com/th2zz/th2zz.github.io/blob/master/notes/real_analysis.pdf" target="_blank" rel="noopener">https://github.com/th2zz/th2zz.github.io/blob/master/notes/real_analysis.pdf</a><br>Textbook reference<br>Principles of Mathematical Analysis - Rudin<br>Analysis I - Terrence Tao</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;summary and notes upon compeletion of the course and self study notes.&lt;br&gt;
&lt;a href=&quot;https://github.com/th2zz/th2zz.github.io/blob/master/
      
    
    </summary>
    
    
      <category term="Math" scheme="http://th2zz.github.io/tags/Math/"/>
    
  </entry>
  
  <entry>
    <title>Programming language and Compiler</title>
    <link href="http://th2zz.github.io/2018/12/09/Compiler/"/>
    <id>http://th2zz.github.io/2018/12/09/Compiler/</id>
    <published>2018-12-09T03:40:41.000Z</published>
    <updated>2019-03-22T21:02:39.161Z</updated>
    
    <content type="html"><![CDATA[<p>summary &amp; notes upon compeletion of course on programming language and compiler<br><a href="https://github.com/th2zz/th2zz.github.io/blob/master/notes/CS536.pdf" target="_blank" rel="noopener">https://github.com/th2zz/th2zz.github.io/blob/master/notes/CS536.pdf</a><br>Textbook reference<br>Engineering a compiler. [Keith_D._Cooper_Linda_Torczon]</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;summary &amp;amp; notes upon compeletion of course on programming language and compiler&lt;br&gt;
&lt;a href=&quot;https://github.com/th2zz/th2zz.github.io
      
    
    </summary>
    
    
      <category term="Compiler" scheme="http://th2zz.github.io/tags/Compiler/"/>
    
  </entry>
  
  <entry>
    <title>Math431-probability theory</title>
    <link href="http://th2zz.github.io/2018/12/02/probability/"/>
    <id>http://th2zz.github.io/2018/12/02/probability/</id>
    <published>2018-12-02T04:30:02.000Z</published>
    <updated>2019-02-04T20:44:28.643Z</updated>
    
    <content type="html"><![CDATA[<p>notes collection<br><a href="https://github.com/th2zz/th2zz.github.io/blob/master/notes/probability.pdf" target="_blank" rel="noopener">https://github.com/th2zz/th2zz.github.io/blob/master/notes/probability.pdf</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;notes collection&lt;br&gt;
&lt;a href=&quot;https://github.com/th2zz/th2zz.github.io/blob/master/notes/probability.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
      
    
    </summary>
    
    
      <category term="Math" scheme="http://th2zz.github.io/tags/Math/"/>
    
  </entry>
  
  <entry>
    <title>Digital system fundamental</title>
    <link href="http://th2zz.github.io/2018/05/22/Digital-system-fundamental/"/>
    <id>http://th2zz.github.io/2018/05/22/Digital-system-fundamental/</id>
    <published>2018-05-22T00:43:32.000Z</published>
    <updated>2019-02-04T20:26:06.050Z</updated>
    
    <content type="html"><![CDATA[<p>summary and notes upon compeletion of the course.<br><a href="https://github.com/th2zz/th2zz.github.io/blob/master/notes/digital_circuit.pdf" target="_blank" rel="noopener">https://github.com/th2zz/th2zz.github.io/blob/master/notes/digital_circuit.pdf</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;summary and notes upon compeletion of the course.&lt;br&gt;
&lt;a href=&quot;https://github.com/th2zz/th2zz.github.io/blob/master/notes/digital_circuit
      
    
    </summary>
    
    
      <category term="Computer Science" scheme="http://th2zz.github.io/tags/Computer-Science/"/>
    
  </entry>
  
  <entry>
    <title>CS540 Intro to AI Notesheet</title>
    <link href="http://th2zz.github.io/2018/05/20/ai/"/>
    <id>http://th2zz.github.io/2018/05/20/ai/</id>
    <published>2018-05-19T18:00:41.000Z</published>
    <updated>2019-03-20T22:42:14.864Z</updated>
    
    <content type="html"><![CDATA[<img width="1000" src="/img_540/1.png"><img width="1000" src="/img_540/2.png"><img width="1000" src="/img_540/3.png"><img width="1000" src="/img_540/4.png"><img width="1000" src="/img_540/5.png"><img width="1000" src="/img_540/6.png"><img width="1000" src="/img_540/7.png"><img width="1000" src="/img_540/8.png"><img width="1000" src="/img_540/9.png">]]></content>
    
    <summary type="html">
    
      
      
        &lt;img width=&quot;1000&quot; src=&quot;/img_540/1.png&quot;&gt;
&lt;img width=&quot;1000&quot; src=&quot;/img_540/2.png&quot;&gt;
&lt;img width=&quot;1000&quot; src=&quot;/img_540/3.png&quot;&gt;
&lt;img width=&quot;1000&quot; sr
      
    
    </summary>
    
    
      <category term="Computer Science" scheme="http://th2zz.github.io/tags/Computer-Science/"/>
    
  </entry>
  
</feed>
